::: progress
::: {.progress-bar style="width: 100%;"}
:::
:::

```{r, include=FALSE}
options(OutDec = ",", digits = 4)
```

# Técnicas Paramétricas - Modelos Probabilísticos

## Introdução

No capítulo anterior, foi apresentada uma abordagem não paramétrica para a análise de dados de sobrevivência, na qual a estimação é realizada sem assumir uma distribuição de probabilidade específica para o tempo de sobrevivência.

Os estimadores não paramétricos são derivados diretamente do conjunto de dados, pressupondo que o mecanismo gerador das informações opera de maneira distinta em diferentes momentos no tempo, funcionando de forma quase independente. Assim, conclui-se que a abordagem não paramétrica possui tantos parâmetros quanto intervalos de tempo considerados. Contudo, ao incluir covariáveis, o modelo de Kaplan-Meier não permite estimar diretamente o "efeito" dessas covariáveis, limitando-se a comparar e testar a igualdade entre diferentes curvas de sobrevivência.

Por outro lado, nos modelos de regressão tradicionais, como os modelos *linear*, *Poisson* ou *logístico*, a escolha de uma distribuição de probabilidade para a variável resposta $Y$ e de uma função para a relação entre $Y$ e as covariáveis $x_{1}, x_{2}, \ldots, x_{p}$ é essencial para identificar o modelo. Ao aplicar esse conceito na análise de sobrevivência, o tempo até a ocorrência de um evento de interesse é tratado como a variável resposta.

Nesse contexto, este capítulo introduz uma abordagem paramétrica para estimar as funções básicas de sobrevivência. Assume-se que a distribuição de probabilidade do tempo de ocorrência do evento é conhecida, permitindo a estimação dos parâmetros associados ao modelo de forma mais estruturada e eficiente.

## Distribuições do Tempo de Sobrevivência {#sec-Dists}

Seja $T$ uma variável aleatória que representa o "tempo de sobrevivência". Qual seria a distribuição de probabilidade mais adequada para representá-la?

Uma característica fundamental da variável aleatória $T$ é que ela é contínua e não negativa. Com base nessa propriedade, é possível eliminar algumas distribuições como candidatas adequadas para modelar $T$. Por exemplo, a distribuição normal não é apropriada, pois admite valores negativos, o que contradiz a natureza do tempo de sobrevivência. Além disso, os tempos de sobrevivência frequentemente apresentam uma forte assimetria à direita, reforçando a inadequação da distribuição normal para esse contexto.

```{r, message=FALSE, warning=FALSE}
# -----------------------
# [1] ATIVAÇÃO DE PACOTES
# -----------------------
library(dplyr)
library(ggplot2)
library(eha)
```

### Distribuição Exponencial {#sec-DistExp}

Se $T \sim Exp(\alpha)$, a sua função densidade de probabilidade é expressa da seguinte forma:

$$
f(t) = \alpha \exp\{ -\alpha t \}, \ t \geq 0 \ \text{e} \ \alpha > 0.
$$ {#eq-densitExp}

Desta forma, podemos obter a função de sobrevivência com base no completar da distribuição acumulada de $T$:

```{=latex}
\begin{align*}
    S(t) & = P(T > t) = 1 - P(T \leq t) = 1 - F(t) \\
         & = 1 - [1 - \exp\{ -\alpha t \}] \\
         & = \exp\{ -\alpha t \}.
\end{align*}
```
\noindent Assim definimos, formalmente, a função de sobrevivência como:

$$
S(t) = \exp\{ -\alpha t \}.
$$ {#eq-StExp}

Note que o parâmetro $\alpha$ é a velocidade de queda da função sobrevivência. Através das relações entre as funções em análise de sobrevivência, temos a função risco ou taxa de falha. Obtida pela razão entre da função densidade de probabilidade e a função de sobrevivência:

$$
\lambda(t) = \dfrac{f(t)}{S(t)} = \dfrac{\alpha \exp\{ -\alpha t \}}{\exp\{ -\alpha t \}} = \alpha = \text{constante}.
$$ {#eq-RiscoExp}

Sendo a função risco constante para todo tempo observado $t$, o risco acumulado é função linear no tempo com uma inclinação da reta dada por $\alpha$:

$$
\Lambda(t) = - \ln[S(t)] = - \ln[ \exp\{ -\alpha t \} ] = - (- \alpha t) = \alpha t
$$ {#eq-RiscoAcumExp}

Veja, a seguir, a @fig-CurvasExp que mostra as curvas de densidade de probabilidade, de sobrevivência, risco e risco acumulado para diferentes valores do parâmetro $\alpha$.

```{r, message=FALSE, warning=FALSE}
#| fig-cap: "Funções Densidade de Probabilidade, Sobrevivência, Risco e Risco Acumulado segundo uma Distribuição Exponencial para diferentes valores do Parâmetro de Taxa."
#| fig-cap-location: top
#| fig-subcap: 
#| - "Função Densidade de Probabilidade"
#| - "Função de Sobrevivência"
#| - "Função de Risco"
#| - "Função de Risco Acumulado"
#| layout-ncol: 2
#| layout-nrow: 2
#| label: fig-CurvasExp

# ---------------------------
# [1] DISTRIBUIÇÃO EXPONENCIAL
# ---------------------------
# -------------
# [1.1] FUNÇÕES
# -------------

density.exp <- function(times, rate.par) dexp(x = times, rate = rate.par)
survival.exp <- function(times, rate.par) 1 - pexp(q = times, rate = rate.par)
hazard.exp <- function(times, rate.par) density.exp(times, rate.par)/survival.exp(times, rate.par)
accumul.hazard.exp <- function(times, rate.par) - log(x = survival.exp(times, rate.par))

# ----------------------------------------
# [1.2] SIMULAÇÃO E VARIAÇÃO DE PARÂMETROS
# ----------------------------------------

set.seed(123456789)        # Semente para reprodutibilidade
n <- 1000                  # Tamanho amostral
times <- rexp(n, rate = 1) # Simulando dados de uma exponencial
alphas <- c(1, 1.5, 2, 2.5, 3) # Valores do parâmetro a serem avaliados

# Criando um Data Frame com valores das funções
dados.exp <- do.call(
  rbind, lapply(alphas, function(alpha) {
    data.frame(
      times = sort(times),
      ft = density.exp(sort(times), alpha),
      st = survival.exp(sort(times), alpha),
      ht = hazard.exp(sort(times), alpha),
      Ht = accumul.hazard.exp(sort(times), alpha),
      rate = factor(alpha)
    )
  })
)

# ---------------------------------------------
# [1.3] FUNÇÃO GRÁFICA & VISUALIZAÇÕES GRÁFICAS
# ---------------------------------------------

plot.function.exp <- function(df, f, label) {
  ggplot(data = df, aes_string(x = "times", y = f, color = "rate")) +
    geom_line(size = 1.15) +
    labs(x = "Tempo", y = label, color = expression(alpha)) +
    scale_color_manual(
      values = c("red", "blue", "green", "purple", "orange"), 
      labels = (levels(df$rate))
    ) + theme_minimal(base_size = 12)
}

# Plotando a função densidade de probabilidade
plot.function.exp(dados.exp, "ft", "Densidade de Probabilidade")

# Plotando a função de sobrevivência
plot.function.exp(dados.exp, "st", "Probabilidade de Sobrevivência")

# Plotando a função de risco
plot.function.exp(dados.exp, "ht", "Risco")

# Plotando a função de risco acumulado
plot.function.exp(dados.exp, "Ht", "Risco Acumulado")
```

#### Algumas considerações

Note que, quanto maior o valor de $\alpha$ (risco), mais abruptamente a função de sobrevivência $S(t)$ decresce, e maior é a inclinação da função de risco acumulado.

A distribuição exponencial, por possuir um único parâmetro, é matematicamente simples e apresenta um formato assimétrico. Seu uso em análise de sobrevivência tem uma analogia com a suposição de normalidade em outras técnicas e áreas da estatística. Entretanto, a suposição de risco constante associada a essa distribuição é bastante restritiva e, em muitos casos, pode não ser realista.

Por exemplo, considere um estudo sobre câncer, em que o tempo até o evento de interesse é definido como o período até a morte ou a cura do paciente. Para aplicar a distribuição exponencial nesse contexto, seria necessário assumir que o tempo desde o diagnóstico da doença não afeta a probabilidade de ocorrência do evento. Essa suposição é delicada, pois o próprio passar do tempo afeta naturalmente a probabilidade de sobrevivência, o risco e o risco acumulado, entre outros fatores. Isso pode ocorrer por causas naturais, como o envelhecimento, que aumenta o risco com o avanço da idade. Essa característica da distribuição exponencial é conhecida como falta de memória, o que significa que o risco futuro é independente do tempo já decorrido.

Quando $\alpha = 1$, a distribuição é denominada exponencial padrão. A média e a variância do tempo de sobrevivência, para uma variável que segue a distribuição exponencial, são expressas como funções inversas do parâmetro de risco ($\alpha$). Assim, quanto maior o risco, menor o tempo médio de sobrevivência e menor a variabilidade em torno da média. As expressões são dadas por:

$$
E[T] = \dfrac{1}{\alpha},
$$

$$
Var[T] = \dfrac{1}{\alpha^2}.
$$ Como a distribuição de $T$ é assimétrica, se torna mais usual utilizar o *tempo mediano de sobrevivência* ao invés de tempo médio. Pode-se obter o tempo mediano de sobrevivência a partir de um tempo $t$, tal que, $S(t) = 0,5$, logo,

```{=latex}
\begin{align*}
    S(t) & = 0,5 \Leftrightarrow \exp\{ -\alpha t \} = 0,5 \Leftrightarrow -\alpha t = \ln(2^{-1}) \\
    \alpha t & = - [-\ln(2)] \Leftrightarrow \alpha t = \ln(2).
\end{align*}
```
Desta forma, o tempo mediano de sobrevivência é definido como:

$$
T_{mediano} = \dfrac{\ln(2)}{\alpha}.
$$

Em resumo, o modelo exponencial é apropriado para situações em que o período do experimento é curto o suficiente para que a suposição de risco constante seja plausível.

### Distribuição Weibull {#sec-DistWeibull}

Na maioria dos casos de análise de sobrevivência na área da saúde, é mais razoável supor que o risco varia ao longo do tempo, em vez de permanecer constante.

Atualmente, a *Distribuição Weibull* é amplamente utilizada, pois permite modelar essa variação do risco ao longo do tempo. Como será demonstrado, a distribuição exponencial é um caso particular da distribuição Weibull.

Se o tempo de sobrevivência $T$ segue uma distribuição Weibull, ou seja, $T \sim Weibull(\gamma, \alpha)$, sua função densidade de probabilidade é dada por:

$$
f(t) = \dfrac{ \gamma }{ \alpha^{\gamma} } t^{\gamma - 1} \exp \left\{ - \left( \dfrac{t}{\alpha} \right)^{\gamma} \right\}.
$$ {#eq-densittWei}

A partir da @eq-densittWei é possível chegar a função de sobrevivência da distribuição Weibull sendo está função definida como:

$$
S(t) = \exp \left\{ - \left( \dfrac{t}{\alpha} \right)^{\gamma} \right\},
$$ {#eq-StWeibull}

onde $t \geq 0$, $\alpha$ o parâmetro escala (ou taxa) e $\gamma$ parâmetro de forma. Ambos os parâmetros sempre positivos.

A função de risco, $\lambda(t)$, depende do tempo de sobrevivência. Apresentando variação no tempo conforme a expressão:

$$
\lambda (t) = \dfrac{f(t)}{S(t)} = \dfrac{ \gamma }{ \alpha^{\gamma} } t^{\gamma - 1}
$$ {#eq-RiscoWeibull}

e a função de risco acumulado da distribuição Weibull é dada por:

$$
\Lambda (t) = - \ln[S(t)] = - \ln \left[ \exp \left\{ - \left( \dfrac{t}{\alpha} \right)^{\gamma} \right\} \right] = \left( \dfrac{t}{\alpha} \right)^{\gamma}.
$$ {#eq-RiscAcumWeibull}

Note que, o parâmetro $\gamma$ determina a forma função de risco da seguinte maneira:

-   $\gamma < 1 \rightarrow$ função de risco decresce;
-   $\gamma > 1 \rightarrow$ função de risco cresce;
-   $\gamma = 1 \rightarrow$ função de risco constante, caindo no caso particular da distribuição exponencial.

Veja, a seguir, a @fig-CurvasWeibull que mostra as curvas de densidade, sobrevivência, risco e risco acumulado para diferentes valores do parâmetro de forma $\gamma$ e o de escala $\alpha = 1$.

```{r message=FALSE, warning=FALSE}
#| fig-cap: "Funções Densidade de Probabilidade, Sobrevivência, Risco e Risco Acumulado segundo uma Distribuição Weibull para diferentes valores do parâmetro de forma."
#| fig-cap-location: top
#| fig-subcap: 
#| - "Função Densidade de Probabilidade"
#| - "Função de Sobrevivência"
#| - "Função de Risco"
#| - "Função de Risco Acumulado"
#| layout-ncol: 2
#| layout-nrow: 2
#| label: fig-CurvasWeibull

# ------------------------
# [2] DISTRIBUIÇÃO WEIBULL
# ------------------------
# -------------
# [2.1] FUNÇÕES
# -------------

density.weib <- function(times, shape.par, scale.par) dweibull(x=times, shape=shape.par, scale=scale.par)
survival.weib <- function(times, shape.par, scale.par) 1 - pweibull(q=times, shape=shape.par, scale=scale.par)
hazard.weib <- function(times, shape.par, scale.par) density.weib(times,shape.par,scale.par)/survival.weib(times,shape.par,scale.par)
accumul.hazard.weib <- function(times, shape.par, scale.par) - log(x = survival.weib(times,shape.par,scale.par))

# ----------------------------------------
# [2.2] SIMULAÇÃO E VARIAÇÃO DE PARÂMETROS
# ----------------------------------------
n <- 1000                                  # Tamanho amostral
times <- rweibull(n, shape = 2, scale = 1) # Simulando dados de uma Weibull
alpha <- 1                                 # Fixo para simplificar
gammas <- c(0.5, 1.0, 1.5, 2.0, 2.5, 3.0)  # # Valores do parâmetro a serem avaliados

# Criando um Data Frame com valores das funções
dados.weib <- do.call(rbind, lapply(gammas, function(gamma) {
  data.frame(
    times = sort(times),
    ft = density.weib(sort(times), gamma, alpha),
    st = survival.weib(sort(times), gamma, alpha),
    ht = hazard.weib(sort(times), gamma, alpha),
    Ht = accumul.hazard.weib(sort(times), gamma, alpha),
    gamma = factor(gamma)
  )
}))

# ---------------------------------------------
# [2.3] FUNÇÃO GRÁFICA & VISUALIZAÇÕES GRÁFICAS
# ---------------------------------------------

plot.function.weib <- function(df, f, label) {
  ggplot(data = df, aes_string(x = "times", y = f, color = "gamma")) +
    geom_line(size = 1.15) +
    labs(x = "Tempo", y = label, color = expression(gamma)) +
    scale_color_manual(
      values = c("red", "blue", "green", "purple", "orange", "brown"), 
      labels = (levels(df$gamma))
    ) + theme_minimal(base_size = 12)
}

# Plotando a função densidade de probabilidade
plot.function.weib(dados.weib, "ft", "Densidade de Probabilidade")

# Plotando a função de sobrevivência
plot.function.weib(dados.weib, "st", "Probabilidade de Sobrevivência")

# Plotando a função de risco
plot.function.weib(dados.weib, "ht", "Risco")

# Plotando a função de risco acumulado
plot.function.weib(dados.weib, "Ht", "Risco Acumulado")
```

#### Algumas considerações

É incluso a função gama na média e variância da distribuição Weibull, assim,

$$
E[T] = \alpha \Gamma[1 + (1/\gamma)]
$$ 
\noindent e

$$
Var[T] = \alpha^{2} \left[ \Gamma [1 + (2/\gamma)] - \Gamma [1 + (1/\gamma)]^{2} \right]
$$

\noindent sendo a função gama $\Gamma [k]$, expressa por $\Gamma [k] = \int_{0}^{\infty} t^{k -1} \exp\{t\} dt$.

Afim de se obter o tempo mediano de sobrevivência, igualamos a probabilidade de sobrevivência a $0,5$. Desta forma:

```{=latex}
\begin{align*}
    S(t) & = 0,5 \Leftrightarrow \exp \left\{ - \left( \dfrac{t}{\alpha} \right)^{\gamma} \right\} = 0,5 \\
    - \left( \dfrac{t}{\alpha} \right)^{\gamma} & = \ln{(2^{-1})} \Leftrightarrow \left( \dfrac{t}{\alpha} \right)^{\gamma} = \ln{(2)} \\
    \dfrac{t}{\alpha} & = [\ln{(2)}]^{1/\gamma}.
\end{align*}
```
Logo, definimos o tempo mediano de sobrevivência da distribuição Weibull como:

$$
T_{mediano} = \alpha [\ln{(2)}]^{1/\gamma}.
$$

### Distribuição Log-normal

Uma outra possibilidade para modelar o tempo de sobrevivência é a *distribuição Log-normal*. Dizer que $T \sim Normal(\mu, \sigma^{2})$ implica em dizer que $\ln(T) \sim Log-normal(\mu, \sigma^{2})$ em que $\mu$ é a média do logaritmo do tempo de falha e $\sigma^{2}$ sua variância. Pode-se fazer uso desta relação para modelar o tempo de sobrevivência conforme uma distribuição normal, desde que, se aplique o logaritmo aos dados observados. A função densidade para tal distribuição é dada por:

$$
f (t) = \dfrac{1}{t \sigma \sqrt{2 \pi}} \exp \left\{- \dfrac{1}{2} \left(\dfrac{\ln(t) - \mu}{\sigma}\right)^{2} \right\}.
$$ {#eq-densitLognormal}

Assim, quando o tempo de sobrevivência segue uma distribuição log-normal, sua função de sobrevivência e as demais não tem uma forma análitica explícita, desde modo, deve-se fazer uso das relações entre as funções para se obter a função taxa de falha e taxa de falha acumulada. Desta forma, essas funções são expressas, respectivamente, por:

$$
S (t) = \Phi \left( \dfrac{- \ln(t) + \mu}{\sigma} \right),
$$ {#eq-StLognormal}

$$
\lambda (t) = \dfrac{f(t)}{S(t)}
$$

\noindent e

$$
\Lambda (t) = - \ln[S(t)]
$$

\noindent em que $\Phi (\cdot)$ é a função de distribuição acumulada da normal padrão.

Veja a @fig-CurvasLognormal que ilustras as curvas usadas na análise de sobrevivência segundo uma distribuição log-normal, variando o parâmetro de locação $\mu$ e fixando o parâmetro de escala $\sigma = 1$.

```{r message=FALSE, warning=FALSE}
#| fig-cap: "Funções Densidade de Probabilidade, Sobrevivência, Risco e Risco Acumulado segundo uma Distribuição Log-normal para diferentes valores do parâmetro de média."
#| fig-cap-location: top
#| fig-subcap: 
#| - "Função Densidade de Probabilidade"
#| - "Função de Sobrevivência"
#| - "Função de Risco"
#| - "Função de Risco Acumulado"
#| layout-ncol: 2
#| layout-nrow: 2
#| label: fig-CurvasLognormal

# ---------------------------
# [3] DISTRIBUIÇÃO LOG-NORMAL
# ---------------------------
# -------------
# [3.1] FUNÇÕES
# -------------

density.lnorm <- function(times, loc.par, scale.par) dlnorm(x=times, loc.par, scale.par)
survival.lnorm <- function(times, loc.par, scale.par) 1 - pnorm(q=(log(times)-loc.par)/scale.par)
hazard.lnorm <- function(times, loc.par, scale.par) density.lnorm(times, loc.par, scale.par)/survival.lnorm(times, loc.par, scale.par)
accumul.hazard.lnorm <- function(times, loc.par, scale.par) -log(x=survival.lnorm(times, loc.par, scale.par))

# ----------------------------------------
# [3.2] SIMULAÇÃO E VARIAÇÃO DE PARÂMETROS
# ----------------------------------------
n <- 1000                                  # Tamanho amostral
times <- rlnorm(n, meanlog = 0, sdlog = 1) # Simulando dados de uma Log-normal
loc.pars <- c(0, 0.5, 1, 1.5, 2, 2.5)      # Valores de mu
scale.par <- 1                             # Valor fixo de sigma

# Criando um Data Frame com valores das funções
dados.lnorm <- do.call(
  rbind, lapply(loc.pars, function(loc.par) {
    data.frame(
      times = sort(times),
      ft = density.lnorm(sort(times), loc.par, scale.par),
      st = survival.lnorm(sort(times), loc.par, scale.par),
      ht = hazard.lnorm(sort(times), loc.par, scale.par),
      Ht = accumul.hazard.lnorm(sort(times), loc.par, scale.par),
      mu = factor(loc.par)
    )
  })
)

# ---------------------------------------------
# [3.3] FUNÇÃO GRÁFICA & VISUALIZAÇÕES GRÁFICAS
# ---------------------------------------------

plot.function.lnorm <- function(df, f, label) {
  ggplot(data = df, aes_string(x = "times", y = f, color = "mu")) +
    geom_line(size = 1.15) +
    labs(x = "Tempo", y = label, color = expression(mu)) +
    scale_color_manual(
      values = c("red", "blue", "green", "purple", "orange", "brown"), 
      labels = (levels(df$mu))
    ) + theme_minimal(base_size = 12)
}

# Plotando a função densidade de probabilidade
plot.function.lnorm(dados.lnorm, "ft", "Densidade de Probabilidade")

# Plotando a função de sobrevivência
plot.function.lnorm(dados.lnorm, "st", "Probabilidade de Sobrevivência")

# Plotando a função de risco
plot.function.lnorm(dados.lnorm, "ht", "Risco")

# Plotando a função de risco acumulado
plot.function.lnorm(dados.lnorm, "Ht", "Risco Acumulado")
```

#### Algumas considerações

A média e a variância da distribuição log-normal são, respectivamente, dadas por:

$$
E[T] = \exp\{ \mu + \sigma^{2} / 2 \}
$$

e

$$
Var[T] = \exp\{ 2 \mu + \sigma^{2} \} (\exp\{ \sigma^{2} - 1 \})
$$

### Distribuição Exponencial por Partes

### Distribuição Exponencial por Partes de Potência

## Estimação de Parâmetros

Foram apresentados alguns modelos probabilísticos. Esses modelos possuem quantidades desconhecidas, denominadas **parâmetros**, ou **parâmetro**, quando o modelo depende de uma única quantidade desconhecida, como no caso da distribuição exponencial.

### Método de Máxima Verossimilhança

O *Método de Máxima Verossimilhança* baseia-se no princípio de que, a partir de uma amostra aleatória, a melhor estimativa para o parâmetro de interesse é aquela que maximiza a probabilidade daquela amostra observada ter sido observada [@bussab2010estatistica].

De forma simples, o método de máxima verossimilhança condensa toda a informação contida na amostra, por meio da **função de verossimilhança**, para encontrar o(s) parâmetro(s) da distribuição que melhor expliquem os dados. Essa abordagem utiliza o produtório das densidades $f(t)$ para cada observação $t_i$, $i = 1, 2, \ldots, n$. Em livros introdutórios de estatística, a função de verossimilhança é definida da seguinte maneira, para um parâmetro ou vetor de parâmetros $\theta$:

$$
L(\theta) = \prod_{i = 1}^{n} f(t_{i} | \theta).
$$

Observe que $L$ é uma função de $\theta$, que pode ser um único parâmetro ou um vetor de parâmetros, como ocorre na distribuição log-normal, onde $\theta = (\mu, \sigma^2)$. No entanto, em análise de sobrevivência, essa definição tradicional de função de verossimilhança é insuficiente, pois os dados frequentemente apresentam **censura**, o que implica que o tempo de evento pode ser apenas parcialmente observado.

Para lidar com essa característica, utiliza-se a variável indicadora $\delta_{i}$, apresentada na @sec-ReprDados, que identifica se o $i$-ésimo tempo é um tempo de evento ou de censura. Com base nessa informação, a função de verossimilhança é ajustada da seguinte forma:

-   Para $\delta_{i} = 1$, o $i$-ésimo tempo é um tempo de evento, e sua contribuição para $L(\theta)$ é a densidade de probabilidade $f(t_{i} | \theta)$;
-   Para $\delta_i = 0$, o $i$-ésimo tempo é um tempo censurado, e sua contribuição para $L(\theta)$ é a função de sobrevivência $S(t_{i} | \theta)$.

Assim, a função de verossimilhança ajustada, que incorpora dados censurados, é expressa como:

$$
L(\theta) = \prod_{i = 1}^{n} \left[ f(t_{i} | \theta) \right]^{\delta_i} \left[ S(t_{i} | \theta) \right]^{1 - \delta_{i}}
$$
$$
L(\theta) = \prod_{i = 1}^{n} \left[ \lambda(t_{i} | \theta) \right]^{\delta_i} S(t_{i} | \theta).
$$ {#eq-verossilGeneric}

Para encontrar o valor de $\theta$ que maximiza $L(\theta)$, utiliza-se a derivada do logaritmo de base neperiana da verossimilhança igualada a zero:

$$
\frac{\partial \ln [L(\theta)]}{\partial \theta} = 0.
$$

\noindent A solução dessa equação fornece o valor de $\theta$ que maximiza $\ln [L(\theta)]$, e consequentemente, $L(\theta)$.

### Método Iterativo de Newton-Raphson {#sec-NewtonRaphson}

Para algumas distribuições, apresentadas na @sec-Dists, e outras denifidas na literatura, não há forma analítica para as estimativas de máxima verossimilhança. Assim, as estimativas de tais parâmetros depende de métodos numéricos, sendo o **Método Iterativo de Newton-Raphson** uma abordagem amplamente utilizada.

O Método de Newton-Raphson é um procedimento iterativo eficiente para resolver equações não lineares, muito empregado na estimação de parâmetros de modelos estatísticos. No ajuste de distribuições o método busca maximizar a função de verossimilhança resolvendo o sistema de equações derivado das condições de otimalidade (gradiente nulo). A fórmula iterativa é:

$$
\theta_{n+1} = \theta_{n} - \mathbf{H}^{-1}(\theta_{n}) \nabla \ln[L(\theta_{n})],
$$ {#eq-NewtonRaphson}

\noindent onde:

-   $\theta_{n}$ é o vetor de parâmetros estimados na iteração $n$;
-   $\ln[L(\theta_{n})]$ é o vetor gradiente, contendo as derivadas parciais de $\ln[L(\theta_{n})]$ em relação as coordenadas do vetor $\theta$ (parâmetros);
-   $\mathbf{H}(\theta)$ é a matriz Hessiana, composta pelas segundas derivadas de $\ln[L(\theta_{n})]$.

O método apresenta vantagens convenientes no ajuste de parâmetros de modelos estatísticos. Uma das vantagens é a *eficiência* do método, que apresenta convergência rápida quando o ponto inicial $\theta_{0}$ está próximo dos valores reais dos parâmetros. Outra vantagem, é *flexibilidade*, pois pode ser aplicado a diversos modelos probabilísticos, como o modelo Weibull, que é amplamente utilizada para modelar tempos de vida e dados de sobrevivência.

Entretanto, deve-se, também, atentar-se aos cuidados na aplicação do método. Pois, a *convergência* do método não é garantida caso o ponto inicial esteja muito distante da solução ou se as condições de regularidade do modelo não forem atendidas. Outro ponto que merece atenção é o cálculo da *matriz Hessiana*, que pode ser computacionalmente custoso, especialmente em modelos com maior complexidade.

Para um melhor entendimento do Método Iterativo de Newton-Raphson veja o Apêndice (D) do livro *Análise de Sobrevivência Aplicada* de @colosimo2006analise.

### Aplicações Caso Não Haja Censura

Nesta seção, será demonstrado como determinar o estimador ou os estimadores de máxima verossimilhança para os parâmetros das distribuições discutidas quando não há presença de censuras nos dados. Aqui, será apresentada apenas a saída dos programas. Para ter o script utilizado, acesse o repositório do Github por meio do seguinte link: [github.com](https://github.com/csilv7/ANALISE_DE_SOBREVIVENCIA/blob/main/CODES/Optimization.R)

#### Distribuição Exponencial

Considere a distribuição exponencial conforme descrita na @sec-DistExp. O **Estimador de Máxima Verossimilhança (EMV)** do parâmetro $\alpha$, isto é, $\theta = \alpha$, pode ser obtido seguindo os passos descritos a seguir:

1.  Definir a Função de Verossimilhança $L(\theta)$:

$$
L(\theta) = \prod_{i = 1}^{n} \left[ \alpha \exp\{ -\alpha t \} \right]^{\delta_{i}} \left[ \exp\{ -\alpha t \} \right]^{1 - \delta_{i}}.
$$ {#eq-loglikelihoodExponential}

2.  Tomar o logaritmo natural da função verossimilhança $\ln[L(\alpha)]$:

```{=latex}
\begin{align*}
    \ln[L(\theta)] & = \sum_{i = 1}^{n} \ln \left[ \alpha^{\delta_{i}} \exp \{ - \alpha t_{i} \} \right] = \sum_{i = 1}^{n} \ln \left[ \alpha^{\delta_{i}} \right] + \sum_{i = 1}^{n} \ln \left[ \exp \{ - \alpha t_{i} \} \right] \\
                   & = \sum_{i = 1}^{n} \delta_{i} \ln[\alpha] + \sum_{i = 1}^{n} - \alpha t_{i} =  \ln[\alpha] \sum_{i = 1}^{n} \delta_{i} - \alpha \sum_{i = 1}^{n} t_{i}. \\
\end{align*}
```
3.  Derivar a função do log-verossimilhança em relação a $\theta$. Logo $\dfrac{\partial \ln[L (\theta)]}{\partial \theta}$:

```{=latex}
\begin{align*}
    \dfrac{\partial \ln L (\theta)}{\partial \theta}  & = \dfrac{1}{\alpha} \sum_{i = 1}^{n} \delta_{i} - \sum_{i = 1}^{n} t_{i}.
\end{align*}
```

4.  Igualar a derivada a zero e resolver para $\alpha$:

```{=latex}
\begin{align*}
    \dfrac{\partial \ln[L (\theta)]}{\partial \theta}  & = 0 \\
    \dfrac{1}{\hat{\alpha}} \sum_{i = 1}^{n} \delta_{i} - \sum_{i = 1}^{n} t_{i} & = 0 \\
    \hat{\alpha} & = \dfrac{\sum_{i = 1}^{n} \delta_{i}}{\sum_{i = 1}^{n} t_{i}}
\end{align*}
```

Note que, para o caso em que não se tem censura o numerador, $\sum_{i = 1}^{n} \delta_{i}$, equivale ao tamanho da amostra $n$. Logo, o EMV para $\alpha$ no caso de não haver censura nos dados é: $\hat{\alpha} = n /\sum_{i = 1}^{n} t_{i}$.

Simulou-se uma amostra proveniente de uma distribuição exponencial e, a partir dessa amostra, obteve-se a estimativa de máxima verossimilhança para o parâmetro $\alpha$. Veja a @tbl-EMVexpSt, que apresenta as dez observações, na ordem de simulação, e suas respectivas funções de sobrevivência real e estimada.

```{r message=FALSE, warning=FALSE}
#| tbl-cap: "Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Exponencial."
#| label: tbl-EMVexpSt
#| tbl-cap-location: top

# ---------------------------
# [1] Função de Sobrevivência
# ---------------------------
survival.exp <- function(times, rate.par) 1 - pexp(q = times, rate = rate.par)

# -------------------------
# [2] Simulação e Estimação
# -------------------------

# Configuração inicial
set.seed(123456789)
n <- 1000    # Tamanho amostral
rate <- 1.5  # Parâmetro verdadeiro

times <- rexp(n, rate = rate) # Simulação de tempos de sobrevivência
emv.exp <- n / sum(times)     # Estimador de Máxima Verossimilhança (EMV)

# -------------------------
# [3] Organização dos Dados
# -------------------------
dados.exp <- data.frame(
  times = times,
  st = survival.exp(times, rate),
  st.emv = survival.exp(times, emv.exp)
)

library(knitr)

knitr::kable(
  round(head(dados.exp, 10), 4), 
  col.names = c("Tempo", "$S(t)$", "$\\hat{S}_{EMV}(t)$"),
  escape = FALSE,
  align = "c",
  booktabs = TRUE
)
```

O valor verdadeiro do parâmetro é $\alpha = `{r} rate`$. A estimativa de máxima verossimilhança obtida foi $\hat{\alpha} = `{r} emv.exp`$. Na @fig-CompEMVexp, comparamos graficamente as duas curvas de sobrevivência, ilustrando o valor real do parâmetro $\alpha$ e sua estimativa $\hat{\alpha}$.

```{r message=FALSE, warning=FALSE}
#| fig-cap: "Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial."
#| label: fig-CompEMVexp
#| fig-cap-location: top

# -------------------------
# [1] Organização dos Dados
# -------------------------
dados.exp <- data.frame(
  times = sort(times),
  st = survival.exp(sort(times), rate),
  st.emv = survival.exp(sort(times), emv.exp)
)

ggplot(dados.exp, aes(x = times)) +
  geom_line(aes(y = st, color = "rate"), lwd = 1) +
  geom_line(aes(y = st.emv, color = "emv.exp"), lwd = 1, lty = 4) +
  scale_color_manual(
    values = c("rate" = "black", "emv.exp" = "red"),
    labels = c(bquote(alpha == .(rate)), bquote(hat(alpha) == .(emv.exp)))
  ) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Parâmetro") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

#### Distribuição Weibull

Para a estimação de parâmetros do modelo Weibull. Necessita-se da aplicação do método numérico de Newton-Raphson descrito na @sec-Dists. Tal método requer o cálculo das derivadas parciais e de segunda ordem em relação ao vetor de parâmetros $\theta = (\gamma, \alpha)$, permitindo ajustar o modelo aos dados observados de tempos de sobrevivência de forma precisa e eficiente.

Para o modelo Weibull será apresentada duas formas de implementar o método. A primeira é a construção braçal do algoritmo, que consiste na definição e cálculo explícito das funções necessárias, como a função de log-verossimilhança, o gradiente e a Hessiana. A segunda é utilizar a função de otimização `optim`, já implementadas na linguagem de programação **R**. Está função automatiza o processo de otimização e oferece uma implementação flexível e eficiente. Para os demais modelos probabilísticos será usado apenas a função de otimização `optim` do **R**.

Começando com a implementação sem uso da função de otimização, deve-se primeiramente, encontrar log-verossimilhança, o gradiente e a Hessiana. Pode-se definir a função de verossimilhança para distribuição Weibul usando a @eq-verossilGeneric, substituindo a função densidade e a função de sobrevivência da distribuição Weibull especificadas na @sec-DistWeibull. Portanto:

$$
L(\theta) = \prod_{i = 1}^{n} \left[ \dfrac{ \gamma }{ \alpha^{\gamma} } t^{\gamma - 1} \exp \left\{ - \left( \dfrac{t}{\alpha} \right)^{\gamma} \right\} \right]^{\delta_{i}} \left[ \exp \left\{ - \left( \dfrac{t}{\alpha} \right)^{\gamma} \right\} \right]^{1 - \delta_{i}}.
$$ {#eq-loglikelihoodWeibull}

\noindent Toma-se o logaritmo natural de $L(\gamma, \alpha)$, logo:

```{=latex}
\begin{align*}
    \ln[L(\gamma, \alpha)] & = \sum_{i = 1}^{n} \delta_{i} \ln[\gamma] - \sum_{i = 1}^{n} \delta_{i} \gamma \ln[\alpha] + \sum_{i = 1}^{n} \delta_{i} (\gamma - 1) \ln[t_{i}] + \sum_{i = 1}^{n} - (\alpha^{-1} t_{i})^{\gamma} \\
    & = \ln[\gamma] \sum_{i = 1}^{n} \delta_{i} - \gamma \ln[\alpha] \sum_{i = 1}^{n} \delta_{i} + (\gamma - 1) \sum_{i = 1}^{n} \delta_{i} \ln[t_{i}] + \sum_{i = 1}^{n} - (\alpha^{-1} t_{i})^{\gamma}.
\end{align*}
```

\noindent Aplicando as derivadas de primeira ordem em relação a $\gamma$ e $\alpha$, temos:

$$
\dfrac{\partial \ln[L(\gamma, \alpha)]}{\partial \gamma} = \dfrac{1}{\gamma} \sum_{i = 1}^{n} \delta_{i} - \ln[\alpha] \sum_{i = 1}^{n} \delta_{i} + \sum_{i = 1}^{n} \delta_{i} \ln[t_{i}] - \sum_{i = 1}^{n} (\alpha^{-1} t_{i})^{\gamma} \ln[\alpha^{-1} t_{i}]
$$

\noindent e

$$
\dfrac{\partial \ln[L (\gamma, \alpha)]}{\partial \alpha} = - \dfrac{\gamma}{\alpha} \sum_{i = 1}^{n} \delta_{i} + \gamma \alpha^{-\gamma - 1} \sum_{i = 1}^{n} t_{i}^{\gamma}.
$$

\noindent Toma-se agora as derivadas de segunda ordem.

$$
\dfrac{\partial^{2} \ln[L (\gamma, \alpha)]}{\partial \gamma^{2}} =  - \dfrac{1}{\gamma^{2}} \sum_{i = 1}^{n} \delta_{i} - \sum_{i = 1}^{n} (\alpha^{-1} t_{i})^{\gamma} (\ln[\alpha^{-1} t_{i}])^{2},
$$

$$
\dfrac{\partial^{2} \ln [L(\gamma, \alpha)]}{\partial \alpha^{2}} = - \dfrac{\gamma}{\alpha^{2}} \sum_{i = 1}^{n} \delta_{i} - \gamma (\gamma + 1) \alpha^{-\gamma - 2} \sum_{i = 1}^{n} t_{i}^{\gamma}
$$

\noindent e

$$
\dfrac{\partial^{2} \ln[L(\gamma, \alpha)]}{\partial \gamma \partial \alpha} = \dfrac{\partial^{2} \ln[L(\gamma, \alpha)]}{\partial \alpha \partial \gamma} = - \dfrac{1}{\alpha} \sum_{i = 1}^{n} \delta_{i} + \alpha^{- \gamma - 1} \sum_{i = 1}^{n} t_{i}^{\gamma} \left( \gamma \ln\left[ \dfrac{t_{i}}{\alpha} \right] + 1 \right)
$$

Com todas as derivadas definidas, pode-se construir o algoritmo iterativo de Newton-Raphson. Tirou-se uma amostra de uma $Weibull(2; 1,5)$. As estimativas obtidas foram as seguintes.

```{r message=FALSE, warning=FALSE}
# ------------------
# [2] MODELO WEIBULL
# ------------------

# Função de sobrevivência
survival.weib <- function(times,shape.par,scale.par) 1 - pweibull(q=times, shape=shape.par, scale=scale.par)

# ---------------------------
# [2.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
shape.weib <- 2     # Parâmetro de forma
scale.weib <- 1.5   # Parâmetro de escala

# Simulação dos dados
times <- rweibull(n, shape.weib, scale.weib)

# ----------------------------------------------
# [2.1.1] IMPLEMENTAÇÃO SEM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Vetor gradiente
GRADIEN <- function(times, theta) {
  # Número de observações
  n <- length(times)
  
  # Distição dos parâmetros
  gamma <- theta[1] # Parâmetro de forma
  alpha <- theta[2] # Parâmetro de escala
  
  # Ajutes de variáveis
  t <- times
  
  # Derivadas Parciais
  DerivGamma <- n/gamma - log(alpha)*n + sum(log(t)) - sum(((t/alpha)^gamma)*log(t/alpha))
  DerivAlpha <- -(gamma/alpha)*n + gamma*(alpha^(-gamma-1))*sum(t^gamma)
  
  # Vetor Gradiente
  gradient <- c(DerivGamma, DerivAlpha)
  
  # Retornar
  return(gradient)
}

# Matriz Hessiana
HESSIAN <- function(times, theta) {
  # Número de observações
  n <- length(times)
  
  # Distição dos parâmetros
  gamma <- theta[1] # Parâmetro de forma
  alpha <- theta[2] # Parâmetro de escala
  
  # Ajutes de variáveis
  t <- times
  
  # Derivadas de 2ª ordem
  D2Gamma <- - n/gamma^2 - sum(((t/alpha)^gamma)*(log(t/alpha)^2))
  D2Alpha <- - (gamma/alpha^2)*n - gamma*(gamma + 1)*(alpha^(-gamma-2))*sum(t^gamma)
  D2 <- -n*alpha + (alpha^(-gamma-1))*sum((t^gamma)*(gamma*log(t/alpha) + 1))
  
  # Matriz Hessiana
  H <- matrix(
    data = c(D2Gamma, D2, D2, D2Alpha),
    nrow = 2, ncol = 2
  )
  
  # Retornar
  return(H)
}

# Método Iterativo de Newton-Raphson
init <- c(1, 1)  # Chute Inicial
diff <- 1        # Diferença entre o passo atual e o passo anterior
error <- 10^(-8) # Erro tolerável
id <- 1          # Contador da iteração

# Iteração
while (diff > error) {
  # Vetor Gradiente e Matriz Hessiana
  U <- GRADIEN(times = times, theta = init) # Vetor Gradiente
  H <- HESSIAN(times = times, theta = init) # Matriz Hessiana
  
  # Solução do sistema linear H %*% solution = U
  solution <- solve(H, U)
  
  # Atualização do Algoritmo
  ajust <- init - solution
  
  # Diferença entre os parâmetros
  diff <- max(abs(ajust - init))
  
  # Imprimir resultados na tela
  #cat("Iteração:", id, " -  Estimativa = (Forma:", ajust[1], ", Escala:", ajust[2], ") \n")
  
  # Controle do Algoritmo
  init <- ajust
  id <- id + 1
}

# Impressão de resultados
cat("Número de Iterações Necessárias:", id, "\n")
cat("Estimativa para o parâmetro de forma:", ajust[1], "\n")
cat("Estimativa para o parâmetro de forma:", ajust[2], "\n")
```

O mesmo resultado, ou bem próximo, pode ser obtido de uma forma mais direta por meio do uso da função `optim` para otimização. Veja a saída obtida de tal função.

```{r message=FALSE, warning=FALSE}
# ----------------------------------------------
# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.weib <- function(times, theta) {
  # Distição dos parâmetros
  gamma <- theta[1] # Parâmetro de forma
  alpha <- theta[2] # Parâmetro de escala
  
  # Ajutes de variáveis
  t <- times
  c <- rep(1, length(t))
  
  # Função Log-verossimilhança
  ft <- dweibull(x = t, gamma, alpha)
  st <- 1 - pweibull(q = t, gamma, alpha)
  flv <- sum(c * log(ft) + (1 - c) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- c(1, 1)

# Otimização
ajust <- optim(
  par = init, fn = loglikelihood.weib,
  method = "BFGS", hessian = TRUE, times = times
)

# Visualização
ajust
```

Assim como para distribuição exponencial, será feita uma comparação entre o real e estimado. Veja a @tbl-EMVweibullSt que mostra as dez observações, na ordem de simulação, e suas respectivas funções de sobrevivência, real e estimada.

```{r, message=FALSE, warning=FALSE}
#| tbl-cap: "Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Weibull."
#| label: tbl-EMVweibullSt
#| tbl-cap-location: top

# Organização dos dados
dados.weib <- data.frame(
  times = times,
  st = survival.weib(times, shape.weib, scale.weib),
  st.emv = survival.weib(times, ajust$par[1], ajust$par[2])
)

library(knitr)

knitr::kable(
  round(head(dados.weib, 10), 4), 
  col.names = c("Tempo", "$S(t)$", "$\\hat{S}_{EMV}(t)$"),
  escape = FALSE,
  align = 'c',
  booktabs = TRUE
)
```

Também foi feita a comparação entre as duas curvas de sobrevivência, ilustradas na @fig-CompEMVWeibull.

```{r, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Weibull."
#| label: fig-CompEMVWeibull
#| fig-cap-location: top

# Organização dos dados
dados.weib <- data.frame(
  times = sort(times),
  st = survival.weib(sort(times), shape.weib, scale.weib),
  st.emv = survival.weib(sort(times), ajust$par[1], ajust$par[2])
)

# Plot da função de sobrevivência
ggplot(dados.weib, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  scale_color_manual(
    values = c("Verdadeiro" = "black", "EMV" = "red"),
    labels = c(
      bquote("Verdadeiro: " ~ gamma == .(shape.weib) ~ ";" ~ alpha == .(scale.weib)),
      bquote("EMV: " ~ hat(gamma) == .(ajust$par[1]) ~ ";" ~ hat(alpha) == .(ajust$par[2]))
    )
  ) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Parâmetro") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

#### Distribuição Log-normal

Para a estimação dos parâmetros do modelo log-normal deve-se, também, utilizar o método numérico de Newton-Raphson. Logo, utilizaremos o método para maximar a seguinte função:

$$
L(\theta) = \prod_{i = 1}^{n} \left[ \dfrac{1}{t_{i} \sigma \sqrt{2 \pi}} \exp \left\{- \dfrac{1}{2} \left(\dfrac{\ln(t_{i}) - \mu}{\sigma}\right)^{2} \right\} \right]^{\delta_{i}} \left[ \Phi \left( \dfrac{- \ln(t_{i}) + \mu}{\sigma} \right) \right]^{1 - \delta_{i}}.
$$ {#eq-loglikelihoodLognormal}

Foi simulada uma amostra oriunda de uma distribuição log-normal com parâmetro de locação $\mu = 0$ e parâmetro de escala $\sigma^{2} = 1$ e, a partir dessa amostra, obteve-se a estimativa de máxima verossimilhança para o parâmetro $\theta = (\mu, \sigma^{2})$. Veja a @tbl-EMVlnormSt, que apresenta as dez observações com as funções de sobrevivência real e estimada.

```{r, message=FALSE, warning=FALSE}
# ---------------------
# [3] MODELO LOG-NORMAL
# ---------------------

# Função de sobrevivência
survival.lnorm <- function(times, loc.par, scale.par) 1 - pnorm(q=(log(times)-loc.par)/scale.par)

# ---------------------------
# [3.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
mu <- 0             # Parâmetro de locação
sigma <- 1          # Parâmetro de escala

# Simulação dos dados
times <- rlnorm(n, meanlog = mu, sdlog = sigma)

# ----------------------------------------------
# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.lnorm <- function(times, theta) {
  # Distição dos parâmetros
  mu <- theta[1] # Parâmetro de locação
  sigma <- theta[2] # Parâmetro de escala
  
  # Ajutes de variáveis
  t <- times
  c <- rep(1, length(t))
  
  # Função Log-verossimilhança
  ft <- dlnorm(x = t, mu, sigma)
  st <- 1 - pnorm(q=(log(t) - mu) / sigma)
  flv <- sum(c * log(ft) + (1 - c) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- c(1, 0.5)

# Otimização
ajust <- optim(
  par = init, fn = loglikelihood.lnorm,
  method = "BFGS", hessian = TRUE, times = times
)

# Visualização
ajust
```

```{r, message=FALSE, warning=FALSE}
#| tbl-cap: "Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Log-normal."
#| label: tbl-EMVlnormSt
#| tbl-cap-location: top

# Organização dos dados
dados.lnorm <- data.frame(
  times = times,
  st = survival.lnorm(times, mu, sigma),
  st.emv = survival.lnorm(times, ajust$par[1], ajust$par[2])
)

library(knitr)

knitr::kable(
  round(head(dados.lnorm, 10), 4), 
  col.names = c("Tempo", "$S(t)$", "$\\hat{S}_{EMV}(t)$"),
  escape = FALSE,
  align = "c",
  booktabs = TRUE
)
```

Para uma visualização gráfica da otimização, foi criada a @fig-CompEMVlnorm.

```{r, message=FALSE, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Log-normal."
#| label: fig-CompEMVlnorm
#| fig-cap-location: top

# ------------------------------------
# [1.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE
# ------------------------------------

# Organização dos dados
dados.lnorm <- data.frame(
  times = sort(times),
  st = survival.lnorm(sort(times), mu, sigma),
  st.emv = survival.lnorm(sort(times), ajust$par[1], ajust$par[2])
)

# Plot da função de sobrevivência
ggplot(dados.lnorm, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  scale_color_manual(
    values = c("Verdadeiro" = "black", "EMV" = "red"),
    labels = c(
      bquote("Verdadeiro: " ~ mu == .(mu) ~ ";" ~ sigma == .(sigma)),
      bquote("EMV: " ~ hat(mu) == .(ajust$par[1]) ~ ";" ~ hat(sigma) == .(ajust$par[2]))
    )
  ) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Parâmetro") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

#### Distribuição Exponencial por Partes

Assim como para as distribuições Weibull e log-normal, será aplicado o método iterativo de Newton-Raphson. Porém, para a implementação do modelo exponencial por partes será usado o pacote `eha`. Esse pacote contém uma vasta quantidade de funções e implementações de modelos *Hazard Constant* (Risco Constante). Os parâmetros escolhidos para simulação dos dados foram: $\boldsymbol{\tau} = (0,4; 1,2; 1,8)$ e $\boldsymbol{\lambda} = (0,5; 1; 1,5; 2)$. Salientando que os parâmetros estimados serão apenas o vetor do parâmetro de taxas. Veja, abaixo, o ajuste do modelo através da maximização da seguinte função:

$$
L(\theta) = \prod_{i = 1}^{n} \left[ ... \right]^{\delta_{i}} \left[ ... \right]^{1 - \delta_{i}}.
$$ {#eq-loglikelihoodPiecewiseExponential}

```{r, message=FALSE, warning=FALSE}
# ---------------------------------
# [4] MODELO EXPONENCIAL POR PARTES
# ---------------------------------

# Função de sobrevivência
survival.pch <- function(times, cuts.points, levels.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)

# ---------------------------
# [3.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
rates <- c(0.5, 1, 1.5, 2) # Parâmetro de escala
breaks <- c(0.4, 1.2, 1.8) # Pontos de corte

# Simulação dos dados
times <- rpch(n, cuts = breaks, levels = rates)

# ----------------------------------------------
# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.pch <- function(par, times, cuts.points) {
  # Ajutes de variáveis
  t <- times
  c <- rep(1, length(t))
  
  # Função Log-verossimilhança
  ft <- dpch(x = times, cuts = cuts.points, levels = par)
  st <- 1 - ppch(q = times, cuts = cuts.points, levels = par)
  flv <- sum(c * log(ft) + (1 - c) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- rep(1, length(rates))

# Otimização
ajust <- optim(par=init, fn = loglikelihood.pch, 
               gr = NULL, method = "BFGS", hessian = TRUE, 
               times=times, cuts.points=breaks)

# Visualização
ajust
```

De forma semelhante aos demais modelos, será feita uma comparação da função de sobrevivência por meio da @tbl-EMVphcSt e @fig-CompEMVphc. Mostradas a seguir.

```{r, message=FALSE, warning=FALSE}
#| tbl-cap: "Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Exponencial por Partes."
#| label: tbl-EMVphcSt
#| tbl-cap-location: top

# Organização dos dados
dados.pch <- data.frame(
  times = times,
  st = survival.pch(times, breaks, rates),
  st.emv = survival.pch(times, breaks, ajust$par)
)

library(knitr)

knitr::kable(
  round(head(dados.pch, 10), 4), 
  col.names = c("Tempo", "$S(t)$", "$\\hat{S}_{EMV}(t)$"),
  escape = FALSE,
  align = "c",
  booktabs = TRUE
)
```

```{r, message=FALSE, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes."
#| label: fig-CompEMVphc
#| fig-cap-location: top

# ------------------------------------
# [1.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE
# ------------------------------------

# Organização dos dados
dados.pch <- data.frame(
  times = sort(times),
  st = survival.pch(sort(times), breaks, rates),
  st.emv = survival.pch(sort(times), breaks, ajust$par)
)

# Plot da função de sobrevivência
ggplot(dados.pch, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  scale_color_manual(
    values = c("Verdadeiro" = "black", "EMV" = "red"),
  ) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Parâmetro") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```


#### Distribuição Exponencial por Partes de Potência

Assim como para as distribuições anteriores, com excessão da distribuição exponencial clássica, o modelo exponencial por partes de potência requer a utilização do método numérico descrito na @sec-NewtonRaphson. Para simulação dos dados foi usado como pontos de corte $\boldsymbol{\tau} = (0,4; 1,2; 1,8)$, parâmetros de taxa $\boldsymbol{\lambda} = (0,5; 1; 1,5; 2)$ e parâmetro de potência $\eta = 3/2$. As estimativas são obtidas maximizando a função:

$$
L(\theta) = \prod_{i = 1}^{n} \left[ ... \right]^{\delta_{i}} \left[ ... \right]^{1 - \delta_{i}}.
$$ {#eq-loglikelihoodPiecewiseExponential}

```{r, message=FALSE, warning=FALSE}
# ---------------------------------------------
# [5] MODELO EXPONENCIAL POR PARTES DE POTÊNCIA
# ---------------------------------------------

# Função de sobrevivência
survival.pchp <- function(times, cuts.points, levels.par, power.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)^power.par

# ---------------------------
# [3.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
rates <- c(0.5, 1, 1.5, 2) # Parâmetros de taxa
breaks <- c(0.4, 1.2, 1.8) # Pontos de corte
power <- 3/2

# Funções de Simulação
time <- function(t, cuts.points=cuts.points, rates.par=rates.par, power.par=power.par, u.unif) {
  surv <- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par
  return(surv - u.unif)
}

gen.pchp <- function(n, cuts.points, rates.par, power.par) {
  # Vetor para armazenar os tempos gerados
  pchp.times <- numeric(n)
  
  for (i in 1:n) {
    # Gerando um único valor de U para cada iteração
    u <- runif(1)
    
    # Encontrando a raiz para cada observação
    raiz <- uniroot(
      time, interval = c(0, 10000), cuts.points = cuts.points, 
      rates.par = rates.par, power.par = power.par, u.unif = u
    )
    
    pchp.times[i] <- raiz$root
  }
  
  return(pchp.times)
}

# Simulação dos dados
times <- gen.pchp(n, cuts.points = breaks, rates.par = rates, power.par = power)

# ----------------------------------------------
# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.pchp <- function(par, times, cuts.points) {
  # Ajuste de Parâmetros
  n.par <- length(par)
  n.cuts <- length(cuts.points)
  rates.par <- par[1:(n.cuts + 1)]
  power.par <- par[n.par]
  
  # Ajutes de variáveis
  t <- times
  c <- rep(1, length(t))
  
  # Função Log-verossimilhança
  ft <- power.par*(ppch(q=t, cuts=cuts.points, levels=rates.par))^(power.par-1)*dpch(x=t, cuts=cuts.points, levels=rates.par)
  st <- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par
  flv <- sum(c * log(ft) + (1 - c) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- rep(1, length(rates) + 1)

# Otimização
ajust <- optim(par=init, fn = loglikelihood.pchp, 
               gr = NULL, method = "BFGS", hessian = TRUE, 
               times=times, cuts.points=breaks)

# Visualização
ajust
```

Veja a @tbl-EMVphcpSt e a @fig-CompEMVphcp, que apresenta uma comparação da função de sobrevivência real e estimada.

```{r, message=FALSE, warning=FALSE}
#| tbl-cap: "Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Exponencial por Partes de Potência."
#| label: tbl-EMVphcpSt
#| tbl-cap-location: top

# Organização dos dados
dados.pchp <- data.frame(
  times = times,
  st = survival.pchp(times, breaks, rates, power),
  st.emv = survival.pchp(times, breaks, ajust$par[1:(length(ajust$par)-1)], ajust$par[length(ajust$par)])
)

library(knitr)

knitr::kable(
  round(head(dados.pchp, 10), 4), 
  col.names = c("Tempo", "$S(t)$", "$\\hat{S}_{EMV}(t)$"),
  escape = FALSE,
  align = "c",
  booktabs = TRUE
)
```

```{r, message=FALSE, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes de Potência."
#| label: fig-CompEMVphcp
#| fig-cap-location: top

# ------------------------------------
# [1.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE
# ------------------------------------

# Organização dos dados
dados.pchp <- data.frame(
  times = sort(times),
  st = survival.pchp(sort(times), breaks, rates, power),
  st.emv = survival.pchp(sort(times), breaks, ajust$par[1:(length(ajust$par)-1)], ajust$par[length(ajust$par)])
)

# Plot da função de sobrevivência
ggplot(dados.pchp, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  scale_color_manual(
    values = c("Verdadeiro" = "black", "EMV" = "red"),
  ) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Parâmetro") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

### Aplicações Caso Haja Censura

Para exemplicação de ajustes dos modelos probabilísticos que foram propostos aqui à dados censurados, fixamos que os dados censurados como dados provenientes de uma distribuição exponencial com parâmetro de taxa $\alpha = 1$. Isto é, seja $C$ uma variável aleatória, que representa os tempos de eventos censurados,  tal quer $C \sim Exp(1)$. 

Já a distribuição do tempo de evento, de fato, foi variada entre os modelos aqui propostos, logo, foram simulados tempos de evento segundo os modelos: $Weibull(2; 1,5)$, $Lognormal(1, 2^{2})$, $EP()$ e $EPP()$. Os tempos observados foram definidos de forma que, para cada unidade amostral, o tempo observado foi definido como a menor realização entre as duas distribuições em análise, ou seja: 

$$t_{i} = min(T_{i}, C_{i}).$$

A censura ocorre quando o tempo de observação não corresponde ao tempo real de falha, ou seja, quando $C_{i} < T_{i}$. Nesse caso, o evento de interesse não foi completamente observado, sendo conhecido apenas que o verdadeiro tempo de falha excede o valor registrado. Essa característica, fundamental na análise de sobrevivência, requer métodos estatísticos específicos para garantir inferências adequadas a partir de dados censurados.

Sanando uma possível dúvida, que possa surgir da parte do leitor. Foi fixada para distribuição dos tempos de evento censurados a distribuição exponencial sem qualquer motivo em especial. Tendo em vista que a distribuição dos tempos de evento censurados não está sendo analisada. O obejto desta seção é apenas mostrar como os tempos censurados interferem na precisão das estimativas.

#### Modelo Weibull

Iniciando as exemplificações com a implementação do modelo Weibull. Veja a saída do ajuste para a distribuição $Weibull(2; 1,5)$.

```{r, message=FALSE, warning=FALSE}
# ------------------
# [1] MODELO WEIBULL
# ------------------

# Função de sobrevivência
survival.weib <- function(times,shape.par,scale.par) 1 - pweibull(q=times, shape=shape.par, scale=scale.par)

# ---------------------------
# [1.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
shape.weib <- 2     # Parâmetro de forma
scale.weib <- 1.5   # Parâmetro de escala
rate.exp <- 1       # Parâmetro de taxa da exponencial (censura)

# Simulação dos dados
t <- rweibull(n, shape.weib, scale.weib) # Tempos de evento
c <- rexp(n, rate = rate.exp)            # Tempos censurados
times <- pmin(t, c)                      # Tempos observados
delta <- as.numeric(t <= c)              # Variável indicadora

# ----------------------------------------------
# [1.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.weib <- function(par, times, cens) {
  # Distição dos parâmetros
  gamma <- par[1] # Parâmetro de forma
  alpha <- par[2] # Parâmetro de escala
  
  # Função Log-verossimilhança
  ft <- dweibull(x = times, gamma, alpha)
  st <- 1 - pweibull(q = times, gamma, alpha)
  flv <- sum(cens * log(ft) + (1 - cens) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- c(1, 1)

# Otimização
ajust <- optim(
  par = init, fn = loglikelihood.weib, method = "BFGS", 
  hessian = TRUE, times = times, cens = delta
)

# Visualização
ajust
```

A seguir, uma visualização gráfica do ajuste ilustrada pela @fig-CompEMVWeibullcens.

```{r, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Weibull para Dados Censurados."
#| label: fig-CompEMVWeibullcens
#| fig-cap-location: top

# Estimador de Kaplan-Meier
#ekm <- survfit(Surv(times, delta)~1)

# Organização dos dados
dados.weib <- data.frame(
  times = sort(times),
  st = survival.weib(sort(times), shape.weib, scale.weib),
  #st.ekm = ekm$surv,
  st.emv = survival.weib(sort(times), ajust$par[1], ajust$par[2])
)

# Plot da função de sobrevivência
ggplot(dados.weib, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  #geom_line(aes(y = st.ekm, color = "KM"), lwd = 1, lty = 2) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  #scale_color_manual(values = c("Verdadeiro" = "black", "KM" = "blue", "EMV" = "red")) +
  scale_color_manual(values = c("Verdadeiro" = "black", "EMV" = "red")) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Sobrevida") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

#### Modelo Log-normal

A segunda implementação feita, foi do modelo log-normal. Veja a saída do ajuste para a distribuição $Lognormal(1, 2^{2})$.

```{r, message=FALSE, warning=FALSE}
# ---------------------
# [2] MODELO LOG-NORMAL
# ---------------------

# Função de sobrevivência
survival.lnorm <- function(times, loc.par, scale.par) 1 - pnorm(q=(log(times)-loc.par)/scale.par)

# ---------------------------
# [2.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
mu <- 1             # Parâmetro de locação
sigma <- 2          # Parâmetro de escala
rate.exp <- 1       # Parâmetro de taxa da exponencial (censura)

# Simulação dos dados
t <- rlnorm(n, meanlog = mu, sdlog = sigma) # Tempos de evento
c <- rexp(n, rate = rate.exp)               # Tempos censurados
times <- pmin(t, c)                         # Tempos observados
delta <- as.numeric(t <= c)                 # Variável indicadora

# ----------------------------------------------
# [2.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.lnorm <- function(par, times, cens) {
  # Distição dos parâmetros
  mu <- par[1] # Parâmetro de locação
  sigma <- par[2] # Parâmetro de escala
  
  # Função Log-verossimilhança
  ft <- dlnorm(x = times, mu, sigma)
  st <- 1 - pnorm(q=(log(times) - mu) / sigma)
  flv <- sum(cens * log(ft) + (1 - cens) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- c(0.5, 0.5)

# Otimização
ajust <- optim(
  par = init, fn = loglikelihood.lnorm, method = "BFGS", 
  hessian = TRUE, times = times, cens = delta
)

# Visualização
ajust
```

A seguir, uma visualização gráfica do ajuste ilustrada pela @fig-CompEMVlnormcens.

```{r, warning=FALSE}
#| fig-cap: "Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Log-normal para Dados Censurados."
#| label: fig-CompEMVlnormcens
#| fig-cap-location: top

# ------------------------------------
# [2.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE
# ------------------------------------

# Estimador de Kaplan-Meier
#ekm <- survfit(Surv(times, delta)~1)

# Organização dos dados
dados.lnorm <- data.frame(
  times = sort(times),
  st = survival.lnorm(sort(times), mu, sigma),
  #st.ekm = ekm$surv,
  st.emv = survival.lnorm(sort(times), ajust$par[1], ajust$par[2])
)

# Plot da função de sobrevivência
ggplot(dados.lnorm, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  #geom_line(aes(y = st.ekm, color = "KM"), lwd = 1, lty = 2) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  #scale_color_manual(values = c("Verdadeiro" = "black", "KM" = "blue", "EMV" = "red")) +
  scale_color_manual(values = c("Verdadeiro" = "black", "EMV" = "red")) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Sobrevida") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

#### Distribuição Exponencial por Partes

Fazendo uma implementação do modelo exponencial por partes para dados censurados. A saída do ajuste está logo abaixo para a distribuição $EP()$.

```{r, message=FALSE, warning=FALSE}
# ---------------------------------
# [3] MODELO EXPONENCIAL POR PARTES
# ---------------------------------

# Função de sobrevivência
survival.pch <- function(times, cuts.points, levels.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)

# ---------------------------
# [3.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
rates <- c(0.5, 1, 1.5, 2) # Parâmetro de escala
breaks <- c(0.4, 1.2, 1.8) # Pontos de corte
rate.exp <- 1       # Parâmetro de taxa da exponencial (censura)

# Simulação dos dados
t <- rpch(n, cuts = breaks, levels = rates) # Tempos de evento
c <- rexp(n, rate = rate.exp)               # Tempos censurados
times <- pmin(t, c)                         # Tempos observados
delta <- as.numeric(t <= c)                 # Variável indicadora

# ----------------------------------------------
# [3.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.pch <- function(par, times, cens, cuts.points) {
  
  # Função Log-verossimilhança
  ft <- dpch(x = times, cuts = cuts.points, levels = par)
  st <- 1 - ppch(q = times, cuts = cuts.points, levels = par)
  flv <- sum(cens * log(ft) + (1 - cens) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- rep(1, length(rates))

# Otimização
ajust <- optim(par=init, fn = loglikelihood.pch, 
               gr = NULL, method = "BFGS", hessian = TRUE, 
               times=times, cens=delta, cuts.points=breaks)

# Visualização
ajust
```

A @fig-CompEMVphccens mostra o ajuste de forma gráfica fazendo uma comparação de curvas de sobrevivência.

```{r, message=FALSE, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes para Dados Censurados."
#| label: fig-CompEMVphccens
#| fig-cap-location: top

# ------------------------------------
# [3.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE
# ------------------------------------

# Estimador de Kaplan-Meier
#ekm <- survfit(Surv(times, delta)~1)

# Organização dos dados
dados.pch <- data.frame(
  times = sort(times),
  st = survival.pch(sort(times), breaks, rates),
  #st.ekm = ekm$surv,
  st.emv = survival.pch(sort(times), breaks, ajust$par)
)

# Plot da função de sobrevivência
ggplot(dados.pch, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  #geom_line(aes(y = st.ekm, color = "KM"), lwd = 1, lty = 2) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  #scale_color_manual(values = c("Verdadeiro" = "black", "KM" = "blue", "EMV" = "red")) +
  scale_color_manual(values = c("Verdadeiro" = "black", "EMV" = "red")) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Sobrevida") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```


#### Distribuição Exponencial por Partes de Potência

Por fim, é apresentado o ajuste para a distribuição $EPP()$.

```{r, message=FALSE, warning=FALSE}
# ---------------------------------------------
# [4] MODELO EXPONENCIAL POR PARTES DE POTÊNCIA
# ---------------------------------------------

# Função de sobrevivência
survival.pchp <- function(times, cuts.points, levels.par, power.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)^power.par

# ---------------------------
# [4.1] SIMULAÇÃO E ESTIMAÇÃO
# ---------------------------

# Parâmetros de simulação
set.seed(123456789) # Semente aleatória
n <- 1000           # Tamanho amostral
rates <- c(0.5, 1, 1.5, 2) # Parâmetros de taxa
breaks <- c(0.4, 1.2, 1.8) # Pontos de corte
power <- 3/2               # Parâmetro de potência
rate.exp <- 1             # Parâmetro de taxa da exponencial (censura)

# Funções de Simulação
time <- function(t, cuts.points=cuts.points, rates.par=rates.par, power.par=power.par, u.unif) {
  surv <- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par
  return(surv - u.unif)
}

gen.pchp <- function(n, cuts.points, rates.par, power.par) {
  # Vetor para armazenar os tempos gerados
  pchp.times <- numeric(n)
  
  for (i in 1:n) {
    # Gerando um único valor de U para cada iteração
    u <- runif(1)
    
    # Encontrando a raiz para cada observação
    raiz <- uniroot(
      time, interval = c(0, 10000), cuts.points = cuts.points, 
      rates.par = rates.par, power.par = power.par, u.unif = u
    )
    
    pchp.times[i] <- raiz$root
  }
  
  return(pchp.times)
}

# Simulação dos dados
t <- gen.pchp(n, cuts.points=breaks, rates.par=rates, power.par=power) # Tempos de evento
c <- rexp(n, rate = rate.exp)               # Tempos censurados
times <- pmin(t, c)                         # Tempos observados
delta <- as.numeric(t <= c)                 # Variável indicadora

# ----------------------------------------------
# [4.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO
# ----------------------------------------------

# Definir a função log-verossimilhança
loglikelihood.pchp <- function(par, times, cens, cuts.points) {
  # Ajuste de Parâmetros
  n.par <- length(par)
  n.cuts <- length(cuts.points)
  rates.par <- par[1:(n.cuts + 1)]
  power.par <- par[n.par]
  
  # Ajutes de variáveis
  t <- times
  
  # Função Log-verossimilhança
  ft <- power.par*(ppch(q=t, cuts=cuts.points, levels=rates.par))^(power.par-1)*dpch(x=t, cuts=cuts.points, levels=rates.par)
  st <- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par
  flv <- sum(cens * log(ft) + (1 - cens) * log(st))
  
  # Retorna o valor simétrico
  return(-flv)
}

# Chute Inicial
init <- rep(1, length(rates) + 1)

# Otimização
ajust <- optim(par=init, fn = loglikelihood.pchp, 
               gr = NULL, method = "BFGS", hessian = TRUE, 
               times=times, cens=delta, cuts.points=breaks)

# Visualização
ajust
```

A seguir, tem-se a comparação das curvas de sobrevivência real e estimada, desenhada na @fig-CompEMVphcpcens, para os dados simulados com censura.

```{r, message=FALSE, warning=FALSE}
#| fig-cap: " Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes de Potência para Dados Censurados."
#| label: fig-CompEMVphcpcens
#| fig-cap-location: top

# ------------------------------------
# [4.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE
# ------------------------------------

# Estimador de Kaplan-Meier
#ekm <- survfit(Surv(times, delta)~1)

# Organização dos dados
dados.pchp <- data.frame(
  times = sort(times),
  st = survival.pchp(sort(times), breaks, rates, power),
  #st.ekm = ekm$surv,
  st.emv = survival.pchp(sort(times), breaks, ajust$par[1:(length(ajust$par)-1)], ajust$par[length(ajust$par)])
)

# Plot da função de sobrevivência
ggplot(dados.pchp, aes(x = times)) +
  geom_line(aes(y = st, color = "Verdadeiro"), lwd = 1) +
  #geom_line(aes(y = st.ekm, color = "KM"), lwd = 1, lty = 2) +
  geom_line(aes(y = st.emv, color = "EMV"), lwd = 1, lty = 4) +
  #scale_color_manual(values = c("Verdadeiro" = "black", "KM" = "blue", "EMV" = "red")) +
  scale_color_manual(values = c("Verdadeiro" = "black", "EMV" = "red")) +
  labs(x = "Tempo", y = "Probabilidade de Sobrevivência", color = "Sobrevida") +
  theme_minimal(base_size = 11) +
  theme(legend.position = "top")
```

::: progress
::: {.progress-bar style="width: 100%;"}
:::
:::