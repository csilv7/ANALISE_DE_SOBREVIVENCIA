[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise de Sobrevivência",
    "section": "",
    "text": "Prefácio\nEste é um projeto desenvolvido…",
    "crumbs": [
      "Prefácio"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html",
    "href": "CI_CONC_BASIC.html",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "",
    "text": "1.1 Introdução\nO objetivo deste capítulo inicial é apresentar alguns conceitos e fundamentos de uma das áreas da Estatística e Análise de Dados que mais se desenvolveram nas últimas duas décadas do século XX. Esse avanço foi impulsionado pela evolução das técnicas estatísticas aliada ao progresso computacional.\nNa Análise de Sobrevivência, a variável resposta é, em geral, o tempo até a ocorrência de um evento de interesse. Especificamente, essa área se concentra em modelar e compreender o tempo necessário para que um evento significativo ocorra, sendo este denominado tempo de falha. Como exemplo, Colosimo e Giolo (2006) mencionam casos como o tempo até a morte de um paciente, até a cura de uma doença ou até a recidiva de uma condição clínica.\nUma questão frequentemente levantada é: por que não utilizar outras técnicas estatísticas? Métodos tradicionais não são adequados para dados de sobrevivência devido a uma característica única: a censura. Esse conceito refere-se à observação parcial do tempo de falha, como ocorre quando o acompanhamento de um paciente é interrompido antes do evento de interesse. A censura, sendo um elemento essencial da Análise de Sobrevivência, caracteriza situações em que o tempo de falha real é desconhecido, sabendo-se apenas que ele excede determinado ponto.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html#tempo-de-falha",
    "href": "CI_CONC_BASIC.html#tempo-de-falha",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "1.2 Tempo de Falha",
    "text": "1.2 Tempo de Falha\nNa Análise de Sobrevivência, é fundamental estabelecer alguns pontos iniciais para o estudo. O primeiro deles é o tempo inicial do estudo, que deve ser claramente definido para garantir que os indivíduos sejam comparáveis no ponto de partida, diferenciando-se apenas pelas covariáveis medidas. Existem diversas maneiras de definir o tempo inicial, sendo o mais comum o tempo cronológico. Contudo, em áreas como Engenharia, outras métricas, como número de ciclos ou quilometragem, também podem ser utilizadas. Colosimo e Giolo (2006) apresentam exemplos práticos, como medidas de carga para equipamentos.\nOutro aspecto essencial é a definição do evento de interesse, frequentemente associado a falhas ou situações indesejáveis. Para garantir resultados consistentes, a definição do evento deve ser clara e objetiva. Um exemplo elucidativo é fornecido por Colosimo e Giolo (2006):\n\n“Em algumas situações, a definição de falha já é clara, como morte ou recidiva, mas em outras pode assumir termos ambíguos. Por exemplo, fabricantes de produtos alimentícios desejam saber o tempo de vida de seus produtos expostos em balcões frigoríficos de supermercados. O tempo de falha vai do momento de exposição (chegada ao supermercado) até o produto se tornar ‘inapropriado para consumo’. Esse evento deve ser claramente definido antes do início do estudo. Por exemplo, o produto é considerado inapropriado para consumo quando atinge uma concentração específica de microrganismos por \\(mm^{2}\\) de área.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html#censura",
    "href": "CI_CONC_BASIC.html#censura",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "1.3 Censura",
    "text": "1.3 Censura\nEstudos clínicos que tratam a resposta como uma variável temporal geralmente são prospectivos e de longa duração. No entanto, mesmo sendo extensos, esses estudos frequentemente se encerram antes que todos os indivíduos passem pelo evento de interesse.\nUma característica comum nesses estudos é a censura, que corresponde a observações incompletas ou parciais. Apesar disso, tais observações fornecem informações valiosas para a análise. Colosimo e Giolo (2006) destacam a relevância de incluir dados censurados na análise:\n\n“Ressalta-se que, mesmo censurados, todos os resultados provenientes de um estudo de sobrevivência devem ser incluídos na análise estatística. Duas razões justificam esse procedimento: (i) mesmo sendo incompletas, as observações censuradas fornecem informações sobre o tempo de vida dos pacientes; (ii) a exclusão das censuras no cálculo das estatísticas pode levar a conclusões enviesadas.”\n\nExistem três tipos principais de censura:\n\nCensura Tipo I: O estudo é encerrado após um período de tempo previamente definido.\nCensura Tipo II: O estudo termina quando um número específico de indivíduos passa pelo evento de interesse.\nCensura Aleatória: Ocorre quando um indivíduo é retirado do estudo antes do evento de interesse.\n\nA censura mais comum é a censura à direita, em que o evento ocorre após o tempo registrado. Entretanto, outros tipos de censura, como à esquerda e intervalar, também são possíveis.\nCensura à esquerda ocorre quando o evento já aconteceu antes do início da observação. Um exemplo é um estudo sobre a idade em que crianças aprendem a ler:\n\n“Quando os pesquisadores começaram a pesquisa, algumas crianças já sabiam ler e não se lembravam com que idade isso ocorreu, caracterizando observações censuradas à esquerda.”\n\nNo mesmo estudo, observa-se censura à direita para crianças que ainda não sabiam ler no momento da coleta de dados. Nesse caso, os tempos de vida são classificados como duplamente censurados (Turnbull 1974).\nA censura intervalar ocorre em estudos com visitas periódicas espaçadas, onde só se sabe que o evento ocorreu dentro de um intervalo de tempo. Quando o tempo de falha \\(T\\) é impreciso, considera-se que ele pertence a um intervalo \\(T \\in (L, U]\\), conhecido como sobrevivência intervalar. Casos especiais incluem tempos de falha exatos, em que \\(L = U\\), sendo \\(U = 0\\) para censura à direita e \\(L = 0\\) para censura à esquerda (Lindsey e Ryan 1998). Destaca-se a seguinte observação de Colosimo e Giolo (2006):\n\n“A presença de censura traz desafios para a análise estatística. A censura do Tipo II é, em princípio, mais tratável que os outros tipos, mas para situações simples, que raramente ocorrem em estudos clínicos (Lawless 1982). Na prática, utiliza-se resultados assintóticos para a análise dos dados de sobrevivência.”",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html#dados-truncados",
    "href": "CI_CONC_BASIC.html#dados-truncados",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "1.4 Dados Truncados",
    "text": "1.4 Dados Truncados\nO truncamento é uma característica de alguns estudos de sobrevivência que, muitas vezes, é confundida com a censura. Ele ocorre quando certos indivíduos são excluídos do estudo devido a uma condição específica. Nesse caso, os pacientes só são incluídos no acompanhamento após passarem por um determinado evento, em vez de serem acompanhados desde o início do processo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html#sec-ReprDados",
    "href": "CI_CONC_BASIC.html#sec-ReprDados",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "1.5 Representação dos Dados de Sobrevivência",
    "text": "1.5 Representação dos Dados de Sobrevivência\nConsidere uma amostra aleatória de tamanho \\(n\\). O \\(i\\)-ésimo indivíduo no estudo é geralmente representado pelo par \\((t_{i}, \\delta_{i})\\), onde \\(t_{i}\\) é o tempo de falha ou censura, indicado pela variável binária \\(\\delta_{i}\\), definida como:\n\\[\n\\delta_{i} = \\begin{cases}\n1, & \\text{se } t_{i} \\text{ é um tempo de falha} \\\\\n0, & \\text{se } t_{i} \\text{ é um tempo de censura}.\n\\end{cases}\n\\]\nPortanto, a variável resposta na análise de sobrevivência é representada por duas colunas no conjunto de dados. Se o estudo também incluir covariáveis, os dados são representados por \\((t_{i}, \\delta_{i}, \\mathbf{x}_{i})\\). Caso a censura seja intervalar, a representação é \\((l{i}, u_{i}, \\delta_{i}, \\mathbf{x}_{i})\\). Para exemplos de dados de sobrevivência, veja a Seção 1.5 do livro de Colosimo e Giolo (2006).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html#especificando-o-tempo-de-sobrevivência",
    "href": "CI_CONC_BASIC.html#especificando-o-tempo-de-sobrevivência",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "1.6 Especificando o Tempo de Sobrevivência",
    "text": "1.6 Especificando o Tempo de Sobrevivência\nSeja \\(T\\) uma variável aleatória (v.a.), na maioria dos casos contínua, que representa o tempo de falha. Assim, o suporte de \\(T\\) é definido nos reais positivos \\(\\mathbb{R}^{+}\\). Tal variável é geralmente representada pela sua função risco ou pela função de taxa de falha (ou taxa de risco). Tais funções, e outras relacionadas, são usadas ao longo do processo de análise de dados de sobrevivência. A seguir, algumas dessas funções e as relações entre elas serão definidas.\n\n1.6.1 Função de Sobrevivência\nEsta é uma das principais funções probabilísticas usadas em análise de sobrevivência. A função sobrevivência é definida como a probabilidade de uma observação não falhar até certo ponto \\(t\\), ou seja a probabilidade de uma observação sobreviver ao tempo \\(t\\). Em probabilidade, isso pode ser escrito como:\n\\[\nS(t) = P(T &gt; t),\n\\tag{1.1}\\]\numa conclusão a qual podemos chegar, é que a probabilidade de uma observação não sobreviver até o tempo \\(t\\), é a acumulada até o ponto \\(t\\), logo,\n\\[\nF(t) = 1 - S(t).\n\\tag{1.2}\\]\n\n\n1.6.2 Função de Taxa de Falha ou de Risco\nA probabilidade da falha ocorrer em um intervalo de tempo \\([t_{1}, t_{2})\\) pode ser expressa em termos da função de sobrevivência como: \\[S(t_{1}) - S(t_{2}).\\]\nA taxa de falha no intervalo \\([t_{1}, t_{2})\\) é definida como a probabilidade de que a falha ocorra neste intervalo, dado que não ocorreu antes de \\(t_{1}\\), dividida pelo comprimento do intervalo. Assim, a taxa de falha no intervalo \\([t_{1}, t_{2})\\) é expressa por \\[\\dfrac{S(t_{1}) - S(t_{2})}{(t_{2} - t_{1})S(t_{1})}.\\]\nDe forma geral, redefinindo o intervalo como \\([t, t + \\Delta t)\\) a expressão assume a seguinte forma:\n\\[\n\\lambda(t) = \\dfrac{S(t) - S(t + \\Delta_{t})}{\\Delta t \\text{ } S(t)}.\n\\]\nAssumindo \\(\\Delta t\\) bem pequeno, \\(\\lambda(t)\\) representa a taxa de falha instantânea no tempo \\(t\\) condicional à sobrevivência até o tempo \\(t\\). Observe que as taxas de falha são números positivos, mas sem limite superior. A função de taxa de falha \\(\\lambda(t)\\) é bastante útil para descrever a distribuição do tempo de vida de pacientes. Ela descreve a forma em que a taxa instantânea de falha muda com o tempo. A função de taxa de falha de \\(T\\) é, então, definida como:\n\\[\n\\lambda(t) = \\lim_{\\Delta t \\to 0} \\dfrac{P(t \\leq T \\leq t + \\Delta t | T \\geq t)}{\\Delta t}.\n\\tag{1.3}\\]\nA função de taxa de falha é mais informativa do que a função de sobrevivência. Diferentes funções de sobrevivência podem ter formas semelhantes, enquanto as respectivas funções de taxa de falha podem diferir drasticamente. Desta forma, a modelagem da função de taxa de falha é um importante método para dados de sobrevivência.\n\n\n1.6.3 Função de Taxa de Falha Acumulada\nOutra função útil em análise de dados de sobrevivência é a função taxa de falha acumulada. Esta função, como o próprio nome sugere, fornece a taxa de falha acumulada do indivíduo e é definida por:\n\\[\n\\Lambda(t) = \\int_{0}^{t} \\lambda(u) du.\n\\tag{1.4}\\]\nA função de taxa de falha acumulada, \\(\\Lambda(t)\\), não têm uma interpretação direta, mas pode ser útil na avaliação da função de maior interesse que é a função de taxa de falha, \\(\\lambda(t)\\). Isto acontece essencialmente na estimação não-paramétrica em que \\(\\Lambda(t)\\) apresenta um estimador com propriedades ótimas e \\(\\lambda(t)\\) é difícil de ser estimada.\n\n\n1.6.4 Tempo Médio e Vida Média Residual\nOutras duas quantidades de interesse em análise de sobrevivência são: o tempo médio de via e a vida média residual. A primeira é obtida pela área sob a função de sobrevivência. Isto é,\n\\[\nt_{m} = \\int_{0}^{\\infty} S(t) dt.\n\\tag{1.5}\\]\nJá a vida média residual é definida condicional a um certo tempo de vida \\(t\\). Ou seja, para indivíduos com idade \\(t\\) está quantidade mede o tempo médio restante de vida e é, então, a área sob a curva de sobrevivência à direita do tempo \\(t\\) dividida por \\(S(t)\\). Isto é,\n\\[\n\\text{vmr}(t) = \\dfrac{\\int_{0}^{\\infty} (u - t) f(u) du}{S(t)} = \\dfrac{\\int_{0}^{\\infty} S(u) du}{S(t)},\n\\tag{1.6}\\]\nsendo \\(f(\\cdot)\\) a função densidade de \\(T\\). Observe que \\(\\text{vmr}(0) = t_{m}\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CI_CONC_BASIC.html#relações-entre-as-funções",
    "href": "CI_CONC_BASIC.html#relações-entre-as-funções",
    "title": "1  Conceitos Básicos e Exemplos",
    "section": "1.7 Relações entre as Funções",
    "text": "1.7 Relações entre as Funções\nPara \\(T\\) uma variável aleatória contínua e não-negativa, tem-se, em termos das funções definidas anteriormente, algumas relações matemáticas importantes entre elas, a saber:\n\\[\n\\lambda(t) = \\dfrac{f(t)}{S(t)} = - \\dfrac{d}{dt} \\left[ \\log S(t) \\right],\n\\]\n\\[\n\\Lambda(t) = \\int_0^{t} \\lambda(u) du = - \\log S(t)\n\\]\ne\n\\[\nS(t) = \\exp \\left\\{ - \\Lambda(t) \\right\\} = \\exp \\left\\{ - \\int_0^{t} \\lambda(u) du \\right\\}\n\\]\nTais relações mostram que o conhecimento de uma das funções, por exemplo \\(S(t)\\), implica no conhecimento das demais, isto é, \\(F(t)\\), \\(f(t)\\), \\(\\lambda(t)\\) e \\(\\Lambda(t)\\). Outras relações envolvendo estas funções são as seguintes:\n\\[\nS(t) = \\dfrac{\\text{vmr}(0)}{\\text{vmr}(t)} \\exp \\left\\{ - \\int_{0}^{t} \\dfrac{du}{\\text{vmr}(u)} \\right\\}\n\\]\ne\n\\[\n\\lambda(t) = \\left( \\dfrac{d \\text{ } [\\text{vmr}(t)]}{dt} + 1 \\right) / \\text{vmr}(t).\n\\]\n\n\n\n\n\n\nColosimo, Enrico Antonio, e Suely Ruiz Giolo. 2006. Análise de Sobrevivência Aplicada. 1.ª ed. São Paulo, Brasil: Blucher.\n\n\nLawless, J. F. 1982. Statistical Models and Methods for Lifetime Data. Wiley Series em Probability e Statistics. New York: John Wiley & Sons.\n\n\nLindsey, Jane C., e Louise M. Ryan. 1998. «Methods for Interval-Censored Data». Statistics in Medicine 17 (2): 219–38. https://doi.org/10.1002/(SICI)1097-0258(19980130)17:2&lt;219::AID-SIM735&gt;3.0.CO;2-D.\n\n\nTurnbull, Bruce W. 1974. «Nonparametric Estimation of a Survivorship Function with Doubly Censored Data». Journal of the American Statistical Association 69 (345): 169–73. https://doi.org/10.1080/01621459.1974.10480146.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Conceitos Básicos e Exemplos</span>"
    ]
  },
  {
    "objectID": "CII_TEC_N_PARAM.html",
    "href": "CII_TEC_N_PARAM.html",
    "title": "2  Técnicas Não Paramétricas",
    "section": "",
    "text": "2.1 Introdução\nEste capítulo apresenta as técnicas não-paramétricas utilizadas para a análise de dados de sobrevivência. Essas técnicas são empregadas quando não se faz suposições sobre a forma específica da distribuição dos tempos de falha, sendo particularmente úteis para dados censurados.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Técnicas Não Paramétricas</span>"
    ]
  },
  {
    "objectID": "CII_TEC_N_PARAM.html#o-estimador-de-kaplan-meier",
    "href": "CII_TEC_N_PARAM.html#o-estimador-de-kaplan-meier",
    "title": "2  Técnicas Não Paramétricas",
    "section": "2.2 O Estimador de Kaplan-Meier",
    "text": "2.2 O Estimador de Kaplan-Meier\nProposto por Kaplan e Meier (1958). É um estimador não-paramétrico utilizado para estimar a função de sobrevivência, \\(S(t)\\). Tal estimador também é chamado de de estimador limite-produto. O Estimador de Kaplan-Meier é uma adaptação a \\(S(t)\\) empiríca que, na ausência de censura nos dados, é definida como:\n\\[\n\\hat{S}(t) = \\dfrac{\\text{nº de observações que não falharam até o tempo } t}{\\text{nº total de observações no estudo}}.\n\\]\n\\(\\hat{S}(t)\\) é uma função que tem um formato gráfico de escada com degraus nos tempos observados de falha de tamanho \\(1/n\\), onde \\(n\\) é o tamanho amostral.\nO processo utilizado até se obter a estimativa de Kaplan-Meier é um processo passo a passo, em que o próximo passo depende do anterior. De forma suscetível, para qualquer \\(t\\), \\(S(t)\\) pode ser escrito em termos de probabilidades condicionais. Suponha que existam \\(n\\) pacientes no estudo e \\(k (\\leq n)\\) falhas distintas nos tempos \\(t_{1} \\leq t_{2} \\leq \\cdots \\leq t_{k}\\). Considerando \\(S(t)\\) uma função discreta com probabilidade maior que zero somente nos tempos de falha \\(t_{j}\\), \\(j = 1, \\cdots, k\\), tem-se que:\n\\[\nS(t_{j}) = (1 - q_{1}) (1 - q_{2}) \\cdots (1 - q_{j}),\n\\tag{2.1}\\]\nem que \\(q_{j}\\) é a probabilidade de um indivíduo morrer no intervalo \\([t_{j-1}, t{j})\\) sabendo que ele não morreu até \\(t_{j-1}\\) e considerando \\(t_{0} = 0\\). Ou seja, pode se escrever \\(q_{j}\\) como:\n\\[\nq_{j} = P(T \\in [t_{j-1}, t_{j}) | T \\geq t_{j-1}),\n\\tag{2.2}\\]\npara \\(j = 1, \\cdots, k\\).\nA expressão geral do estimador de Kaplan-Meier pode ser apresentada após estas considerações preliminares, Formalmente, considere:\n\n\\(t_{1} \\leq t_{2} \\leq \\cdots \\leq t_{k}\\), os \\(k\\) tempos distintos e ordenados de falha;\n\\(d_{j}\\) o número de falhas em \\(t_{j}\\), \\(j = 1, \\cdots, k\\);\n\\(n_{j}\\) o número de indivíduos sob risco em \\(t_{j}\\), ou seja, os indivíduos que não falharam e não foram censurados até o instante imediatamente anterior a \\(t_{j}\\).\n\nCom isso, pode-se definir o estimador de Kaplan-Meier como:\n\\[\n\\hat{S}_{KM}(t) = \\prod_{j \\text{ : } t_{j} &lt; t} \\left( \\dfrac{n_{j} - d_{j}}{n_{j}} \\right) = \\prod_{j \\text{ : } t_{j} &lt; t} \\left( 1 - \\dfrac{d_{j}}{n_{j}} \\right)\n\\tag{2.3}\\]\nDe forma intuitiva, por assim dizer, a Equação 2.3 é proveniente da Equação 2.1, sendo está, uma decomposição de \\(S(t)\\) em termos \\(q_{j}\\)’s. Assim, a Equação 2.3 é justificada se os \\(q_{j}\\)’s forem estimados por \\(d_{j}/n_{j}\\), que em palavras está expresso na Equação 2.2. No artigo original de 1958, Kaplan e Meier provam que a Equação 2.3 é um Estimador de Máxima Verossimilhança (EMV) para \\(S(t)\\). Seguindo certos passos, é possível provar que que \\(\\hat{S}_{KM}(t)\\) é EMV de \\(S(t)\\). Supondo que \\(d_{j}\\) observações falham no tempo tempo \\(t_{j}\\), para \\(j = 1, \\cdots, k\\), e \\(m_{j}\\) observações são censuradas no intervalo \\([t_{j}, t_{j+1})\\), nos tempos \\(t_{j1}, \\ldots, t_{jm_{j}}\\). A probabilidade de falha no tempo \\(t_{j}\\) é, então,\n\\[\nS(t_{j}) - S(t_{j}+),\n\\]\ncom \\(S(t_{j}+) = \\lim_{\\Delta t \\to 0+} S(t_{j} + \\Delta t)\\), \\(j = 1, \\cdots, k\\). Por outro lado, a contribuição para a função de verossimilhança de um tempo de sobrevivência censurado em \\(t_{jl}\\) para \\(l = 1, \\ldots, m_{j}\\), é:\n\\[\nP(T &gt; t_{jl}) = S(t_{jl}+).\n\\]\nA função de verossimilhança pode, então, ser escrita como:\n\\[L(S(\\cdot)) = \\prod_{j = 0}^{k} \\left\\{ [ S(t_{j}) - S(t_{j}+) ]^{d_{j}} \\prod_{l = 1}^{m_{j}} S(t_{jl}+) \\right\\}.\\]\nCom isso, é possível provar que \\(S(t)\\) que maximiza \\(L(S(\\cdot))\\) é exatamente a expressão dada pela Equação 2.3.\n\n2.2.1 Propriedades do Estimador de Kaplan-Meier\nComo um estimador de máxima verossimilhança, o estimador de Kaplan-Meier têm interessantes propriedades. As principais são:\n\nÉ não-viciado para grandes amostras;\nÉ fracamente consistente;\nConverge assintoticamente para um processo gaussiano.\n\nA consistência e normalidade assintótica de \\(\\hat{S}_{KM}(t)\\) foram provadas sob certas condições de regularidade, por Breslow e Crowley (1974) e Meier (1975) e, no artigo original, Kaplan e Meier (1958) mostram que \\(\\hat{S}_{KM}(t)\\) é um EMV para \\(S(t)\\), como já dito.\n\n\n2.2.2 Variância do Estimador de Kaplan-Meier\nPara que se possa construir intervalos de confiança e testar hipóteses para \\(S(t)\\), se faz necessário ter conhecimento quanto variabilidade e precisão do estimador de Kaplan-Meier. Este estimador, assim como outros, está sujeito a variações que devem ser descritas em termos de estimações intervalares. A expressão da variância assintótica do estimador de Kaplan-Meier é dada pela Equação 2.4.\n\\[\n\\hat{Var}[\\hat{S}_{KM}(t)] = [\\hat{S}_{KM}(t)]^{2} \\sum_{j \\text{ : } t_{j} &lt; t} \\dfrac{d_{j}}{n_{j} (n_{j} - d_{j})}\n\\tag{2.4}\\]\nA expressão dada na Equação 2.4, é conhecida como fórmula de Greenwood e pode ser obtida a partir de propriedades do estimador de máxima verossimilhança. Os detalhes da obtenção da Equação 2.4 estão disponíveis em Kalbfleisch e Prentice (1980).\nComo \\(\\hat{S}_{KM}(t)\\), para um \\(t\\) fixo, tem distribuição assintóticamente Normal. O intervalo de confiança com \\(100(1 - \\alpha)\\)% de confiança para \\(\\hat{S}_{KM}(t)\\) é expresso por:\n\\[\n\\hat{S}_{KM}(t) \\pm z_{\\alpha/2} \\sqrt{\\hat{Var}[\\hat{S}_{KM}(t)]}.\n\\]\nVale salientar que para valores extremos de \\(t\\), este intervalo de confiança pode apresentar limites que não condizem com a teoria de probabilidades. Para solucionar tal problema, aplica-se uma transformação em \\(S(t)\\) como, por exemplo, \\(\\hat{U}(t) = \\log{[-\\log{(\\hat{S}_{KM}(t)})]}\\). Esta transformação foi sugerida por Kalbfleisch e Prentice (1980), tendo sua variância estimada por:\n\\[\n\\hat{Var}[\\hat{U}(t)] = \\dfrac{ \\sum_{j \\text{ : } t_{j} &lt; t} \\dfrac{d_{j}}{n_{j} (n_{j} - d_{j})} }{ \\left[\\sum_{j \\text{ : } t_{j} &lt; t} \\log{\\left( \\dfrac{n_{j} - d_{j}}{n_{j}} \\right)}\\right]^{2}} = \\dfrac{ \\sum_{j \\text{ : } t_{j} &lt; t} \\dfrac{d_{j}}{n_{j} (n_{j} - d_{j})} }{ \\left[ \\log{\\hat{S}_{KM}(t)} \\right]^{2} }\n\\]\nLogo, pode-se aproximar um intervalo com \\(100 (1 - \\alpha)\\%\\) de confiança para \\(S(t)\\) desta forma:\n\\[\n\\left[ \\hat{S}(t) \\right]^{ \\exp\\left\\{ \\pm z_{\\alpha / 2} \\sqrt{\\hat{Var}[\\hat{U}(t)]} \\right\\}}.\n\\]\nVeja uma aplicação do estimador de Kaplan-Meier para os dados de Leucemia Pediátrica dispostos no Apêndice (A) do livro Análise de Sobrevivência Aplicada de Colosimo e Giolo (2006). De posse do conjunto de dados, pode-se estimar a curva de sobrevivência, tal curva foi ilustrada na Figura 2.1.\n\n\nCódigo\n# -----------------------\n# [1] ATIVAÇÃO DE PACOTES\n# -----------------------\nlibrary(survival)\nlibrary(ggplot2)\n\n# ---------------------------------\n# [2] IMPORTAÇÃO E AJUSTE DOS DADOS\n# ---------------------------------\n\n# Caminho URL para os dados\nurl &lt;- \"https://docs.ufpr.br/~giolo/asa/dados/leucemia.txt\"\n\n# Leitura dos dados\ndados &lt;- read.table(url, header = TRUE)\n\n# -----------------------------\n# [3] ESTIMADOR DE KAPLAN-MEIER\n# -----------------------------\nekm &lt;- survfit(Surv(tempos, cens)~1, data = dados)\n\n# -----------------\n# [4] VISUALIZAÇÃO\n# -----------------\n\n# Preparando os dados para o ggplot2\nekm_data &lt;- data.frame(\n  time = ekm$time, survival = ekm$surv, \n  lower = ekm$lower, upper = ekm$upper\n)\n\n# Gráfico com ggplot2\nggplot(ekm_data, aes(x = time, y = survival)) +\n  geom_line(color = \"blue\", lwd = 1.2) +\n  geom_ribbon(aes(ymin = lower, ymax = upper), fill = \"blue\", alpha = 0.2) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\") +\n  theme_minimal(base_size = 10)\n\n\n\n\n\nFigura 2.1: Curva de Sobrevivência de Kaplan-Meier com IC de 95%",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Técnicas Não Paramétricas</span>"
    ]
  },
  {
    "objectID": "CII_TEC_N_PARAM.html#outros-estimadores-não-parâmetricos",
    "href": "CII_TEC_N_PARAM.html#outros-estimadores-não-parâmetricos",
    "title": "2  Técnicas Não Paramétricas",
    "section": "2.3 Outros Estimadores Não Parâmetricos",
    "text": "2.3 Outros Estimadores Não Parâmetricos\nO estimador de Kaplan-Meier é, indiscutivelmente, o mais utilizado para estimar \\(S(t)\\) em análises de sobrevivência. Ele é amplamente disponibilizado em diversos pacotes estatísticos e abordado em inúmeros textos de estatística básica. Entretanto, outros dois estimadores de \\(S(t)\\) também possuem relevância significativa na literatura especializada: o estimador de Nelson-Aalen e o estimador da tabela de vida.\nO estimador de Nelson-Aalen, mais recente que o de Kaplan-Meier, apresenta propriedades similares às deste último. Já o estimador da tabela de vida possui importância histórica, tendo sido utilizado em informações derivadas de censos demográficos para estimar características associadas ao tempo de vida humano. Este estimador foi inicialmente proposto por demógrafos e atuários no final do século XIX, sendo empregado principalmente em grandes amostras.\nNesta seção será abordado apenas o estimador de Nelson-Aalen. Para conhecer mais sobre o estimador da Tabela de Vida ou Tabela Atuarial, consulte a Seção 2.4.2 do livro Análise de Sobrevivência Aplicada de Colosimo e Giolo (2006).\n\n2.3.1 Estimador de Nelson-Aalen\nMais recente que o estimador de Kaplan-Meier, este estimador se baseia na função de sobrevivência expressa da seguinte forma:\n\\[\nS(t) = \\exp\\left\\{ - \\Lambda(t) \\right\\},\n\\]\nem que \\(\\Lambda(t)\\) é a função de risco acumulado apresentada na Seção 1.6.3.\nA estimativa para \\(\\Lambda(t)\\) foi inicialmente proposta por Nelson (1972) posteriormente retomada por Aalen (1978) que demonstrou suas propriedades assintóticas utilizando processos de contagem. Na literatura, esse estimador é amplamente conhecido como o estimador de Nelson-Aalen e é definido pela seguinte expressão:\n\\[\n\\hat{\\Lambda}(t) = \\sum_{j:t_{j} &lt; t} \\left( \\dfrac{d_{j}}{n_{j}} \\right),\n\\tag{2.5}\\]\nonde \\(d_{j}\\) e \\(n_{j}\\) são as mesmas definições usadas no estimador de Kaplan-Meier. A variância do estimador, conforme proposta por Aalen (1978), é dada por:\n\\[\n\\hat{Var}(\\hat{\\Lambda}(t)) = \\sum_{j:t_{j} &lt; t} \\left( \\dfrac{d_{j}}{n_{j}^{2}} \\right).\n\\tag{2.6}\\]\nUma alternativa para a estimativa da variância de \\(\\hat{\\Lambda}(t)\\), proposta por Klein (1991), é:\n\\[\n\\hat{Var}(\\hat{\\Lambda}(t)) = \\sum_{j:t_{j} &lt; t} \\dfrac{(n_{j} - d_{j})d_{j}}{n_{j}^{3}},\n\\]\nentretanto, o estimador da Equação 2.6 apresenta menor vício, tornando-o mais preferível que o proposto por Klein (1991).\nDesta forma, podemos definir, com base no estimador de Nelson-Aalen, um estimador para a função de sobrevivência, podendo ser expressa por:\n\\[\n\\hat{S}_{NA}(t) = \\exp\\left\\{- \\hat{\\Lambda}(t) \\right\\}.\n\\]\nDeve-se, a variância deste estimador, a Aalen e Johansen (1978). Podendo ser mensurada pela expressão:\n\\[\n\\hat{Var}(\\hat{S}_{NA}(t)) = \\left[ \\hat{S}_{NA}(t) \\right]^{2} \\sum_{j:t_{j} &lt; t} \\left( \\dfrac{d_{j}}{n_{j}^{2}} \\right)\n\\]\nVale destacar que o estimador de Nelson-Aalen apresenta, na maioria dos casos, estimativas próximas ao estimador de Kaplan-Meier. Bohoris (1994) mostrou que \\(\\hat{S}_{NA}(t) \\geq \\hat{S}_{KM}(t)\\) para todo \\(t\\), isto é, as estimativas obtidas pelo estimador de Nelson-Aalen são maiores ou iguais às estimativas obtidas pelo estimador de Kaplan-Meier.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Técnicas Não Paramétricas</span>"
    ]
  },
  {
    "objectID": "CII_TEC_N_PARAM.html#comparação-de-curvas-de-sobrevivência",
    "href": "CII_TEC_N_PARAM.html#comparação-de-curvas-de-sobrevivência",
    "title": "2  Técnicas Não Paramétricas",
    "section": "2.4 Comparação de Curvas de Sobrevivência",
    "text": "2.4 Comparação de Curvas de Sobrevivência\nConsidere um problema na área da saúde em que se deseja comparar dois grupos: um que receberá tratamento com uma determinada droga e outro que será o grupo controle. Estatísticas amplamente utilizadas para esse fim podem ser vistas como generalizações, para dados censurados, de testes não paramétricos bem conhecidos. Entre esses, o teste logrank (Mantel 1966) é o mais empregado em análises de sobrevivência. Gehan (1965) propôs uma generalização para a estatística de Wilcoxon. Outras generalizações foram introduzidas por autores como Peto e Peto (1972) e Prentice (1978), enquanto Latta (1981) utilizou simulações de Monte Carlo para comparar diversos testes não-paramétricos.\nNesta seção, será dada ênfase ao teste logrank, amplamente utilizado em análises de sobrevivência e particularmente adequado quando a razão entre as funções de risco dos grupos a serem comparados é aproximadamente constante. Ou seja, quando as populações apresentam a propriedade de riscos proporcionais.\nA estatística do teste logrank baseia-se na diferença entre o número observado de falhas em cada grupo e o número esperado de falhas sob a hipótese nula. Essa abordagem é semelhante à do teste de Mantel e Haenszel (1959), que combina tabelas de contingência. Além disso, o teste logrank possui a mesma expressão do teste de escore para o modelo de regressão de Cox.\nConsidere, inicialmente, o teste de igualdade entre duas funções de sobrevivência \\(S_{1}(t)\\) e \\(S_{2}(t)\\). Seja \\(t_{1} &lt; t_{2} &lt; \\ldots &lt; t_{k}\\) a sequência dos tempos de falha distintos observados na amostra combinada, formada pela união das duas amostras individuais. Suponha que, no tempo \\(t_{j}\\), ocorram \\(d_{j}\\) falhas e que \\(n_{j}\\) indivíduos estejam sob risco imediatamente antes de \\(t_{j}\\) na amostra combinada. Nas amostras individuais, as quantidades correspondentes são \\(d_{ij}\\) e \\(n_{ij}\\), onde \\(i = 1, 2\\) representa o grupo e \\(j = 1, \\cdots, k\\) indica o tempo de falha.\nNo tempo \\(t_{j}\\), os dados podem ser organizados em uma tabela de contingência \\(2 \\times 2\\), onde \\(d_{ij}\\) representa o número de falhas e \\(n_{ij} - d_{ij}\\) o número de sobreviventes em cada grupo \\(i\\). Essa disposição está ilustrada na Tabela 2.1.\n\n\n\n\nTabela 2.1: Tabela de contingência gerada no tempo \\(t_{j}\\).\n\n\n\n\n\n\n\nGrupo 1\nGrupo 2\n\n\n\n\n\nFalha\n\\(d_{1j}\\)\n\\(d_{2j}\\)\n\\(d_{j}\\)\n\n\nNão Falha\n\\(n_{1j} - d_{1j}\\)\n\\(n_{2j} - d_{2j}\\)\n\\(n_{j} - d_{j}\\)\n\n\n\n\\(n_{1j}\\)\n\\(n_{2j}\\)\n\\(n_{j}\\)\n\n\n\n\n\n\n\n\nCondicionado à ocorrência de falhas e censuras até o tempo \\(t_{j}\\) (fixando as marginais das colunas) e ao número total de falhas no tempo \\(t_{j}\\) (fixando as marginais das linhas), a distribuição de \\(d_{2j}\\) é, então, uma hipergeométrica:\n\\[\n\\dfrac{ \\binom{ n_{1j} }{ d_{1j} } \\binom{ n_{2j} }{ d_{2j} } }{ \\binom{ n_{j} }{ d_{j} } }.\n\\]\nA média de \\(d_{2j}\\) é dada por \\(w_{2j} = n_{2j} d_{j} n_{j}^{-1}\\). Isso significa que, na ausência de diferenças entre as duas populações no tempo \\(t_{j}\\), o número total de falhas (\\(d_{j}\\)) pode ser alocado entre as duas amostras proporcionalmente à razão entre o número de indivíduos sob risco em cada amostra e o número total sob risco.\nA variância de \\(d_{2j}\\) obtida a partir da distribuição hipergeométrica é:\n\\[\n(V_{j})_{2} = n_{2j}(n_{j} - n_{2j})d_{j}(n_{j} - d_{j}) n_{j}^{-2} (n_{j} - 1)^{-1}.\n\\]\nPortanto, a estatística \\(d_{2j} - w_{2j}\\) possui média zero e variância \\((V_{j})_{2}\\). Se as \\(k\\) tabelas de contingência forem independentes, um teste aproximado para avaliar a igualdade entre as duas funções de sobrevivência pode ser construído com base na seguinte estatística:\n\\[\nT = \\dfrac{ \\left[ \\sum_{j = 1}^{k} (d_{2j} - w_{2j}) \\right]^{2} }{ \\sum_{j = 1}^{k} (V_{j})_{2} },\n\\tag{2.7}\\]\nque, sob a hipótese nula \\(H_{0}: S_{1}(t) = S_{2}(t)\\) para todo \\(t\\) no período de acompanhamento, segue aproximadamente uma distribuição qui-quadrado com \\(1\\) grau de liberdade para amostras grandes.\nPara exemplificar a aplicação do teste de logrank em dados reais, utilizou-se o conjunto de dados sobre Leucemia Pediátrica, disponível no Apêndice (A) do livro Análise de Sobrevivência Aplicada de Colosimo e Giolo (2006). Esses mesmos dados foram usados para gerar a Figura 2.1. O objetivo do teste realizado foi avaliar se as curvas de sobrevivência das categorias da covariável r6 são iguais, com as seguintes hipóteses:\n\\[\n\\begin{cases}\n  H_{0}: \\text{As curvas de sobrevivência dos grupos são iguais ao longo do tempo} \\\\\n  H_{1}: \\text{As curvas de sobrevivência dos grupos são diferentes ao longo do tempo.}\n\\end{cases}\n\\]\nVeja a saída resultante do teste realizado no software R:\n\n\nCódigo\n# -----------------------\n# [1] ATIVAÇÃO DE PACOTES\n# -----------------------\nlibrary(survival)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# ----------------------------------\n# [2] IMPORTAÇÃO E AJUSTES DOS DADOS\n# ----------------------------------\n\n# Caminho URL para os dados\nurl &lt;- \"https://docs.ufpr.br/~giolo/asa/dados/leucemia.txt\"\n\n# Leitura dos dados\ndados &lt;- read.table(url, header = TRUE)\n\n# Decodificando a coluna r6\ndados &lt;- dados %&gt;%\n  mutate(grupo = ifelse(r6 == 0, \"Category Zero\", \"Category One\"))\n\n# --------------------\n# [3] TESTE DE LOGRANK\n# --------------------\n\n# Aplicando o Teste de Logrank\nTestLogrank &lt;- survdiff(Surv(tempos, cens) ~ grupo, data = dados, rho = 0)\nprint(TestLogrank)\n\n\nCall:\nsurvdiff(formula = Surv(tempos, cens) ~ grupo, data = dados, \n    rho = 0)\n\n                     N Observed Expected (O-E)^2/E (O-E)^2/V\ngrupo=Category One  95       34    37,16     0,269      5,73\ngrupo=Category Zero  8        5     1,84     5,429      5,73\n\n Chisq= 5,7  on 1 degrees of freedom, p= 0,02 \n\n\nAo fixar o nível de significância em 5% (\\(\\alpha = 0,05\\)), rejeitamos a hipótese nula. Essa conclusão baseia-se no valor \\(p\\) (probabilidade de significância) obtido no teste, calculado como \\(p-valor =\\) 0,0166. Como o \\(p-valor &lt; \\alpha\\), rejeita-se \\(H_{0}\\). Assim, conclui-se que as curvas de sobrevivência dos grupos são diferentes ao longo do tempo, ao nível de significância de 5%.\nA generalização do teste logrank para a comparação de \\(r &gt; 2\\) funções de sobrevivência, \\(S_{1}(t), S_{2}(t), \\ldots, S_{r}(t)\\), é direta. Utilizando a mesma notação anterior, o índice \\(i\\) varia agora de \\(1\\) a \\(r\\). Assim, os dados podem ser organizados em uma tabela de contingência \\(2 \\times r\\), onde cada coluna \\(i\\) contém \\(d_{ij}\\) falhas e \\(n_{ij} - d_{ij}\\) sobreviventes. Dessa forma, a Tabela 2.1 seria estendida para ter \\(r\\) colunas em vez de apenas duas.\nCondicionada à experiência de falha e censura até o tempo \\(t_{j}\\) e ao número total de falhas no tempo \\(t_{j}\\), a distribuição conjunta de \\(d_{2j}, \\ldots,d_{rj}\\) segue uma hipergeométrica multivariada, dada por:\n\\[\n\\dfrac{ \\prod_{i = 1}^{r} \\binom{ n_{ij }}{ d_{ij} } }{ \\binom{ n_{j }}{ d_{j} } }.\n\\]\nA média de \\(d_{ij}\\) é \\(w_{ij} = n_{ij} d_{j} n_{j}^{-1}\\), bem como a variância de \\(d_{ij}\\) e a covariância de \\(d_{ij}\\) e \\(d_{lj}\\) são, respectivamente,\n\\[\n(V_{j})_{ii} = n_{ij} (n_{j} - n_{ij}) d_{j} (n_{j} - d_{j}) n_{j}^{-2} (n_{j} - 1)^{-1}\n\\]\ne\n\\[\n(V_{j})_{il} = - n_{ij} n_{lj} d_{j} (n_{j} - d_{j}) n_{j}^{-2} (n_{j} - 1)^{-1}.\n\\]\nA estatística \\(v'_{j} = (d_{2j} - w_{2j}, \\ldots, d_{rj} - w_{rj})\\) possui média zero e matriz de variância-covariância \\(V_{j}\\), com dimensão \\(r - 1\\). A matriz \\(V_{j}\\) contém os termos \\((V_{j}){ii}\\) na diagonal principal e \\((V_{j})_{il}\\), \\(i,l = 2, \\ldots,r\\), fora da diagonal principal.\nA estatística \\(v\\), que agrega as contribuições de todos os tempos distintos de falha, é definida como:\n\\[\nv = \\sum_{j = 1}^{k} v_{j},\n\\]\nonde \\(v\\) é um vetor de dimensão \\((r - 1) \\times 1\\), cujos elementos correspondem às diferenças entre os totais observados e esperados de falhas.\nConsiderando, novamente, a independência das \\(k\\) tabelas de contingência, a variância de \\(v\\) é dada por \\(V = V_{1} + \\ldots + V_{k}\\). Um teste aproximado para a igualdade das \\(r\\) funções de sobrevivência pode ser baseado na estatística:\n\\[\nT = v´V^{-1} v,\n\\tag{2.8}\\]\nque, sob a hipótese nula \\(H_{0}\\) (igualdade das curvas de sobrevivência), segue uma distribuição qui-quadrado com \\(r - 1\\) graus de liberdade para amostras grandes. Os graus de liberdade são \\(r - 1\\) em vez de \\(r\\), pois os elementos de \\(v\\) somam zero.\nUma aplicação para a comparação de \\(r\\) curvas de sobrevivência…\n\n\nCódigo\ncat(\"Código em R a ser preenchido\")\n\n\nCódigo em R a ser preenchido\n\n\n\n2.4.1 Outros Testes\n[…]\n\n\n\n\n\n\nAalen, Odd O. 1978. «Nonparametric Inference for a Family of Counting Processes». Annals of Statistics 6 (4): 701–26. https://doi.org/10.1214/aos/1176344247.\n\n\nAalen, Odd O., e Søren Johansen. 1978. «An Empirical Transition Matrix for Non-Homogeneous Markov Chains Based on Censored Observations». Scandinavian Journal of Statistics 5 (3): 141–50.\n\n\nBohoris, G. A. 1994. «Comparison of the Cumulative-Hazard and Kaplan-Meier Estimators of the Survivor Function». IEEE Transactions on Reliability 43 (2): 230–32. https://doi.org/10.1109/24.293488.\n\n\nBreslow, Norman, e John Crowley. 1974. «A Large Sample Study of the Life Table and Product Limit Estimates under Random Censorship». The Annals of Statistics 2 (3): 437–53. https://doi.org/10.1214/aos/1176342705.\n\n\nColosimo, Enrico Antonio, e Suely Ruiz Giolo. 2006. Análise de Sobrevivência Aplicada. 1.ª ed. São Paulo, Brasil: Blucher.\n\n\nGehan, Edmund A. 1965. «A Generalized Wilcoxon Test for Comparing Arbitrarily Singly-Censored Samples». Biometrika 52 (1-2): 203–24. https://doi.org/10.2307/2333825.\n\n\nKalbfleisch, John D., e Ross L. Prentice. 1980. The Statistical Analysis of Failure Time Data. Wiley Series em Probability e Mathematical Statistics. New York: Wiley.\n\n\nKaplan, Edward L., e Paul Meier. 1958. «Nonparametric Estimation from Incomplete Observations». Journal of the American Statistical Association 53 (282): 457–81. https://doi.org/10.1080/01621459.1958.10501452.\n\n\nKlein, John P. 1991. «Small Sample Moments of Some Estimators of the Variance of the Kaplan-Meier and Nelson-Aalen Estimators». Scandinavian Journal of Statistics 18 (4): 333–40. https://doi.org/10.2307/4616203.\n\n\nLatta, Robert B. 1981. «A Monte Carlo Study of Some Two-Sample Rank Tests with Censored Data». Journal of the American Statistical Association 76 (375): 713–19. https://doi.org/10.2307/2287572.\n\n\nMantel, Nathan. 1966. «Evaluation of Survival Data and Two New Rank Order Statistics Arising in Its Consideration». Cancer Chemotherapy Reports 50 (3): 163–70.\n\n\nMantel, Nathan, e William Haenszel. 1959. «Statistical Aspects of the Analysis of Data from Retrospective Studies of Disease». Journal of the National Cancer Institute 22 (4): 719–48.\n\n\nMeier, Paul. 1975. «Estimation of a Survival Curve from Incomplete Data». Journal of the American Statistical Association 70 (351): 607–10. https://doi.org/10.1080/01621459.1975.10479872.\n\n\nNelson, Wayne. 1972. «Theory and Applications of Hazard Plotting for Censored Failure Data». Technometrics 14 (4): 945–66. https://doi.org/10.1080/00401706.1972.10488981.\n\n\nPeto, Richard, e Julian Peto. 1972. «Asymptotically Efficient Rank Invariant Test Procedures». Journal of the Royal Statistical Society: Series A (General) 135 (2): 185–98. https://doi.org/10.2307/2344317.\n\n\nPrentice, Ross L. 1978. «Linear Rank Tests with Right Censored Data». Biometrika 65 (1): 167–79. https://doi.org/10.2307/2335206.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Técnicas Não Paramétricas</span>"
    ]
  },
  {
    "objectID": "CIII_TEC_PARAM.html",
    "href": "CIII_TEC_PARAM.html",
    "title": "3  Técnicas Paramétricas - Modelos Probabilísticos",
    "section": "",
    "text": "3.1 Introdução\nNo capítulo anterior, foi apresentada uma abordagem não paramétrica para a análise de dados de sobrevivência, na qual a estimação é realizada sem assumir uma distribuição de probabilidade específica para o tempo de sobrevivência.\nOs estimadores não paramétricos são derivados diretamente do conjunto de dados, pressupondo que o mecanismo gerador das informações opera de maneira distinta em diferentes momentos no tempo, funcionando de forma quase independente. Assim, conclui-se que a abordagem não paramétrica possui tantos parâmetros quanto intervalos de tempo considerados. Contudo, ao incluir covariáveis, o modelo de Kaplan-Meier não permite estimar diretamente o “efeito” dessas covariáveis, limitando-se a comparar e testar a igualdade entre diferentes curvas de sobrevivência.\nPor outro lado, nos modelos de regressão tradicionais, como os modelos linear, Poisson ou logístico, a escolha de uma distribuição de probabilidade para a variável resposta \\(Y\\) e de uma função para a relação entre \\(Y\\) e as covariáveis \\(x_{1}, x_{2}, \\ldots, x_{p}\\) é essencial para identificar o modelo. Ao aplicar esse conceito na análise de sobrevivência, o tempo até a ocorrência de um evento de interesse é tratado como a variável resposta.\nNesse contexto, este capítulo introduz uma abordagem paramétrica para estimar as funções básicas de sobrevivência. Assume-se que a distribuição de probabilidade do tempo de ocorrência do evento é conhecida, permitindo a estimação dos parâmetros associados ao modelo de forma mais estruturada e eficiente.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Técnicas Paramétricas - Modelos Probabilísticos</span>"
    ]
  },
  {
    "objectID": "CIII_TEC_PARAM.html#sec-Dists",
    "href": "CIII_TEC_PARAM.html#sec-Dists",
    "title": "3  Técnicas Paramétricas - Modelos Probabilísticos",
    "section": "3.2 Distribuições do Tempo de Sobrevivência",
    "text": "3.2 Distribuições do Tempo de Sobrevivência\nSeja \\(T\\) uma variável aleatória que representa o “tempo de sobrevivência”. Qual seria a distribuição de probabilidade mais adequada para representá-la?\nUma característica fundamental da variável aleatória \\(T\\) é que ela é contínua e não negativa. Com base nessa propriedade, é possível eliminar algumas distribuições como candidatas adequadas para modelar \\(T\\). Por exemplo, a distribuição normal não é apropriada, pois admite valores negativos, o que contradiz a natureza do tempo de sobrevivência. Além disso, os tempos de sobrevivência frequentemente apresentam uma forte assimetria à direita, reforçando a inadequação da distribuição normal para esse contexto.\n\n\nCódigo\n# -----------------------\n# [1] ATIVAÇÃO DE PACOTES\n# -----------------------\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(eha)\n\n\n\n3.2.1 Distribuição Exponencial\nSe \\(T \\sim Exp(\\alpha)\\), a sua função densidade de probabilidade é expressa da seguinte forma:\n\\[\nf(t) = \\alpha \\exp\\{ -\\alpha t \\}, \\ t \\geq 0 \\ \\text{e} \\ \\alpha &gt; 0.\n\\tag{3.1}\\]\nDesta forma, podemos obter a função de sobrevivência com base no completar da distribuição acumulada de \\(T\\):\n\\[\\begin{align*}\n    S(t) & = P(T &gt; t) = 1 - P(T \\leq t) = 1 - F(t) \\\\\n         & = 1 - [1 - \\exp\\{ -\\alpha t \\}] \\\\\n         & = \\exp\\{ -\\alpha t \\}.\n\\end{align*}\\]\nAssim definimos, formalmente, a função de sobrevivência como:\n\\[\nS(t) = \\exp\\{ -\\alpha t \\}.\n\\tag{3.2}\\]\nNote que o parâmetro \\(\\alpha\\) é a velocidade de queda da função sobrevivência. Através das relações entre as funções em análise de sobrevivência, temos a função risco ou taxa de falha. Obtida pela razão entre da função densidade de probabilidade e a função de sobrevivência:\n\\[\n\\lambda(t) = \\dfrac{f(t)}{S(t)} = \\dfrac{\\alpha \\exp\\{ -\\alpha t \\}}{\\exp\\{ -\\alpha t \\}} = \\alpha = \\text{constante}.\n\\tag{3.3}\\]\nSendo a função risco constante para todo tempo observado \\(t\\), o risco acumulado é função linear no tempo com uma inclinação da reta dada por \\(\\alpha\\):\n\\[\n\\Lambda(t) = - \\ln[S(t)] = - \\ln[ \\exp\\{ -\\alpha t \\} ] = - (- \\alpha t) = \\alpha t\n\\tag{3.4}\\]\nVeja, a seguir, a Figura 3.1 que mostra as curvas de densidade de probabilidade, de sobrevivência, risco e risco acumulado para diferentes valores do parâmetro \\(\\alpha\\).\n\nCódigo\n# ---------------------------\n# [1] DISTRIBUIÇÃO EXPONENCIAL\n# ---------------------------\n# -------------\n# [1.1] FUNÇÕES\n# -------------\n\ndensity.exp &lt;- function(times, rate.par) dexp(x = times, rate = rate.par)\nsurvival.exp &lt;- function(times, rate.par) 1 - pexp(q = times, rate = rate.par)\nhazard.exp &lt;- function(times, rate.par) density.exp(times, rate.par)/survival.exp(times, rate.par)\naccumul.hazard.exp &lt;- function(times, rate.par) - log(x = survival.exp(times, rate.par))\n\n# ----------------------------------------\n# [1.2] SIMULAÇÃO E VARIAÇÃO DE PARÂMETROS\n# ----------------------------------------\n\nset.seed(123456789)        # Semente para reprodutibilidade\nn &lt;- 1000                  # Tamanho amostral\ntimes &lt;- rexp(n, rate = 1) # Simulando dados de uma exponencial\nalphas &lt;- c(1, 1.5, 2, 2.5, 3) # Valores do parâmetro a serem avaliados\n\n# Criando um Data Frame com valores das funções\ndados.exp &lt;- do.call(\n  rbind, lapply(alphas, function(alpha) {\n    data.frame(\n      times = sort(times),\n      ft = density.exp(sort(times), alpha),\n      st = survival.exp(sort(times), alpha),\n      ht = hazard.exp(sort(times), alpha),\n      Ht = accumul.hazard.exp(sort(times), alpha),\n      rate = factor(alpha)\n    )\n  })\n)\n\n# ---------------------------------------------\n# [1.3] FUNÇÃO GRÁFICA & VISUALIZAÇÕES GRÁFICAS\n# ---------------------------------------------\n\nplot.function.exp &lt;- function(df, f, label) {\n  ggplot(data = df, aes_string(x = \"times\", y = f, color = \"rate\")) +\n    geom_line(size = 1.15) +\n    labs(x = \"Tempo\", y = label, color = expression(alpha)) +\n    scale_color_manual(\n      values = c(\"red\", \"blue\", \"green\", \"purple\", \"orange\"), \n      labels = (levels(df$rate))\n    ) + theme_minimal(base_size = 12)\n}\n\n# Plotando a função densidade de probabilidade\nplot.function.exp(dados.exp, \"ft\", \"Densidade de Probabilidade\")\n\n# Plotando a função de sobrevivência\nplot.function.exp(dados.exp, \"st\", \"Probabilidade de Sobrevivência\")\n\n# Plotando a função de risco\nplot.function.exp(dados.exp, \"ht\", \"Risco\")\n\n# Plotando a função de risco acumulado\nplot.function.exp(dados.exp, \"Ht\", \"Risco Acumulado\")\n\n\n\n\nFigura 3.1: Funções Densidade de Probabilidade, Sobrevivência, Risco e Risco Acumulado segundo uma Distribuição Exponencial para diferentes valores do Parâmetro de Taxa.\n\n\n\n\n\n\n\n\n\n\n(a) Função Densidade de Probabilidade\n\n\n\n\n\n\n\n\n\n\n\n(b) Função de Sobrevivência\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Função de Risco\n\n\n\n\n\n\n\n\n\n\n\n(d) Função de Risco Acumulado\n\n\n\n\n\n\n\n\n\n3.2.1.1 Algumas considerações\nNote que, quanto maior o valor de \\(\\alpha\\) (risco), mais abruptamente a função de sobrevivência \\(S(t)\\) decresce, e maior é a inclinação da função de risco acumulado.\nA distribuição exponencial, por possuir um único parâmetro, é matematicamente simples e apresenta um formato assimétrico. Seu uso em análise de sobrevivência tem uma analogia com a suposição de normalidade em outras técnicas e áreas da estatística. Entretanto, a suposição de risco constante associada a essa distribuição é bastante restritiva e, em muitos casos, pode não ser realista.\nPor exemplo, considere um estudo sobre câncer, em que o tempo até o evento de interesse é definido como o período até a morte ou a cura do paciente. Para aplicar a distribuição exponencial nesse contexto, seria necessário assumir que o tempo desde o diagnóstico da doença não afeta a probabilidade de ocorrência do evento. Essa suposição é delicada, pois o próprio passar do tempo afeta naturalmente a probabilidade de sobrevivência, o risco e o risco acumulado, entre outros fatores. Isso pode ocorrer por causas naturais, como o envelhecimento, que aumenta o risco com o avanço da idade. Essa característica da distribuição exponencial é conhecida como falta de memória, o que significa que o risco futuro é independente do tempo já decorrido.\nQuando \\(\\alpha = 1\\), a distribuição é denominada exponencial padrão. A média e a variância do tempo de sobrevivência, para uma variável que segue a distribuição exponencial, são expressas como funções inversas do parâmetro de risco (\\(\\alpha\\)). Assim, quanto maior o risco, menor o tempo médio de sobrevivência e menor a variabilidade em torno da média. As expressões são dadas por:\n\\[\nE[T] = \\dfrac{1}{\\alpha},\n\\]\n\\[\nVar[T] = \\dfrac{1}{\\alpha^2}.\n\\] Como a distribuição de \\(T\\) é assimétrica, se torna mais usual utilizar o tempo mediano de sobrevivência ao invés de tempo médio. Pode-se obter o tempo mediano de sobrevivência a partir de um tempo \\(t\\), tal que, \\(S(t) = 0,5\\), logo,\n\\[\\begin{align*}\n    S(t) & = 0,5 \\Leftrightarrow \\exp\\{ -\\alpha t \\} = 0,5 \\Leftrightarrow -\\alpha t = \\ln(2^{-1}) \\\\\n    \\alpha t & = - [-\\ln(2)] \\Leftrightarrow \\alpha t = \\ln(2).\n\\end{align*}\\]\nDesta forma, o tempo mediano de sobrevivência é definido como:\n\\[\nT_{mediano} = \\dfrac{\\ln(2)}{\\alpha}.\n\\]\nEm resumo, o modelo exponencial é apropriado para situações em que o período do experimento é curto o suficiente para que a suposição de risco constante seja plausível.\n\n\n\n3.2.2 Distribuição Weibull\nNa maioria dos casos de análise de sobrevivência na área da saúde, é mais razoável supor que o risco varia ao longo do tempo, em vez de permanecer constante.\nAtualmente, a Distribuição Weibull é amplamente utilizada, pois permite modelar essa variação do risco ao longo do tempo. Como será demonstrado, a distribuição exponencial é um caso particular da distribuição Weibull.\nSe o tempo de sobrevivência \\(T\\) segue uma distribuição Weibull, ou seja, \\(T \\sim Weibull(\\gamma, \\alpha)\\), sua função densidade de probabilidade é dada por:\n\\[\nf(t) = \\dfrac{ \\gamma }{ \\alpha^{\\gamma} } t^{\\gamma - 1} \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} \\right\\}.\n\\tag{3.5}\\]\nA partir da Equação 3.5 é possível chegar a função de sobrevivência da distribuição Weibull sendo está função definida como:\n\\[\nS(t) = \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} \\right\\},\n\\tag{3.6}\\]\nonde \\(t \\geq 0\\), \\(\\alpha\\) o parâmetro escala (ou taxa) e \\(\\gamma\\) parâmetro de forma. Ambos os parâmetros sempre positivos.\nA função de risco, \\(\\lambda(t)\\), depende do tempo de sobrevivência. Apresentando variação no tempo conforme a expressão:\n\\[\n\\lambda (t) = \\dfrac{f(t)}{S(t)} = \\dfrac{ \\gamma }{ \\alpha^{\\gamma} } t^{\\gamma - 1}\n\\tag{3.7}\\]\ne a função de risco acumulado da distribuição Weibull é dada por:\n\\[\n\\Lambda (t) = - \\ln[S(t)] = - \\ln \\left[ \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} \\right\\} \\right] = \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma}.\n\\tag{3.8}\\]\nNote que, o parâmetro \\(\\gamma\\) determina a forma função de risco da seguinte maneira:\n\n\\(\\gamma &lt; 1 \\rightarrow\\) função de risco decresce;\n\\(\\gamma &gt; 1 \\rightarrow\\) função de risco cresce;\n\\(\\gamma = 1 \\rightarrow\\) função de risco constante, caindo no caso particular da distribuição exponencial.\n\nVeja, a seguir, a Figura 3.2 que mostra as curvas de densidade, sobrevivência, risco e risco acumulado para diferentes valores do parâmetro de forma \\(\\gamma\\) e o de escala \\(\\alpha = 1\\).\n\nCódigo\n# ------------------------\n# [2] DISTRIBUIÇÃO WEIBULL\n# ------------------------\n# -------------\n# [2.1] FUNÇÕES\n# -------------\n\ndensity.weib &lt;- function(times, shape.par, scale.par) dweibull(x=times, shape=shape.par, scale=scale.par)\nsurvival.weib &lt;- function(times, shape.par, scale.par) 1 - pweibull(q=times, shape=shape.par, scale=scale.par)\nhazard.weib &lt;- function(times, shape.par, scale.par) density.weib(times,shape.par,scale.par)/survival.weib(times,shape.par,scale.par)\naccumul.hazard.weib &lt;- function(times, shape.par, scale.par) - log(x = survival.weib(times,shape.par,scale.par))\n\n# ----------------------------------------\n# [2.2] SIMULAÇÃO E VARIAÇÃO DE PARÂMETROS\n# ----------------------------------------\nn &lt;- 1000                                  # Tamanho amostral\ntimes &lt;- rweibull(n, shape = 2, scale = 1) # Simulando dados de uma Weibull\nalpha &lt;- 1                                 # Fixo para simplificar\ngammas &lt;- c(0.5, 1.0, 1.5, 2.0, 2.5, 3.0)  # # Valores do parâmetro a serem avaliados\n\n# Criando um Data Frame com valores das funções\ndados.weib &lt;- do.call(rbind, lapply(gammas, function(gamma) {\n  data.frame(\n    times = sort(times),\n    ft = density.weib(sort(times), gamma, alpha),\n    st = survival.weib(sort(times), gamma, alpha),\n    ht = hazard.weib(sort(times), gamma, alpha),\n    Ht = accumul.hazard.weib(sort(times), gamma, alpha),\n    gamma = factor(gamma)\n  )\n}))\n\n# ---------------------------------------------\n# [2.3] FUNÇÃO GRÁFICA & VISUALIZAÇÕES GRÁFICAS\n# ---------------------------------------------\n\nplot.function.weib &lt;- function(df, f, label) {\n  ggplot(data = df, aes_string(x = \"times\", y = f, color = \"gamma\")) +\n    geom_line(size = 1.15) +\n    labs(x = \"Tempo\", y = label, color = expression(gamma)) +\n    scale_color_manual(\n      values = c(\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"brown\"), \n      labels = (levels(df$gamma))\n    ) + theme_minimal(base_size = 12)\n}\n\n# Plotando a função densidade de probabilidade\nplot.function.weib(dados.weib, \"ft\", \"Densidade de Probabilidade\")\n\n# Plotando a função de sobrevivência\nplot.function.weib(dados.weib, \"st\", \"Probabilidade de Sobrevivência\")\n\n# Plotando a função de risco\nplot.function.weib(dados.weib, \"ht\", \"Risco\")\n\n# Plotando a função de risco acumulado\nplot.function.weib(dados.weib, \"Ht\", \"Risco Acumulado\")\n\n\n\n\nFigura 3.2: Funções Densidade de Probabilidade, Sobrevivência, Risco e Risco Acumulado segundo uma Distribuição Weibull para diferentes valores do parâmetro de forma.\n\n\n\n\n\n\n\n\n\n\n(a) Função Densidade de Probabilidade\n\n\n\n\n\n\n\n\n\n\n\n(b) Função de Sobrevivência\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Função de Risco\n\n\n\n\n\n\n\n\n\n\n\n(d) Função de Risco Acumulado\n\n\n\n\n\n\n\n\n\n3.2.2.1 Algumas considerações\nÉ incluso a função gama na média e variância da distribuição Weibull, assim,\n\\[\nE[T] = \\alpha \\Gamma[1 + (1/\\gamma)]\n\\] e\n\\[\nVar[T] = \\alpha^{2} \\left[ \\Gamma [1 + (2/\\gamma)] - \\Gamma [1 + (1/\\gamma)]^{2} \\right]\n\\]\nsendo a função gama \\(\\Gamma [k]\\), expressa por \\(\\Gamma [k] = \\int_{0}^{\\infty} t^{k -1} \\exp\\{t\\} dt\\).\nAfim de se obter o tempo mediano de sobrevivência, igualamos a probabilidade de sobrevivência a \\(0,5\\). Desta forma:\n\\[\\begin{align*}\n    S(t) & = 0,5 \\Leftrightarrow \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} \\right\\} = 0,5 \\\\\n    - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} & = \\ln{(2^{-1})} \\Leftrightarrow \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} = \\ln{(2)} \\\\\n    \\dfrac{t}{\\alpha} & = [\\ln{(2)}]^{1/\\gamma}.\n\\end{align*}\\]\nLogo, definimos o tempo mediano de sobrevivência da distribuição Weibull como:\n\\[\nT_{mediano} = \\alpha [\\ln{(2)}]^{1/\\gamma}.\n\\]\n\n\n\n3.2.3 Distribuição Log-normal\nUma outra possibilidade para modelar o tempo de sobrevivência é a distribuição Log-normal. Dizer que \\(T \\sim Normal(\\mu, \\sigma^{2})\\) implica em dizer que \\(\\ln(T) \\sim Log-normal(\\mu, \\sigma^{2})\\) em que \\(\\mu\\) é a média do logaritmo do tempo de falha e \\(\\sigma^{2}\\) sua variância. Pode-se fazer uso desta relação para modelar o tempo de sobrevivência conforme uma distribuição normal, desde que, se aplique o logaritmo aos dados observados. A função densidade para tal distribuição é dada por:\n\\[\nf (t) = \\dfrac{1}{t \\sigma \\sqrt{2 \\pi}} \\exp \\left\\{- \\dfrac{1}{2} \\left(\\dfrac{\\ln(t) - \\mu}{\\sigma}\\right)^{2} \\right\\}.\n\\tag{3.9}\\]\nAssim, quando o tempo de sobrevivência segue uma distribuição log-normal, sua função de sobrevivência e as demais não tem uma forma análitica explícita, desde modo, deve-se fazer uso das relações entre as funções para se obter a função taxa de falha e taxa de falha acumulada. Desta forma, essas funções são expressas, respectivamente, por:\n\\[\nS (t) = \\Phi \\left( \\dfrac{- \\ln(t) + \\mu}{\\sigma} \\right),\n\\tag{3.10}\\]\n\\[\n\\lambda (t) = \\dfrac{f(t)}{S(t)}\n\\]\ne\n\\[\n\\Lambda (t) = - \\ln[S(t)]\n\\]\nem que \\(\\Phi (\\cdot)\\) é a função de distribuição acumulada da normal padrão.\nVeja a Figura 3.3 que ilustras as curvas usadas na análise de sobrevivência segundo uma distribuição log-normal, variando o parâmetro de locação \\(\\mu\\) e fixando o parâmetro de escala \\(\\sigma = 1\\).\n\nCódigo\n# ---------------------------\n# [3] DISTRIBUIÇÃO LOG-NORMAL\n# ---------------------------\n# -------------\n# [3.1] FUNÇÕES\n# -------------\n\ndensity.lnorm &lt;- function(times, loc.par, scale.par) dlnorm(x=times, loc.par, scale.par)\nsurvival.lnorm &lt;- function(times, loc.par, scale.par) 1 - pnorm(q=(log(times)-loc.par)/scale.par)\nhazard.lnorm &lt;- function(times, loc.par, scale.par) density.lnorm(times, loc.par, scale.par)/survival.lnorm(times, loc.par, scale.par)\naccumul.hazard.lnorm &lt;- function(times, loc.par, scale.par) -log(x=survival.lnorm(times, loc.par, scale.par))\n\n# ----------------------------------------\n# [3.2] SIMULAÇÃO E VARIAÇÃO DE PARÂMETROS\n# ----------------------------------------\nn &lt;- 1000                                  # Tamanho amostral\ntimes &lt;- rlnorm(n, meanlog = 0, sdlog = 1) # Simulando dados de uma Log-normal\nloc.pars &lt;- c(0, 0.5, 1, 1.5, 2, 2.5)      # Valores de mu\nscale.par &lt;- 1                             # Valor fixo de sigma\n\n# Criando um Data Frame com valores das funções\ndados.lnorm &lt;- do.call(\n  rbind, lapply(loc.pars, function(loc.par) {\n    data.frame(\n      times = sort(times),\n      ft = density.lnorm(sort(times), loc.par, scale.par),\n      st = survival.lnorm(sort(times), loc.par, scale.par),\n      ht = hazard.lnorm(sort(times), loc.par, scale.par),\n      Ht = accumul.hazard.lnorm(sort(times), loc.par, scale.par),\n      mu = factor(loc.par)\n    )\n  })\n)\n\n# ---------------------------------------------\n# [3.3] FUNÇÃO GRÁFICA & VISUALIZAÇÕES GRÁFICAS\n# ---------------------------------------------\n\nplot.function.lnorm &lt;- function(df, f, label) {\n  ggplot(data = df, aes_string(x = \"times\", y = f, color = \"mu\")) +\n    geom_line(size = 1.15) +\n    labs(x = \"Tempo\", y = label, color = expression(mu)) +\n    scale_color_manual(\n      values = c(\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"brown\"), \n      labels = (levels(df$mu))\n    ) + theme_minimal(base_size = 12)\n}\n\n# Plotando a função densidade de probabilidade\nplot.function.lnorm(dados.lnorm, \"ft\", \"Densidade de Probabilidade\")\n\n# Plotando a função de sobrevivência\nplot.function.lnorm(dados.lnorm, \"st\", \"Probabilidade de Sobrevivência\")\n\n# Plotando a função de risco\nplot.function.lnorm(dados.lnorm, \"ht\", \"Risco\")\n\n# Plotando a função de risco acumulado\nplot.function.lnorm(dados.lnorm, \"Ht\", \"Risco Acumulado\")\n\n\n\n\nFigura 3.3: Funções Densidade de Probabilidade, Sobrevivência, Risco e Risco Acumulado segundo uma Distribuição Log-normal para diferentes valores do parâmetro de média.\n\n\n\n\n\n\n\n\n\n\n(a) Função Densidade de Probabilidade\n\n\n\n\n\n\n\n\n\n\n\n(b) Função de Sobrevivência\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Função de Risco\n\n\n\n\n\n\n\n\n\n\n\n(d) Função de Risco Acumulado\n\n\n\n\n\n\n\n\n\n3.2.3.1 Algumas considerações\nA média e a variância da distribuição log-normal são, respectivamente, dadas por:\n\\[\nE[T] = \\exp\\{ \\mu + \\sigma^{2} / 2 \\}\n\\]\ne\n\\[\nVar[T] = \\exp\\{ 2 \\mu + \\sigma^{2} \\} (\\exp\\{ \\sigma^{2} - 1 \\})\n\\]\n\n\n\n3.2.4 Distribuição Exponencial por Partes\n\n\n3.2.5 Distribuição Exponencial por Partes de Potência",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Técnicas Paramétricas - Modelos Probabilísticos</span>"
    ]
  },
  {
    "objectID": "CIII_TEC_PARAM.html#estimação-de-parâmetros",
    "href": "CIII_TEC_PARAM.html#estimação-de-parâmetros",
    "title": "3  Técnicas Paramétricas - Modelos Probabilísticos",
    "section": "3.3 Estimação de Parâmetros",
    "text": "3.3 Estimação de Parâmetros\nForam apresentados alguns modelos probabilísticos. Esses modelos possuem quantidades desconhecidas, denominadas parâmetros, ou parâmetro, quando o modelo depende de uma única quantidade desconhecida, como no caso da distribuição exponencial.\n\n3.3.1 Método de Máxima Verossimilhança\nO Método de Máxima Verossimilhança baseia-se no princípio de que, a partir de uma amostra aleatória, a melhor estimativa para o parâmetro de interesse é aquela que maximiza a probabilidade daquela amostra observada ter sido observada (Bussab e Morettin 2010).\nDe forma simples, o método de máxima verossimilhança condensa toda a informação contida na amostra, por meio da função de verossimilhança, para encontrar o(s) parâmetro(s) da distribuição que melhor expliquem os dados. Essa abordagem utiliza o produtório das densidades \\(f(t)\\) para cada observação \\(t_i\\), \\(i = 1, 2, \\ldots, n\\). Em livros introdutórios de estatística, a função de verossimilhança é definida da seguinte maneira, para um parâmetro ou vetor de parâmetros \\(\\theta\\):\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} f(t_{i} | \\theta).\n\\]\nObserve que \\(L\\) é uma função de \\(\\theta\\), que pode ser um único parâmetro ou um vetor de parâmetros, como ocorre na distribuição log-normal, onde \\(\\theta = (\\mu, \\sigma^2)\\). No entanto, em análise de sobrevivência, essa definição tradicional de função de verossimilhança é insuficiente, pois os dados frequentemente apresentam censura, o que implica que o tempo de evento pode ser apenas parcialmente observado.\nPara lidar com essa característica, utiliza-se a variável indicadora \\(\\delta_{i}\\), apresentada na Seção 1.5, que identifica se o \\(i\\)-ésimo tempo é um tempo de evento ou de censura. Com base nessa informação, a função de verossimilhança é ajustada da seguinte forma:\n\nPara \\(\\delta_{i} = 1\\), o \\(i\\)-ésimo tempo é um tempo de evento, e sua contribuição para \\(L(\\theta)\\) é a densidade de probabilidade \\(f(t_{i} | \\theta)\\);\nPara \\(\\delta_i = 0\\), o \\(i\\)-ésimo tempo é um tempo censurado, e sua contribuição para \\(L(\\theta)\\) é a função de sobrevivência \\(S(t_{i} | \\theta)\\).\n\nAssim, a função de verossimilhança ajustada, que incorpora dados censurados, é expressa como:\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ f(t_{i} | \\theta) \\right]^{\\delta_i} \\left[ S(t_{i} | \\theta) \\right]^{1 - \\delta_{i}}\n\\] \\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ \\lambda(t_{i} | \\theta) \\right]^{\\delta_i} S(t_{i} | \\theta).\n\\tag{3.11}\\]\nPara encontrar o valor de \\(\\theta\\) que maximiza \\(L(\\theta)\\), utiliza-se a derivada do logaritmo de base neperiana da verossimilhança igualada a zero:\n\\[\n\\frac{\\partial \\ln [L(\\theta)]}{\\partial \\theta} = 0.\n\\]\nA solução dessa equação fornece o valor de \\(\\theta\\) que maximiza \\(\\ln [L(\\theta)]\\), e consequentemente, \\(L(\\theta)\\).\n\n\n3.3.2 Método Iterativo de Newton-Raphson\nPara algumas distribuições, apresentadas na Seção 3.2, e outras denifidas na literatura, não há forma analítica para as estimativas de máxima verossimilhança. Assim, as estimativas de tais parâmetros depende de métodos numéricos, sendo o Método Iterativo de Newton-Raphson uma abordagem amplamente utilizada.\nO Método de Newton-Raphson é um procedimento iterativo eficiente para resolver equações não lineares, muito empregado na estimação de parâmetros de modelos estatísticos. No ajuste de distribuições o método busca maximizar a função de verossimilhança resolvendo o sistema de equações derivado das condições de otimalidade (gradiente nulo). A fórmula iterativa é:\n\\[\n\\theta_{n+1} = \\theta_{n} - \\mathbf{H}^{-1}(\\theta_{n}) \\nabla \\ln[L(\\theta_{n})],\n\\tag{3.12}\\]\nonde:\n\n\\(\\theta_{n}\\) é o vetor de parâmetros estimados na iteração \\(n\\);\n\\(\\ln[L(\\theta_{n})]\\) é o vetor gradiente, contendo as derivadas parciais de \\(\\ln[L(\\theta_{n})]\\) em relação as coordenadas do vetor \\(\\theta\\) (parâmetros);\n\\(\\mathbf{H}(\\theta)\\) é a matriz Hessiana, composta pelas segundas derivadas de \\(\\ln[L(\\theta_{n})]\\).\n\nO método apresenta vantagens convenientes no ajuste de parâmetros de modelos estatísticos. Uma das vantagens é a eficiência do método, que apresenta convergência rápida quando o ponto inicial \\(\\theta_{0}\\) está próximo dos valores reais dos parâmetros. Outra vantagem, é flexibilidade, pois pode ser aplicado a diversos modelos probabilísticos, como o modelo Weibull, que é amplamente utilizada para modelar tempos de vida e dados de sobrevivência.\nEntretanto, deve-se, também, atentar-se aos cuidados na aplicação do método. Pois, a convergência do método não é garantida caso o ponto inicial esteja muito distante da solução ou se as condições de regularidade do modelo não forem atendidas. Outro ponto que merece atenção é o cálculo da matriz Hessiana, que pode ser computacionalmente custoso, especialmente em modelos com maior complexidade.\nPara um melhor entendimento do Método Iterativo de Newton-Raphson veja o Apêndice (D) do livro Análise de Sobrevivência Aplicada de Colosimo e Giolo (2006).\n\n\n3.3.3 Aplicações Caso Não Haja Censura\nNesta seção, será demonstrado como determinar o estimador ou os estimadores de máxima verossimilhança para os parâmetros das distribuições discutidas quando não há presença de censuras nos dados. Aqui, será apresentada apenas a saída dos programas. Para ter o script utilizado, acesse o repositório do Github por meio do seguinte link: github.com\n\n3.3.3.1 Distribuição Exponencial\nConsidere a distribuição exponencial conforme descrita na Seção 3.2.1. O Estimador de Máxima Verossimilhança (EMV) do parâmetro \\(\\alpha\\), isto é, \\(\\theta = \\alpha\\), pode ser obtido seguindo os passos descritos a seguir:\n\nDefinir a Função de Verossimilhança \\(L(\\theta)\\):\n\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ \\alpha \\exp\\{ -\\alpha t \\} \\right]^{\\delta_{i}} \\left[ \\exp\\{ -\\alpha t \\} \\right]^{1 - \\delta_{i}}.\n\\tag{3.13}\\]\n\nTomar o logaritmo natural da função verossimilhança \\(\\ln[L(\\alpha)]\\):\n\n\\[\\begin{align*}\n    \\ln[L(\\theta)] & = \\sum_{i = 1}^{n} \\ln \\left[ \\alpha^{\\delta_{i}} \\exp \\{ - \\alpha t_{i} \\} \\right] = \\sum_{i = 1}^{n} \\ln \\left[ \\alpha^{\\delta_{i}} \\right] + \\sum_{i = 1}^{n} \\ln \\left[ \\exp \\{ - \\alpha t_{i} \\} \\right] \\\\\n                   & = \\sum_{i = 1}^{n} \\delta_{i} \\ln[\\alpha] + \\sum_{i = 1}^{n} - \\alpha t_{i} =  \\ln[\\alpha] \\sum_{i = 1}^{n} \\delta_{i} - \\alpha \\sum_{i = 1}^{n} t_{i}. \\\\\n\\end{align*}\\]\n\nDerivar a função do log-verossimilhança em relação a \\(\\theta\\). Logo \\(\\dfrac{\\partial \\ln[L (\\theta)]}{\\partial \\theta}\\):\n\n\\[\\begin{align*}\n    \\dfrac{\\partial \\ln L (\\theta)}{\\partial \\theta}  & = \\dfrac{1}{\\alpha} \\sum_{i = 1}^{n} \\delta_{i} - \\sum_{i = 1}^{n} t_{i}.\n\\end{align*}\\]\n\nIgualar a derivada a zero e resolver para \\(\\alpha\\):\n\n\\[\\begin{align*}\n    \\dfrac{\\partial \\ln[L (\\theta)]}{\\partial \\theta}  & = 0 \\\\\n    \\dfrac{1}{\\hat{\\alpha}} \\sum_{i = 1}^{n} \\delta_{i} - \\sum_{i = 1}^{n} t_{i} & = 0 \\\\\n    \\hat{\\alpha} & = \\dfrac{\\sum_{i = 1}^{n} \\delta_{i}}{\\sum_{i = 1}^{n} t_{i}}\n\\end{align*}\\]\nNote que, para o caso em que não se tem censura o numerador, \\(\\sum_{i = 1}^{n} \\delta_{i}\\), equivale ao tamanho da amostra \\(n\\). Logo, o EMV para \\(\\alpha\\) no caso de não haver censura nos dados é: \\(\\hat{\\alpha} = n /\\sum_{i = 1}^{n} t_{i}\\).\nSimulou-se uma amostra proveniente de uma distribuição exponencial e, a partir dessa amostra, obteve-se a estimativa de máxima verossimilhança para o parâmetro \\(\\alpha\\). Veja a Tabela 3.1, que apresenta as dez observações, na ordem de simulação, e suas respectivas funções de sobrevivência real e estimada.\n\n\nCódigo\n# ---------------------------\n# [1] Função de Sobrevivência\n# ---------------------------\nsurvival.exp &lt;- function(times, rate.par) 1 - pexp(q = times, rate = rate.par)\n\n# -------------------------\n# [2] Simulação e Estimação\n# -------------------------\n\n# Configuração inicial\nset.seed(123456789)\nn &lt;- 1000    # Tamanho amostral\nrate &lt;- 1.5  # Parâmetro verdadeiro\n\ntimes &lt;- rexp(n, rate = rate) # Simulação de tempos de sobrevivência\nemv.exp &lt;- n / sum(times)     # Estimador de Máxima Verossimilhança (EMV)\n\n# -------------------------\n# [3] Organização dos Dados\n# -------------------------\ndados.exp &lt;- data.frame(\n  times = times,\n  st = survival.exp(times, rate),\n  st.emv = survival.exp(times, emv.exp)\n)\n\nlibrary(knitr)\n\nknitr::kable(\n  round(head(dados.exp, 10), 4), \n  col.names = c(\"Tempo\", \"$S(t)$\", \"$\\\\hat{S}_{EMV}(t)$\"),\n  escape = FALSE,\n  align = \"c\",\n  booktabs = TRUE\n)\n\n\n\n\nTabela 3.1: Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Exponencial.\n\n\n\n\n\n\nTempo\n\\(S(t)\\)\n\\(\\hat{S}_{EMV}(t)\\)\n\n\n\n\n0,2576\n0,6795\n0,6856\n\n\n0,2305\n0,7077\n0,7134\n\n\n0,2052\n0,7351\n0,7403\n\n\n0,2920\n0,6453\n0,6519\n\n\n0,1086\n0,8497\n0,8529\n\n\n0,1239\n0,8304\n0,8339\n\n\n2,1030\n0,0427\n0,0459\n\n\n1,0528\n0,2062\n0,2138\n\n\n0,4921\n0,4780\n0,4862\n\n\n1,9384\n0,0546\n0,0584\n\n\n\n\n\n\n\n\nO valor verdadeiro do parâmetro é \\(\\alpha = 1,5\\). A estimativa de máxima verossimilhança obtida foi \\(\\hat{\\alpha} = 1,4654\\). Na Figura 3.4, comparamos graficamente as duas curvas de sobrevivência, ilustrando o valor real do parâmetro \\(\\alpha\\) e sua estimativa \\(\\hat{\\alpha}\\).\n\n\nCódigo\n# -------------------------\n# [1] Organização dos Dados\n# -------------------------\ndados.exp &lt;- data.frame(\n  times = sort(times),\n  st = survival.exp(sort(times), rate),\n  st.emv = survival.exp(sort(times), emv.exp)\n)\n\nggplot(dados.exp, aes(x = times)) +\n  geom_line(aes(y = st, color = \"rate\"), lwd = 1) +\n  geom_line(aes(y = st.emv, color = \"emv.exp\"), lwd = 1, lty = 4) +\n  scale_color_manual(\n    values = c(\"rate\" = \"black\", \"emv.exp\" = \"red\"),\n    labels = c(bquote(alpha == .(rate)), bquote(hat(alpha) == .(emv.exp)))\n  ) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Parâmetro\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.4: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial.\n\n\n\n\n\n\n\n\n\n\n3.3.3.2 Distribuição Weibull\nPara a estimação de parâmetros do modelo Weibull. Necessita-se da aplicação do método numérico de Newton-Raphson descrito na Seção 3.2. Tal método requer o cálculo das derivadas parciais e de segunda ordem em relação ao vetor de parâmetros \\(\\theta = (\\gamma, \\alpha)\\), permitindo ajustar o modelo aos dados observados de tempos de sobrevivência de forma precisa e eficiente.\nPara o modelo Weibull será apresentada duas formas de implementar o método. A primeira é a construção braçal do algoritmo, que consiste na definição e cálculo explícito das funções necessárias, como a função de log-verossimilhança, o gradiente e a Hessiana. A segunda é utilizar a função de otimização optim, já implementadas na linguagem de programação R. Está função automatiza o processo de otimização e oferece uma implementação flexível e eficiente. Para os demais modelos probabilísticos será usado apenas a função de otimização optim do R.\nComeçando com a implementação sem uso da função de otimização, deve-se primeiramente, encontrar log-verossimilhança, o gradiente e a Hessiana. Pode-se definir a função de verossimilhança para distribuição Weibul usando a Equação 3.11, substituindo a função densidade e a função de sobrevivência da distribuição Weibull especificadas na Seção 3.2.2. Portanto:\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ \\dfrac{ \\gamma }{ \\alpha^{\\gamma} } t^{\\gamma - 1} \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} \\right\\} \\right]^{\\delta_{i}} \\left[ \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha} \\right)^{\\gamma} \\right\\} \\right]^{1 - \\delta_{i}}.\n\\tag{3.14}\\]\nToma-se o logaritmo natural de \\(L(\\gamma, \\alpha)\\), logo:\n\\[\\begin{align*}\n    \\ln[L(\\gamma, \\alpha)] & = \\sum_{i = 1}^{n} \\delta_{i} \\ln[\\gamma] - \\sum_{i = 1}^{n} \\delta_{i} \\gamma \\ln[\\alpha] + \\sum_{i = 1}^{n} \\delta_{i} (\\gamma - 1) \\ln[t_{i}] + \\sum_{i = 1}^{n} - (\\alpha^{-1} t_{i})^{\\gamma} \\\\\n    & = \\ln[\\gamma] \\sum_{i = 1}^{n} \\delta_{i} - \\gamma \\ln[\\alpha] \\sum_{i = 1}^{n} \\delta_{i} + (\\gamma - 1) \\sum_{i = 1}^{n} \\delta_{i} \\ln[t_{i}] + \\sum_{i = 1}^{n} - (\\alpha^{-1} t_{i})^{\\gamma}.\n\\end{align*}\\]\nAplicando as derivadas de primeira ordem em relação a \\(\\gamma\\) e \\(\\alpha\\), temos:\n\\[\n\\dfrac{\\partial \\ln[L(\\gamma, \\alpha)]}{\\partial \\gamma} = \\dfrac{1}{\\gamma} \\sum_{i = 1}^{n} \\delta_{i} - \\ln[\\alpha] \\sum_{i = 1}^{n} \\delta_{i} + \\sum_{i = 1}^{n} \\delta_{i} \\ln[t_{i}] - \\sum_{i = 1}^{n} (\\alpha^{-1} t_{i})^{\\gamma} \\ln[\\alpha^{-1} t_{i}]\n\\]\ne\n\\[\n\\dfrac{\\partial \\ln[L (\\gamma, \\alpha)]}{\\partial \\alpha} = - \\dfrac{\\gamma}{\\alpha} \\sum_{i = 1}^{n} \\delta_{i} + \\gamma \\alpha^{-\\gamma - 1} \\sum_{i = 1}^{n} t_{i}^{\\gamma}.\n\\]\nToma-se agora as derivadas de segunda ordem.\n\\[\n\\dfrac{\\partial^{2} \\ln[L (\\gamma, \\alpha)]}{\\partial \\gamma^{2}} =  - \\dfrac{1}{\\gamma^{2}} \\sum_{i = 1}^{n} \\delta_{i} - \\sum_{i = 1}^{n} (\\alpha^{-1} t_{i})^{\\gamma} (\\ln[\\alpha^{-1} t_{i}])^{2},\n\\]\n\\[\n\\dfrac{\\partial^{2} \\ln [L(\\gamma, \\alpha)]}{\\partial \\alpha^{2}} = - \\dfrac{\\gamma}{\\alpha^{2}} \\sum_{i = 1}^{n} \\delta_{i} - \\gamma (\\gamma + 1) \\alpha^{-\\gamma - 2} \\sum_{i = 1}^{n} t_{i}^{\\gamma}\n\\]\ne\n\\[\n\\dfrac{\\partial^{2} \\ln[L(\\gamma, \\alpha)]}{\\partial \\gamma \\partial \\alpha} = \\dfrac{\\partial^{2} \\ln[L(\\gamma, \\alpha)]}{\\partial \\alpha \\partial \\gamma} = - \\dfrac{1}{\\alpha} \\sum_{i = 1}^{n} \\delta_{i} + \\alpha^{- \\gamma - 1} \\sum_{i = 1}^{n} t_{i}^{\\gamma} \\left( \\gamma \\ln\\left[ \\dfrac{t_{i}}{\\alpha} \\right] + 1 \\right)\n\\]\nCom todas as derivadas definidas, pode-se construir o algoritmo iterativo de Newton-Raphson. Tirou-se uma amostra de uma \\(Weibull(2; 1,5)\\). As estimativas obtidas foram as seguintes.\n\n\nCódigo\n# ------------------\n# [2] MODELO WEIBULL\n# ------------------\n\n# Função de sobrevivência\nsurvival.weib &lt;- function(times,shape.par,scale.par) 1 - pweibull(q=times, shape=shape.par, scale=scale.par)\n\n# ---------------------------\n# [2.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nshape.weib &lt;- 2     # Parâmetro de forma\nscale.weib &lt;- 1.5   # Parâmetro de escala\n\n# Simulação dos dados\ntimes &lt;- rweibull(n, shape.weib, scale.weib)\n\n# ----------------------------------------------\n# [2.1.1] IMPLEMENTAÇÃO SEM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Vetor gradiente\nGRADIEN &lt;- function(times, theta) {\n  # Número de observações\n  n &lt;- length(times)\n  \n  # Distição dos parâmetros\n  gamma &lt;- theta[1] # Parâmetro de forma\n  alpha &lt;- theta[2] # Parâmetro de escala\n  \n  # Ajutes de variáveis\n  t &lt;- times\n  \n  # Derivadas Parciais\n  DerivGamma &lt;- n/gamma - log(alpha)*n + sum(log(t)) - sum(((t/alpha)^gamma)*log(t/alpha))\n  DerivAlpha &lt;- -(gamma/alpha)*n + gamma*(alpha^(-gamma-1))*sum(t^gamma)\n  \n  # Vetor Gradiente\n  gradient &lt;- c(DerivGamma, DerivAlpha)\n  \n  # Retornar\n  return(gradient)\n}\n\n# Matriz Hessiana\nHESSIAN &lt;- function(times, theta) {\n  # Número de observações\n  n &lt;- length(times)\n  \n  # Distição dos parâmetros\n  gamma &lt;- theta[1] # Parâmetro de forma\n  alpha &lt;- theta[2] # Parâmetro de escala\n  \n  # Ajutes de variáveis\n  t &lt;- times\n  \n  # Derivadas de 2ª ordem\n  D2Gamma &lt;- - n/gamma^2 - sum(((t/alpha)^gamma)*(log(t/alpha)^2))\n  D2Alpha &lt;- - (gamma/alpha^2)*n - gamma*(gamma + 1)*(alpha^(-gamma-2))*sum(t^gamma)\n  D2 &lt;- -n*alpha + (alpha^(-gamma-1))*sum((t^gamma)*(gamma*log(t/alpha) + 1))\n  \n  # Matriz Hessiana\n  H &lt;- matrix(\n    data = c(D2Gamma, D2, D2, D2Alpha),\n    nrow = 2, ncol = 2\n  )\n  \n  # Retornar\n  return(H)\n}\n\n# Método Iterativo de Newton-Raphson\ninit &lt;- c(1, 1)  # Chute Inicial\ndiff &lt;- 1        # Diferença entre o passo atual e o passo anterior\nerror &lt;- 10^(-8) # Erro tolerável\nid &lt;- 1          # Contador da iteração\n\n# Iteração\nwhile (diff &gt; error) {\n  # Vetor Gradiente e Matriz Hessiana\n  U &lt;- GRADIEN(times = times, theta = init) # Vetor Gradiente\n  H &lt;- HESSIAN(times = times, theta = init) # Matriz Hessiana\n  \n  # Solução do sistema linear H %*% solution = U\n  solution &lt;- solve(H, U)\n  \n  # Atualização do Algoritmo\n  ajust &lt;- init - solution\n  \n  # Diferença entre os parâmetros\n  diff &lt;- max(abs(ajust - init))\n  \n  # Imprimir resultados na tela\n  #cat(\"Iteração:\", id, \" -  Estimativa = (Forma:\", ajust[1], \", Escala:\", ajust[2], \") \\n\")\n  \n  # Controle do Algoritmo\n  init &lt;- ajust\n  id &lt;- id + 1\n}\n\n# Impressão de resultados\ncat(\"Número de Iterações Necessárias:\", id, \"\\n\")\n\n\nNúmero de Iterações Necessárias: 47 \n\n\nCódigo\ncat(\"Estimativa para o parâmetro de forma:\", ajust[1], \"\\n\")\n\n\nEstimativa para o parâmetro de forma: 1,964 \n\n\nCódigo\ncat(\"Estimativa para o parâmetro de forma:\", ajust[2], \"\\n\")\n\n\nEstimativa para o parâmetro de forma: 1,508 \n\n\nO mesmo resultado, ou bem próximo, pode ser obtido de uma forma mais direta por meio do uso da função optim para otimização. Veja a saída obtida de tal função.\n\n\nCódigo\n# ----------------------------------------------\n# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.weib &lt;- function(times, theta) {\n  # Distição dos parâmetros\n  gamma &lt;- theta[1] # Parâmetro de forma\n  alpha &lt;- theta[2] # Parâmetro de escala\n  \n  # Ajutes de variáveis\n  t &lt;- times\n  c &lt;- rep(1, length(t))\n  \n  # Função Log-verossimilhança\n  ft &lt;- dweibull(x = t, gamma, alpha)\n  st &lt;- 1 - pweibull(q = t, gamma, alpha)\n  flv &lt;- sum(c * log(ft) + (1 - c) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- c(1, 1)\n\n# Otimização\najust &lt;- optim(\n  par = init, fn = loglikelihood.weib,\n  method = \"BFGS\", hessian = TRUE, times = times\n)\n\n# Visualização\najust\n\n\n$par\n[1] 1,964 1,508\n\n$value\n[1] 1017\n\n$counts\nfunction gradient \n      21        6 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n       [,1]   [,2]\n[1,]  477,5 -282,7\n[2,] -282,7 1696,4\n\n\nAssim como para distribuição exponencial, será feita uma comparação entre o real e estimado. Veja a Tabela 3.2 que mostra as dez observações, na ordem de simulação, e suas respectivas funções de sobrevivência, real e estimada.\n\n\nCódigo\n# Organização dos dados\ndados.weib &lt;- data.frame(\n  times = times,\n  st = survival.weib(times, shape.weib, scale.weib),\n  st.emv = survival.weib(times, ajust$par[1], ajust$par[2])\n)\n\nlibrary(knitr)\n\nknitr::kable(\n  round(head(dados.weib, 10), 4), \n  col.names = c(\"Tempo\", \"$S(t)$\", \"$\\\\hat{S}_{EMV}(t)$\"),\n  escape = FALSE,\n  align = 'c',\n  booktabs = TRUE\n)\n\n\n\n\nTabela 3.2: Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Weibull.\n\n\n\n\n\n\nTempo\n\\(S(t)\\)\n\\(\\hat{S}_{EMV}(t)\\)\n\n\n\n\n0,9081\n0,6932\n0,6912\n\n\n0,9442\n0,6729\n0,6711\n\n\n0,9776\n0,6539\n0,6524\n\n\n0,8616\n0,7190\n0,7166\n\n\n0,4288\n0,9215\n0,9189\n\n\n0,4892\n0,8991\n0,8962\n\n\n1,8050\n0,2350\n0,2408\n\n\n0,4011\n0,9310\n0,9285\n\n\n1,7208\n0,2682\n0,2735\n\n\n1,3342\n0,4533\n0,4554\n\n\n\n\n\n\n\n\nTambém foi feita a comparação entre as duas curvas de sobrevivência, ilustradas na Figura 3.5.\n\n\nCódigo\n# Organização dos dados\ndados.weib &lt;- data.frame(\n  times = sort(times),\n  st = survival.weib(sort(times), shape.weib, scale.weib),\n  st.emv = survival.weib(sort(times), ajust$par[1], ajust$par[2])\n)\n\n# Plot da função de sobrevivência\nggplot(dados.weib, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  scale_color_manual(\n    values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\"),\n    labels = c(\n      bquote(\"Verdadeiro: \" ~ gamma == .(shape.weib) ~ \";\" ~ alpha == .(scale.weib)),\n      bquote(\"EMV: \" ~ hat(gamma) == .(ajust$par[1]) ~ \";\" ~ hat(alpha) == .(ajust$par[2]))\n    )\n  ) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Parâmetro\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.5: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Weibull.\n\n\n\n\n\n\n\n\n\n\n3.3.3.3 Distribuição Log-normal\nPara a estimação dos parâmetros do modelo log-normal deve-se, também, utilizar o método numérico de Newton-Raphson. Logo, utilizaremos o método para maximar a seguinte função:\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ \\dfrac{1}{t_{i} \\sigma \\sqrt{2 \\pi}} \\exp \\left\\{- \\dfrac{1}{2} \\left(\\dfrac{\\ln(t_{i}) - \\mu}{\\sigma}\\right)^{2} \\right\\} \\right]^{\\delta_{i}} \\left[ \\Phi \\left( \\dfrac{- \\ln(t_{i}) + \\mu}{\\sigma} \\right) \\right]^{1 - \\delta_{i}}.\n\\tag{3.15}\\]\nFoi simulada uma amostra oriunda de uma distribuição log-normal com parâmetro de locação \\(\\mu = 0\\) e parâmetro de escala \\(\\sigma^{2} = 1\\) e, a partir dessa amostra, obteve-se a estimativa de máxima verossimilhança para o parâmetro \\(\\theta = (\\mu, \\sigma^{2})\\). Veja a Tabela 3.3, que apresenta as dez observações com as funções de sobrevivência real e estimada.\n\n\nCódigo\n# ---------------------\n# [3] MODELO LOG-NORMAL\n# ---------------------\n\n# Função de sobrevivência\nsurvival.lnorm &lt;- function(times, loc.par, scale.par) 1 - pnorm(q=(log(times)-loc.par)/scale.par)\n\n# ---------------------------\n# [3.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nmu &lt;- 0             # Parâmetro de locação\nsigma &lt;- 1          # Parâmetro de escala\n\n# Simulação dos dados\ntimes &lt;- rlnorm(n, meanlog = mu, sdlog = sigma)\n\n# ----------------------------------------------\n# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.lnorm &lt;- function(times, theta) {\n  # Distição dos parâmetros\n  mu &lt;- theta[1] # Parâmetro de locação\n  sigma &lt;- theta[2] # Parâmetro de escala\n  \n  # Ajutes de variáveis\n  t &lt;- times\n  c &lt;- rep(1, length(t))\n  \n  # Função Log-verossimilhança\n  ft &lt;- dlnorm(x = t, mu, sigma)\n  st &lt;- 1 - pnorm(q=(log(t) - mu) / sigma)\n  flv &lt;- sum(c * log(ft) + (1 - c) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- c(1, 0.5)\n\n# Otimização\najust &lt;- optim(\n  par = init, fn = loglikelihood.lnorm,\n  method = \"BFGS\", hessian = TRUE, times = times\n)\n\n# Visualização\najust\n\n\n$par\n[1] 0,01217 1,01342\n\n$value\n[1] 1444\n\n$counts\nfunction gradient \n      72       18 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]      [,2]\n[1,] 9,737e+02 1,271e-04\n[2,] 1,271e-04 1,947e+03\n\n\n\n\nCódigo\n# Organização dos dados\ndados.lnorm &lt;- data.frame(\n  times = times,\n  st = survival.lnorm(times, mu, sigma),\n  st.emv = survival.lnorm(times, ajust$par[1], ajust$par[2])\n)\n\nlibrary(knitr)\n\nknitr::kable(\n  round(head(dados.lnorm, 10), 4), \n  col.names = c(\"Tempo\", \"$S(t)$\", \"$\\\\hat{S}_{EMV}(t)$\"),\n  escape = FALSE,\n  align = \"c\",\n  booktabs = TRUE\n)\n\n\n\n\nTabela 3.3: Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Log-normal.\n\n\n\n\n\n\nTempo\n\\(S(t)\\)\n\\(\\hat{S}_{EMV}(t)\\)\n\n\n\n\n1,6568\n0,3068\n0,3134\n\n\n1,4857\n0,3461\n0,3525\n\n\n4,1187\n0,0785\n0,0831\n\n\n0,4856\n0,7650\n0,7657\n\n\n0,5388\n0,7318\n0,7331\n\n\n0,2096\n0,9409\n0,9399\n\n\n1,1365\n0,4491\n0,4545\n\n\n0,8547\n0,5624\n0,5663\n\n\n0,2197\n0,9352\n0,9341\n\n\n3,1950\n0,1227\n0,1284\n\n\n\n\n\n\n\n\nPara uma visualização gráfica da otimização, foi criada a Figura 3.6.\n\n\nCódigo\n# ------------------------------------\n# [1.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE\n# ------------------------------------\n\n# Organização dos dados\ndados.lnorm &lt;- data.frame(\n  times = sort(times),\n  st = survival.lnorm(sort(times), mu, sigma),\n  st.emv = survival.lnorm(sort(times), ajust$par[1], ajust$par[2])\n)\n\n# Plot da função de sobrevivência\nggplot(dados.lnorm, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  scale_color_manual(\n    values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\"),\n    labels = c(\n      bquote(\"Verdadeiro: \" ~ mu == .(mu) ~ \";\" ~ sigma == .(sigma)),\n      bquote(\"EMV: \" ~ hat(mu) == .(ajust$par[1]) ~ \";\" ~ hat(sigma) == .(ajust$par[2]))\n    )\n  ) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Parâmetro\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.6: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Log-normal.\n\n\n\n\n\n\n\n\n\n\n3.3.3.4 Distribuição Exponencial por Partes\nAssim como para as distribuições Weibull e log-normal, será aplicado o método iterativo de Newton-Raphson. Porém, para a implementação do modelo exponencial por partes será usado o pacote eha. Esse pacote contém uma vasta quantidade de funções e implementações de modelos Hazard Constant (Risco Constante). Os parâmetros escolhidos para simulação dos dados foram: \\(\\boldsymbol{\\tau} = (0,4; 1,2; 1,8)\\) e \\(\\boldsymbol{\\lambda} = (0,5; 1; 1,5; 2)\\). Salientando que os parâmetros estimados serão apenas o vetor do parâmetro de taxas. Veja, abaixo, o ajuste do modelo através da maximização da seguinte função:\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ ... \\right]^{\\delta_{i}} \\left[ ... \\right]^{1 - \\delta_{i}}.\n\\tag{3.16}\\]\n\n\nCódigo\n# ---------------------------------\n# [4] MODELO EXPONENCIAL POR PARTES\n# ---------------------------------\n\n# Função de sobrevivência\nsurvival.pch &lt;- function(times, cuts.points, levels.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)\n\n# ---------------------------\n# [3.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nrates &lt;- c(0.5, 1, 1.5, 2) # Parâmetro de escala\nbreaks &lt;- c(0.4, 1.2, 1.8) # Pontos de corte\n\n# Simulação dos dados\ntimes &lt;- rpch(n, cuts = breaks, levels = rates)\n\n# ----------------------------------------------\n# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.pch &lt;- function(par, times, cuts.points) {\n  # Ajutes de variáveis\n  t &lt;- times\n  c &lt;- rep(1, length(t))\n  \n  # Função Log-verossimilhança\n  ft &lt;- dpch(x = times, cuts = cuts.points, levels = par)\n  st &lt;- 1 - ppch(q = times, cuts = cuts.points, levels = par)\n  flv &lt;- sum(c * log(ft) + (1 - c) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- rep(1, length(rates))\n\n# Otimização\najust &lt;- optim(par=init, fn = loglikelihood.pch, \n               gr = NULL, method = \"BFGS\", hessian = TRUE, \n               times=times, cuts.points=breaks)\n\n# Visualização\najust\n\n\n$par\n[1] 0,5011 0,9831 1,4345 2,2094\n\n$value\n[1] 926,2\n\n$counts\nfunction gradient \n      52       13 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n           [,1]       [,2]      [,3]      [,4]\n[1,]  7,209e+02 -2,842e-08 0,000e+00 2,842e-08\n[2,] -2,842e-08  4,574e+02 0,000e+00 2,842e-08\n[3,]  0,000e+00  0,000e+00 1,040e+02 2,842e-08\n[4,]  2,842e-08  2,842e-08 2,842e-08 3,339e+01\n\n\nDe forma semelhante aos demais modelos, será feita uma comparação da função de sobrevivência por meio da Tabela 3.4 e Figura 3.7. Mostradas a seguir.\n\n\nCódigo\n# Organização dos dados\ndados.pch &lt;- data.frame(\n  times = times,\n  st = survival.pch(times, breaks, rates),\n  st.emv = survival.pch(times, breaks, ajust$par)\n)\n\nlibrary(knitr)\n\nknitr::kable(\n  round(head(dados.pch, 10), 4), \n  col.names = c(\"Tempo\", \"$S(t)$\", \"$\\\\hat{S}_{EMV}(t)$\"),\n  escape = FALSE,\n  align = \"c\",\n  booktabs = TRUE\n)\n\n\n\n\nTabela 3.4: Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Exponencial por Partes.\n\n\n\n\n\n\nTempo\n\\(S(t)\\)\n\\(\\hat{S}_{EMV}(t)\\)\n\n\n\n\n1,3210\n0,3068\n0,3133\n\n\n1,2783\n0,3271\n0,3331\n\n\n1,2407\n0,3461\n0,3516\n\n\n1,3796\n0,2810\n0,2881\n\n\n2,1226\n0,0785\n0,0773\n\n\n1,9968\n0,1009\n0,1020\n\n\n0,4679\n0,7650\n0,7655\n\n\n2,1868\n0,0690\n0,0671\n\n\n0,5122\n0,7318\n0,7329\n\n\n0,8039\n0,5467\n0,5502\n\n\n\n\n\n\n\n\n\n\nCódigo\n# ------------------------------------\n# [1.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE\n# ------------------------------------\n\n# Organização dos dados\ndados.pch &lt;- data.frame(\n  times = sort(times),\n  st = survival.pch(sort(times), breaks, rates),\n  st.emv = survival.pch(sort(times), breaks, ajust$par)\n)\n\n# Plot da função de sobrevivência\nggplot(dados.pch, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  scale_color_manual(\n    values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\"),\n  ) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Parâmetro\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.7: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes.\n\n\n\n\n\n\n\n\n\n\n3.3.3.5 Distribuição Exponencial por Partes de Potência\nAssim como para as distribuições anteriores, com excessão da distribuição exponencial clássica, o modelo exponencial por partes de potência requer a utilização do método numérico descrito na Seção 3.3.2. Para simulação dos dados foi usado como pontos de corte \\(\\boldsymbol{\\tau} = (0,4; 1,2; 1,8)\\), parâmetros de taxa \\(\\boldsymbol{\\lambda} = (0,5; 1; 1,5; 2)\\) e parâmetro de potência \\(\\eta = 3/2\\). As estimativas são obtidas maximizando a função:\n\\[\nL(\\theta) = \\prod_{i = 1}^{n} \\left[ ... \\right]^{\\delta_{i}} \\left[ ... \\right]^{1 - \\delta_{i}}.\n\\tag{3.17}\\]\n\n\nCódigo\n# ---------------------------------------------\n# [5] MODELO EXPONENCIAL POR PARTES DE POTÊNCIA\n# ---------------------------------------------\n\n# Função de sobrevivência\nsurvival.pchp &lt;- function(times, cuts.points, levels.par, power.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)^power.par\n\n# ---------------------------\n# [3.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nrates &lt;- c(0.5, 1, 1.5, 2) # Parâmetros de taxa\nbreaks &lt;- c(0.4, 1.2, 1.8) # Pontos de corte\npower &lt;- 3/2\n\n# Funções de Simulação\ntime &lt;- function(t, cuts.points=cuts.points, rates.par=rates.par, power.par=power.par, u.unif) {\n  surv &lt;- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par\n  return(surv - u.unif)\n}\n\ngen.pchp &lt;- function(n, cuts.points, rates.par, power.par) {\n  # Vetor para armazenar os tempos gerados\n  pchp.times &lt;- numeric(n)\n  \n  for (i in 1:n) {\n    # Gerando um único valor de U para cada iteração\n    u &lt;- runif(1)\n    \n    # Encontrando a raiz para cada observação\n    raiz &lt;- uniroot(\n      time, interval = c(0, 10000), cuts.points = cuts.points, \n      rates.par = rates.par, power.par = power.par, u.unif = u\n    )\n    \n    pchp.times[i] &lt;- raiz$root\n  }\n  \n  return(pchp.times)\n}\n\n# Simulação dos dados\ntimes &lt;- gen.pchp(n, cuts.points = breaks, rates.par = rates, power.par = power)\n\n# ----------------------------------------------\n# [2.1.2] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.pchp &lt;- function(par, times, cuts.points) {\n  # Ajuste de Parâmetros\n  n.par &lt;- length(par)\n  n.cuts &lt;- length(cuts.points)\n  rates.par &lt;- par[1:(n.cuts + 1)]\n  power.par &lt;- par[n.par]\n  \n  # Ajutes de variáveis\n  t &lt;- times\n  c &lt;- rep(1, length(t))\n  \n  # Função Log-verossimilhança\n  ft &lt;- power.par*(ppch(q=t, cuts=cuts.points, levels=rates.par))^(power.par-1)*dpch(x=t, cuts=cuts.points, levels=rates.par)\n  st &lt;- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par\n  flv &lt;- sum(c * log(ft) + (1 - c) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- rep(1, length(rates) + 1)\n\n# Otimização\najust &lt;- optim(par=init, fn = loglikelihood.pchp, \n               gr = NULL, method = \"BFGS\", hessian = TRUE, \n               times=times, cuts.points=breaks)\n\n# Visualização\najust\n\n\n$par\n[1] 0,3907 0,9449 1,4424 1,9043 1,3467\n\n$value\n[1] 1011\n\n$counts\nfunction gradient \n      70       20 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]     [,2]    [,3]    [,4]     [,5]\n[1,]  838,0649   98,460   6,477  0,7767 -572,329\n[2,]   98,4597  583,608  12,953  1,5534 -315,284\n[3,]    6,4765   12,953 141,697  1,1651  -36,677\n[4,]    0,7767    1,553   1,165 61,9192   -5,166\n[5,] -572,3294 -315,284 -36,677 -5,1664  551,421\n\n\nVeja a Tabela 3.5 e a Figura 3.8, que apresenta uma comparação da função de sobrevivência real e estimada.\n\n\nCódigo\n# Organização dos dados\ndados.pchp &lt;- data.frame(\n  times = times,\n  st = survival.pchp(times, breaks, rates, power),\n  st.emv = survival.pchp(times, breaks, ajust$par[1:(length(ajust$par)-1)], ajust$par[length(ajust$par)])\n)\n\nlibrary(knitr)\n\nknitr::kable(\n  round(head(dados.pchp, 10), 4), \n  col.names = c(\"Tempo\", \"$S(t)$\", \"$\\\\hat{S}_{EMV}(t)$\"),\n  escape = FALSE,\n  align = \"c\",\n  booktabs = TRUE\n)\n\n\n\n\nTabela 3.5: Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Exponencial por Partes de Potência.\n\n\n\n\n\n\nTempo\n\\(S(t)\\)\n\\(\\hat{S}_{EMV}(t)\\)\n\n\n\n\n0,8068\n0,6932\n0,6914\n\n\n0,8439\n0,6729\n0,6713\n\n\n0,8791\n0,6539\n0,6525\n\n\n0,7604\n0,7190\n0,7171\n\n\n0,4024\n0,9215\n0,9246\n\n\n0,4443\n0,8991\n0,9009\n\n\n1,7403\n0,2350\n0,2398\n\n\n0,3684\n0,9310\n0,9332\n\n\n1,6479\n0,2682\n0,2726\n\n\n1,2696\n0,4533\n0,4555\n\n\n\n\n\n\n\n\n\n\nCódigo\n# ------------------------------------\n# [1.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE\n# ------------------------------------\n\n# Organização dos dados\ndados.pchp &lt;- data.frame(\n  times = sort(times),\n  st = survival.pchp(sort(times), breaks, rates, power),\n  st.emv = survival.pchp(sort(times), breaks, ajust$par[1:(length(ajust$par)-1)], ajust$par[length(ajust$par)])\n)\n\n# Plot da função de sobrevivência\nggplot(dados.pchp, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  scale_color_manual(\n    values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\"),\n  ) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Parâmetro\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.8: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes de Potência.\n\n\n\n\n\n\n\n\n\n\n\n3.3.4 Aplicações Caso Haja Censura\nPara exemplicação de ajustes dos modelos probabilísticos que foram propostos aqui à dados censurados, fixamos que os dados censurados como dados provenientes de uma distribuição exponencial com parâmetro de taxa \\(\\alpha = 1\\). Isto é, seja \\(C\\) uma variável aleatória, que representa os tempos de eventos censurados, tal quer \\(C \\sim Exp(1)\\).\nJá a distribuição do tempo de evento, de fato, foi variada entre os modelos aqui propostos, logo, foram simulados tempos de evento segundo os modelos: \\(Weibull(2; 1,5)\\), \\(Lognormal(1, 2^{2})\\), \\(EP()\\) e \\(EPP()\\). Os tempos observados foram definidos de forma que, para cada unidade amostral, o tempo observado foi definido como a menor realização entre as duas distribuições em análise, ou seja:\n\\[t_{i} = min(T_{i}, C_{i}).\\]\nA censura ocorre quando o tempo de observação não corresponde ao tempo real de falha, ou seja, quando \\(C_{i} &lt; T_{i}\\). Nesse caso, o evento de interesse não foi completamente observado, sendo conhecido apenas que o verdadeiro tempo de falha excede o valor registrado. Essa característica, fundamental na análise de sobrevivência, requer métodos estatísticos específicos para garantir inferências adequadas a partir de dados censurados.\nSanando uma possível dúvida, que possa surgir da parte do leitor. Foi fixada para distribuição dos tempos de evento censurados a distribuição exponencial sem qualquer motivo em especial. Tendo em vista que a distribuição dos tempos de evento censurados não está sendo analisada. O obejto desta seção é apenas mostrar como os tempos censurados interferem na precisão das estimativas.\n\n3.3.4.1 Modelo Weibull\nIniciando as exemplificações com a implementação do modelo Weibull. Veja a saída do ajuste para a distribuição \\(Weibull(2; 1,5)\\).\n\n\nCódigo\n# ------------------\n# [1] MODELO WEIBULL\n# ------------------\n\n# Função de sobrevivência\nsurvival.weib &lt;- function(times,shape.par,scale.par) 1 - pweibull(q=times, shape=shape.par, scale=scale.par)\n\n# ---------------------------\n# [1.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nshape.weib &lt;- 2     # Parâmetro de forma\nscale.weib &lt;- 1.5   # Parâmetro de escala\nrate.exp &lt;- 1       # Parâmetro de taxa da exponencial (censura)\n\n# Simulação dos dados\nt &lt;- rweibull(n, shape.weib, scale.weib) # Tempos de evento\nc &lt;- rexp(n, rate = rate.exp)            # Tempos censurados\ntimes &lt;- pmin(t, c)                      # Tempos observados\ndelta &lt;- as.numeric(t &lt;= c)              # Variável indicadora\n\n# ----------------------------------------------\n# [1.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.weib &lt;- function(par, times, cens) {\n  # Distição dos parâmetros\n  gamma &lt;- par[1] # Parâmetro de forma\n  alpha &lt;- par[2] # Parâmetro de escala\n  \n  # Função Log-verossimilhança\n  ft &lt;- dweibull(x = times, gamma, alpha)\n  st &lt;- 1 - pweibull(q = times, gamma, alpha)\n  flv &lt;- sum(cens * log(ft) + (1 - cens) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- c(1, 1)\n\n# Otimização\najust &lt;- optim(\n  par = init, fn = loglikelihood.weib, method = \"BFGS\", \n  hessian = TRUE, times = times, cens = delta\n)\n\n# Visualização\najust\n\n\n$par\n[1] 1,911 1,533\n\n$value\n[1] 449,5\n\n$counts\nfunction gradient \n      28        7 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n       [,1]   [,2]\n[1,] 187,59  78,67\n[2,]  78,67 485,05\n\n\nA seguir, uma visualização gráfica do ajuste ilustrada pela Figura 3.9.\n\n\nCódigo\n# Estimador de Kaplan-Meier\n#ekm &lt;- survfit(Surv(times, delta)~1)\n\n# Organização dos dados\ndados.weib &lt;- data.frame(\n  times = sort(times),\n  st = survival.weib(sort(times), shape.weib, scale.weib),\n  #st.ekm = ekm$surv,\n  st.emv = survival.weib(sort(times), ajust$par[1], ajust$par[2])\n)\n\n# Plot da função de sobrevivência\nggplot(dados.weib, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  #geom_line(aes(y = st.ekm, color = \"KM\"), lwd = 1, lty = 2) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  #scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"KM\" = \"blue\", \"EMV\" = \"red\")) +\n  scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\")) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Sobrevida\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.9: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Weibull para Dados Censurados.\n\n\n\n\n\n\n\n\n\n\n3.3.4.2 Modelo Log-normal\nA segunda implementação feita, foi do modelo log-normal. Veja a saída do ajuste para a distribuição \\(Lognormal(1, 2^{2})\\).\n\n\nCódigo\n# ---------------------\n# [2] MODELO LOG-NORMAL\n# ---------------------\n\n# Função de sobrevivência\nsurvival.lnorm &lt;- function(times, loc.par, scale.par) 1 - pnorm(q=(log(times)-loc.par)/scale.par)\n\n# ---------------------------\n# [2.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nmu &lt;- 1             # Parâmetro de locação\nsigma &lt;- 2          # Parâmetro de escala\nrate.exp &lt;- 1       # Parâmetro de taxa da exponencial (censura)\n\n# Simulação dos dados\nt &lt;- rlnorm(n, meanlog = mu, sdlog = sigma) # Tempos de evento\nc &lt;- rexp(n, rate = rate.exp)               # Tempos censurados\ntimes &lt;- pmin(t, c)                         # Tempos observados\ndelta &lt;- as.numeric(t &lt;= c)                 # Variável indicadora\n\n# ----------------------------------------------\n# [2.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.lnorm &lt;- function(par, times, cens) {\n  # Distição dos parâmetros\n  mu &lt;- par[1] # Parâmetro de locação\n  sigma &lt;- par[2] # Parâmetro de escala\n  \n  # Função Log-verossimilhança\n  ft &lt;- dlnorm(x = times, mu, sigma)\n  st &lt;- 1 - pnorm(q=(log(times) - mu) / sigma)\n  flv &lt;- sum(cens * log(ft) + (1 - cens) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- c(0.5, 0.5)\n\n# Otimização\najust &lt;- optim(\n  par = init, fn = loglikelihood.lnorm, method = \"BFGS\", \n  hessian = TRUE, times = times, cens = delta\n)\n\n# Visualização\najust\n\n\n$par\n[1] 1,139 2,090\n\n$value\n[1] 480,5\n\n$counts\nfunction gradient \n      78       35 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n       [,1]   [,2]\n[1,]  121,3 -109,5\n[2,] -109,5  193,9\n\n\nA seguir, uma visualização gráfica do ajuste ilustrada pela Figura 3.10.\n\n\nCódigo\n# ------------------------------------\n# [2.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE\n# ------------------------------------\n\n# Estimador de Kaplan-Meier\n#ekm &lt;- survfit(Surv(times, delta)~1)\n\n# Organização dos dados\ndados.lnorm &lt;- data.frame(\n  times = sort(times),\n  st = survival.lnorm(sort(times), mu, sigma),\n  #st.ekm = ekm$surv,\n  st.emv = survival.lnorm(sort(times), ajust$par[1], ajust$par[2])\n)\n\n# Plot da função de sobrevivência\nggplot(dados.lnorm, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  #geom_line(aes(y = st.ekm, color = \"KM\"), lwd = 1, lty = 2) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  #scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"KM\" = \"blue\", \"EMV\" = \"red\")) +\n  scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\")) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Sobrevida\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.10: Comparação de Dez Observações entre o valor Real e o Estimado por Máxima Verossimilhança da Função de Sobrevivência segundo o Modelo Log-normal para Dados Censurados.\n\n\n\n\n\n\n\n\n\n\n3.3.4.3 Distribuição Exponencial por Partes\nFazendo uma implementação do modelo exponencial por partes para dados censurados. A saída do ajuste está logo abaixo para a distribuição \\(EP()\\).\n\n\nCódigo\n# ---------------------------------\n# [3] MODELO EXPONENCIAL POR PARTES\n# ---------------------------------\n\n# Função de sobrevivência\nsurvival.pch &lt;- function(times, cuts.points, levels.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)\n\n# ---------------------------\n# [3.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nrates &lt;- c(0.5, 1, 1.5, 2) # Parâmetro de escala\nbreaks &lt;- c(0.4, 1.2, 1.8) # Pontos de corte\nrate.exp &lt;- 1       # Parâmetro de taxa da exponencial (censura)\n\n# Simulação dos dados\nt &lt;- rpch(n, cuts = breaks, levels = rates) # Tempos de evento\nc &lt;- rexp(n, rate = rate.exp)               # Tempos censurados\ntimes &lt;- pmin(t, c)                         # Tempos observados\ndelta &lt;- as.numeric(t &lt;= c)                 # Variável indicadora\n\n# ----------------------------------------------\n# [3.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.pch &lt;- function(par, times, cens, cuts.points) {\n  \n  # Função Log-verossimilhança\n  ft &lt;- dpch(x = times, cuts = cuts.points, levels = par)\n  st &lt;- 1 - ppch(q = times, cuts = cuts.points, levels = par)\n  flv &lt;- sum(cens * log(ft) + (1 - cens) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- rep(1, length(rates))\n\n# Otimização\najust &lt;- optim(par=init, fn = loglikelihood.pch, \n               gr = NULL, method = \"BFGS\", hessian = TRUE, \n               times=times, cens=delta, cuts.points=breaks)\n\n# Visualização\najust\n\n\n$par\n[1] 0,4907 1,0450 1,3908 2,0843\n\n$value\n[1] 504,7\n\n$counts\nfunction gradient \n      26       10 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n           [,1]       [,2]       [,3]  [,4]\n[1,]  6,063e+02 -1,421e-08  7,105e-09 0,000\n[2,] -1,421e-08  2,042e+02 -1,421e-08 0,000\n[3,]  7,105e-09 -1,421e-08  2,740e+01 0,000\n[4,]  0,000e+00  0,000e+00  0,000e+00 5,294\n\n\nA Figura 3.11 mostra o ajuste de forma gráfica fazendo uma comparação de curvas de sobrevivência.\n\n\nCódigo\n# ------------------------------------\n# [3.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE\n# ------------------------------------\n\n# Estimador de Kaplan-Meier\n#ekm &lt;- survfit(Surv(times, delta)~1)\n\n# Organização dos dados\ndados.pch &lt;- data.frame(\n  times = sort(times),\n  st = survival.pch(sort(times), breaks, rates),\n  #st.ekm = ekm$surv,\n  st.emv = survival.pch(sort(times), breaks, ajust$par)\n)\n\n# Plot da função de sobrevivência\nggplot(dados.pch, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  #geom_line(aes(y = st.ekm, color = \"KM\"), lwd = 1, lty = 2) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  #scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"KM\" = \"blue\", \"EMV\" = \"red\")) +\n  scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\")) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Sobrevida\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.11: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes para Dados Censurados.\n\n\n\n\n\n\n\n\n\n\n3.3.4.4 Distribuição Exponencial por Partes de Potência\nPor fim, é apresentado o ajuste para a distribuição \\(EPP()\\).\n\n\nCódigo\n# ---------------------------------------------\n# [4] MODELO EXPONENCIAL POR PARTES DE POTÊNCIA\n# ---------------------------------------------\n\n# Função de sobrevivência\nsurvival.pchp &lt;- function(times, cuts.points, levels.par, power.par) 1 - ppch(q=times, cuts=cuts.points, levels=levels.par)^power.par\n\n# ---------------------------\n# [4.1] SIMULAÇÃO E ESTIMAÇÃO\n# ---------------------------\n\n# Parâmetros de simulação\nset.seed(123456789) # Semente aleatória\nn &lt;- 1000           # Tamanho amostral\nrates &lt;- c(0.5, 1, 1.5, 2) # Parâmetros de taxa\nbreaks &lt;- c(0.4, 1.2, 1.8) # Pontos de corte\npower &lt;- 3/2               # Parâmetro de potência\nrate.exp &lt;- 1             # Parâmetro de taxa da exponencial (censura)\n\n# Funções de Simulação\ntime &lt;- function(t, cuts.points=cuts.points, rates.par=rates.par, power.par=power.par, u.unif) {\n  surv &lt;- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par\n  return(surv - u.unif)\n}\n\ngen.pchp &lt;- function(n, cuts.points, rates.par, power.par) {\n  # Vetor para armazenar os tempos gerados\n  pchp.times &lt;- numeric(n)\n  \n  for (i in 1:n) {\n    # Gerando um único valor de U para cada iteração\n    u &lt;- runif(1)\n    \n    # Encontrando a raiz para cada observação\n    raiz &lt;- uniroot(\n      time, interval = c(0, 10000), cuts.points = cuts.points, \n      rates.par = rates.par, power.par = power.par, u.unif = u\n    )\n    \n    pchp.times[i] &lt;- raiz$root\n  }\n  \n  return(pchp.times)\n}\n\n# Simulação dos dados\nt &lt;- gen.pchp(n, cuts.points=breaks, rates.par=rates, power.par=power) # Tempos de evento\nc &lt;- rexp(n, rate = rate.exp)               # Tempos censurados\ntimes &lt;- pmin(t, c)                         # Tempos observados\ndelta &lt;- as.numeric(t &lt;= c)                 # Variável indicadora\n\n# ----------------------------------------------\n# [4.1.1] IMPLEMENTAÇÃO COM FUNÇÃO DE OTIMIZAÇÃO\n# ----------------------------------------------\n\n# Definir a função log-verossimilhança\nloglikelihood.pchp &lt;- function(par, times, cens, cuts.points) {\n  # Ajuste de Parâmetros\n  n.par &lt;- length(par)\n  n.cuts &lt;- length(cuts.points)\n  rates.par &lt;- par[1:(n.cuts + 1)]\n  power.par &lt;- par[n.par]\n  \n  # Ajutes de variáveis\n  t &lt;- times\n  \n  # Função Log-verossimilhança\n  ft &lt;- power.par*(ppch(q=t, cuts=cuts.points, levels=rates.par))^(power.par-1)*dpch(x=t, cuts=cuts.points, levels=rates.par)\n  st &lt;- 1 - ppch(q = t, cuts = cuts.points, levels = rates.par)^power.par\n  flv &lt;- sum(cens * log(ft) + (1 - cens) * log(st))\n  \n  # Retorna o valor simétrico\n  return(-flv)\n}\n\n# Chute Inicial\ninit &lt;- rep(1, length(rates) + 1)\n\n# Otimização\najust &lt;- optim(par=init, fn = loglikelihood.pchp, \n               gr = NULL, method = \"BFGS\", hessian = TRUE, \n               times=times, cens=delta, cuts.points=breaks)\n\n# Visualização\najust\n\n\n$par\n[1] 0,3853 0,9786 1,3719 1,4265 1,3525\n\n$value\n[1] 461\n\n$counts\nfunction gradient \n      40       13 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n          [,1]      [,2]    [,3]    [,4]      [,5]\n[1,]  668,6728   51,1112  1,5572  0,1151 -450,8718\n[2,]   51,1112  254,4160  3,1144  0,2303 -153,0120\n[3,]    1,5572    3,1144 33,9231  0,1727   -8,6832\n[4,]    0,1151    0,2303  0,1727  9,4803   -0,7445\n[5,] -450,8718 -153,0120 -8,6832 -0,7445  397,0270\n\n\nA seguir, tem-se a comparação das curvas de sobrevivência real e estimada, desenhada na Figura 3.12, para os dados simulados com censura.\n\n\nCódigo\n# ------------------------------------\n# [4.2] VISUALIZAÇÃO GRÁFICA DO AJUSTE\n# ------------------------------------\n\n# Estimador de Kaplan-Meier\n#ekm &lt;- survfit(Surv(times, delta)~1)\n\n# Organização dos dados\ndados.pchp &lt;- data.frame(\n  times = sort(times),\n  st = survival.pchp(sort(times), breaks, rates, power),\n  #st.ekm = ekm$surv,\n  st.emv = survival.pchp(sort(times), breaks, ajust$par[1:(length(ajust$par)-1)], ajust$par[length(ajust$par)])\n)\n\n# Plot da função de sobrevivência\nggplot(dados.pchp, aes(x = times)) +\n  geom_line(aes(y = st, color = \"Verdadeiro\"), lwd = 1) +\n  #geom_line(aes(y = st.ekm, color = \"KM\"), lwd = 1, lty = 2) +\n  geom_line(aes(y = st.emv, color = \"EMV\"), lwd = 1, lty = 4) +\n  #scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"KM\" = \"blue\", \"EMV\" = \"red\")) +\n  scale_color_manual(values = c(\"Verdadeiro\" = \"black\", \"EMV\" = \"red\")) +\n  labs(x = \"Tempo\", y = \"Probabilidade de Sobrevivência\", color = \"Sobrevida\") +\n  theme_minimal(base_size = 11) +\n  theme(legend.position = \"top\")\n\n\n\n\n\nFigura 3.12: Comparação das Curvas de Sobrevivência Real e Estimada por Máxima Verossimilhança segundo o Modelo Exponencial por Partes de Potência para Dados Censurados.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBussab, Wilton de Oliveira, e Pedro Alberto Morettin. 2010. Estatística Básica. 6ª ed. São Paulo: Saraiva.\n\n\nColosimo, Enrico Antonio, e Suely Ruiz Giolo. 2006. Análise de Sobrevivência Aplicada. 1.ª ed. São Paulo, Brasil: Blucher.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Técnicas Paramétricas - Modelos Probabilísticos</span>"
    ]
  },
  {
    "objectID": "CIV_MAFT.html",
    "href": "CIV_MAFT.html",
    "title": "4  Modelos de Tempo de Vida Acelerado",
    "section": "",
    "text": "4.1 Introdução\nNo capítulo anterior, foram apresentados modelos paramétricos para dados de sobrevivência. Entretanto, esses modelos não contemplam a inclusão de covariáveis na análise do tempo de sobrevivência. Neste capítulo, exploraremos esse método.\nNo modelo de regressão linear clássico, a relação entre a variável resposta \\(Y\\) e as covariáveis \\(\\mathbf{x'}\\) é aditiva, ou seja, mudanças nas covariáveis alteram \\(Y\\) de maneira linear. O modelo de regressão linear clássico é expresso como:\n\\[\nY = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} + \\ldots + \\beta_{p} X_{p} + \\varepsilon,\n\\tag{4.1}\\]\nonde \\(\\varepsilon\\) é a parte estocástica (erro) que segue uma distribuição \\(Normal(0, \\sigma^{2})\\).\nNo entanto, em análise de sobrevivência, essa suposição não se sustenta, pois o efeito das covariáveis geralmente acelera ou retarda o tempo de falha, tornando necessária uma abordagem multiplicativa. Este modelo de regressão é chamado de Modelo de Tempo de Vida Acelerado (Accelerated Failure Time - AFT).\nNo modelo AFT, assume-se que o tempo de falha \\(T\\) é afetado por um fator de aceleração exponencial das covariáveis. Esse fator multiplicativo indica se o tempo até o evento será prolongado ou encurtado. Assim, o modelo é definido como:\n\\[\nT = \\exp\\{ \\mathbf{x'} \\boldsymbol{\\beta} \\} \\varepsilon = \\exp\\{ \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} \\ldots + \\beta_{p} X_{p} \\} \\varepsilon,\n\\tag{4.2}\\]\nonde \\(\\varepsilon\\) é um termo de erro multiplicativo que captura a variabilidade não explicada pelas covariáveis. Aplicando a transformação logarítmica em \\(T\\) obtém-se a forma linearizável de Equação 4.2 que aproxima-se da Equação 4.1, de forma que\n\\[\n\\ln[T] = \\beta_{0} + \\beta_{1} X_{1} + \\beta_{2} X_{2} \\ldots + \\beta_{p} X_{p} + v,\n\\]\nonde \\(v = \\ln[\\varepsilon]\\) segue uma distribuição de valor extremo. Essa escolha para a distribuição dos erros decorre do fato de que os tempos de sobrevivência frequentemente apresentam forte assimetria à direita. Portanto, os erros não podem ser adequadamente representados por uma distribuição normal, sendo mais apropriado assumir distribuições como Log-normal, Weibull ou Exponencial.\nNos modelos AFT, a função de sobrevivência sofre um ajuste devido ao efeito das covariáveis, que podem acelerar ou retardar o tempo de falha. Assim, a função de sobrevivência condicional às covariáveis é expressa como:\n\\[\nS (t | x) = P (T &gt; t / \\exp\\{ \\mathbf{x'} \\boldsymbol{\\beta}\\}).\n\\tag{4.3}\\]\nComo o tempo de falha é ajustado pelo fator de aceleração, a função de risco também precisa ser reformulada para incorporar o efeito das covariáveis. A forma geral da função de risco em modelos AFT é dada por:\n\\[\n\\lambda(t | \\mathbf{x}) = \\lambda_{0}(t) g(\\mathbf{x}).\n\\tag{4.4}\\]\nNesta expressão, \\(\\lambda_{0}(t)\\), representa a função de risco basal, isto é, representa o risco no tempo \\(t\\) quando todas as covariáveis são iguais a zero, ou seja, na ausência de efeitos das covariáveis. Já o termo \\(g(\\mathbf{x}) = \\exp\\{ - \\mathbf{x'} \\boldsymbol{\\beta} \\}\\) age como um fator de ajuste, mensurando o impacto das covariáveis na taxa de falha.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos de Tempo de Vida Acelerado</span>"
    ]
  },
  {
    "objectID": "CIV_MAFT.html#modelo-exponencial",
    "href": "CIV_MAFT.html#modelo-exponencial",
    "title": "4  Modelos de Tempo de Vida Acelerado",
    "section": "4.2 Modelo Exponencial",
    "text": "4.2 Modelo Exponencial\nEm modelos AFT, a função de sobrevivência à distribuição exponencial é expressa por:\n\\[\nS (t | x) = \\exp \\left\\{- \\alpha \\left( \\dfrac{t}{\\exp\\{ \\mathbf{x'} \\boldsymbol{\\beta} \\}} \\right) \\right\\}.\n\\tag{4.5}\\]\nCom função de risco dada por:\n\\[\n\\lambda(t | \\mathbf{x}) = \\alpha \\exp\\{ - \\mathbf{x'} \\boldsymbol{\\beta} \\}.\n\\tag{4.6}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos de Tempo de Vida Acelerado</span>"
    ]
  },
  {
    "objectID": "CIV_MAFT.html#modelo-weibull",
    "href": "CIV_MAFT.html#modelo-weibull",
    "title": "4  Modelos de Tempo de Vida Acelerado",
    "section": "4.3 Modelo Weibull",
    "text": "4.3 Modelo Weibull\nPara modelos AFT, baseados na distribuição Weibull, a função de sobrevivência é dada por:\n\\[\nS (t | x) = \\exp \\left\\{ - \\left( \\dfrac{t}{\\alpha \\exp\\{ - \\mathbf{x'} \\boldsymbol{\\beta} \\} } \\right)^{\\gamma} \\right\\}.\n\\tag{4.7}\\]\nAssim, pode-se escrever a função de risco da distribuição Weibull como:\n\\[\n\\lambda(t | \\mathbf{x}) = \\dfrac{ \\gamma }{ \\alpha^{\\gamma} } t^{\\gamma - 1} \\exp\\{ - \\mathbf{x'} \\boldsymbol{\\beta} \\}\n\\tag{4.8}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos de Tempo de Vida Acelerado</span>"
    ]
  },
  {
    "objectID": "CIV_MAFT.html#modelo-exponencial-por-partes",
    "href": "CIV_MAFT.html#modelo-exponencial-por-partes",
    "title": "4  Modelos de Tempo de Vida Acelerado",
    "section": "4.4 Modelo Exponencial por Partes",
    "text": "4.4 Modelo Exponencial por Partes\n[…]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos de Tempo de Vida Acelerado</span>"
    ]
  },
  {
    "objectID": "CIV_MAFT.html#estimação-de-parâmetros",
    "href": "CIV_MAFT.html#estimação-de-parâmetros",
    "title": "4  Modelos de Tempo de Vida Acelerado",
    "section": "4.5 Estimação de Parâmetros",
    "text": "4.5 Estimação de Parâmetros\nAssim como no capítulo anterior, a estimação dos parâmetros será realizada pelo método de máxima verossimilhança. Recordando que a função de verossimilhança para dados censurados é expressa como:\n\\[\\begin{align*}\nL(\\theta) & = \\prod_{i = 1}^{n} \\left[f(t_{i} | \\mathbf{x}) \\right]^{\\delta_{i}} \\left[S(t_{i} | \\mathbf{x}) \\right]^{1 - \\delta_{i}} \\\\\n          & = \\prod_{i = 1}^{n} \\left[\\lambda(t_{i} | \\mathbf{x}) \\right]^{\\delta_{i}} S(t_{i} | \\mathbf{x}),\n\\end{align*}\\]\nonde:\n\n\\(\\delta_{i}\\) é a variável indicadora, assumindo \\(1\\) se \\(t_{i}\\) for um tempo de falha observado e \\(0\\) se for censurado;\n\\(f(t_{i}|\\mathbf{x})\\) representa a função densidade de probabilidade condicional;\n\\(S(t_{i}|\\mathbf{x})\\) é a função de sobrevivência condicional;\n\\(\\lambda(t_{i}|\\mathbf{x})\\) corresponde à função de risco condicional.\n\nO estimador de máxima verossimilhança (EMV) para \\(\\theta\\) é obtido maximizando a função de log-verossimilhança, dada por:\n\\[\n\\ln{L(\\theta)} = \\sum_{i = 1}^{n} \\delta_{i} \\ln{\\lambda(t_{i}|\\mathbf{x})} + \\ln{S(t_{i}|\\mathbf{x})}.\n\\]\nPortanto, o parâmetro ou o conjunto de parâmetros \\(\\theta\\) que maximiza \\(\\ln{L(\\theta)}\\) representa a melhor estimativa para a amostra observada, sendo obtido por métodos numéricos como o Newton-Raphson.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos de Tempo de Vida Acelerado</span>"
    ]
  },
  {
    "objectID": "CIV_MAFT.html#implementação-computacional",
    "href": "CIV_MAFT.html#implementação-computacional",
    "title": "4  Modelos de Tempo de Vida Acelerado",
    "section": "4.6 Implementação Computacional",
    "text": "4.6 Implementação Computacional\n\n4.6.1 Modelo Exponencial\n\n4.6.1.1 Geração dos Dados\n\nFunções de Geração:\n\nPode-se simular dados de sobrevivência conforme um modelo AFT baseado na distribuição exponencial através da expressão: \\[\nT = - \\dfrac{\\exp\\{\\mathbf{x'} \\boldsymbol{\\beta}\\} \\ln{[1 - U]} }{\\alpha},\n\\]\nonde \\(U \\sim Uniforme(0, 1)\\). Sendo este o Método da Tranformação da Inversa.\n\n\nCódigo\ntime &lt;- function(t=t, alpha.par=alpha.par, beta.par=beta.par, x.mat=x.mat, u.unif=u.unif){\n  1 - pexp(q = t/exp(x.mat%*%beta.par), rate = alpha.par) - u.unif\n}\n\ngen.exp &lt;- function(alpha.par=alpha.par, beta.par=beta.par, x.mat=x.mat){\n  raiz &lt;- uniroot(\n    time, c(0, 10000), alpha.par=alpha.par, beta.par=beta.par,\n    x.mat=x.mat, u.unif=runif(1)\n  )\n  \n  exp.time &lt;- raiz$root\n}\n\nsim.data &lt;- function(n=n, alpha.par=alpha.par, beta.par=beta.par, x.mat=x.mat, alpha.parc=alpha.parc){\n  t &lt;- rep(0, n)     # Tempo de falha\n  c &lt;- rep(0, n)     # Tempo de censura\n  times &lt;- rep(0, n) # Tempo observado\n  \n  # Iteração\n  for (i in 1:n){\n    t[i] &lt;- gen.exp(alpha.par=alpha.par, beta.par=beta.par, x.mat=x.mat[i, ])\n    c[i] &lt;- rexp(1, rate = alpha.parc)\n    times[i] &lt;- min(t[i], c[i])\n  }\n  \n  # Tempos Observados\n  delta &lt;- ifelse(t &lt;= c, 1, 0)\n  dados &lt;- data.frame(times, delta, x.mat)\n  return(dados)\n}\n\n\n\nSimulação dos dados:\n\n\n\nCódigo\nset.seed(123456789)\n\n# Tamanho da amostra e número de variáveis\nn &lt;- 1000\n\n# Parâmetro da distribuição exponencial\ntaxa &lt;- 1.5\n\n# Matriz Design\nx1 &lt;- rbinom(n = n, size = 1, prob=0.5)\nx2 &lt;- rnorm(n=n)\nX &lt;- cbind(1, x1, x2)\n\n# Vetor de Coeficientes Betas\nbetas &lt;- c(0.5, -0.5, 0.5)\n\n# Simulando o Tempo de Sobrevivência\ndados &lt;- sim.data(n = n, alpha.par = taxa, beta.par = betas, x.mat = X, alpha.parc=taxa)\n\n# Proporção de Falhas\nprop &lt;- mean(dados$delta)*100\n\n\nVeja a Tabela 4.1 que apresenta as dez primeiras observações simuladas.\n\n\nCódigo\nlibrary(knitr)\n\nkable(\n  round(head(dados, 10), 4),\n  col.names = c(\"Tempo\", \"Delta\", \"Constante\", \"X1 ~ Bern(0,5)\", \"X2 ~ Normal(0, 1)\"),\n  escape = FALSE,\n  align = \"c\",\n  booktabs = TRUE\n)\n\n\n\n\nTabela 4.1: Dez primeiras observações Simuladas para Dados de Sobrevivência Censurados baseados no Modelo Exponencial.\n\n\n\n\n\n\nTempo\nDelta\nConstante\nX1 ~ Bern(0,5)\nX2 ~ Normal(0, 1)\n\n\n\n\n0,5804\n0\n1\n1\n0,2627\n\n\n0,8607\n1\n1\n1\n0,3934\n\n\n0,1656\n0\n1\n1\n1,3079\n\n\n0,6948\n1\n1\n1\n-0,2373\n\n\n0,2539\n1\n1\n1\n-0,3461\n\n\n0,0724\n1\n1\n1\n0,7248\n\n\n0,0019\n0\n1\n0\n-0,4015\n\n\n0,0147\n1\n1\n1\n-1,3736\n\n\n1,6933\n0\n1\n0\n0,6389\n\n\n0,9775\n0\n1\n0\n0,0040\n\n\n\n\n\n\n\n\nA proporção de censura nos dados foi: 44,8%.\n\n\n4.6.1.2 Ajuste do modelo ATF usando o pacote survival:\n\n\nCódigo\nlibrary(survival)\najust &lt;- survreg(Surv(times, delta)~x1+x2, dist = \"exponential\", data=dados)\nsummary(ajust)\n\n\n\nCall:\nsurvreg(formula = Surv(times, delta) ~ x1 + x2, data = dados, \n    dist = \"exponential\")\n              Value Std. Error     z      p\n(Intercept)  0,0688     0,0720  0,96   0,34\nx1          -0,4648     0,0951 -4,89  1e-06\nx2           0,4674     0,0476  9,82 &lt;2e-16\n\nScale fixed at 1 \n\nExponential distribution\nLoglik(model)= -313,9   Loglik(intercept only)= -369,5\n    Chisq= 111,2 on 2 degrees of freedom, p= 7e-25 \nNumber of Newton-Raphson Iterations: 5 \nn= 1000 \n\n\n\n\n4.6.1.3 Usando a função optim\n\nImplementando a função log-verossimilhança:\n\nA função log-verossimilhança, a ser maximizada, para um modelo AFT baseado na distribuição exponencial é dada por:\n\\[\n\\ln L(\\theta) = \\sum_{i = 1}^{n} \\delta_{i} \\ln{ \\alpha \\exp\\{ - \\mathbf{x'}_{i} \\boldsymbol{\\beta} \\} } + \\ln{ \\exp \\left\\{- \\alpha \\left( \\dfrac{t_{i}}{\\exp\\{ \\mathbf{x'}_{i} \\boldsymbol{\\beta} \\}} \\right) \\right\\} }.\n\\]\n\n\nCódigo\nStAFTexp &lt;- function(t, alpha.par, x.mat=x.mat, beta.par) {\n  # Combinação linear dos preditores lineares\n  effect &lt;- x.mat %*% beta.par\n  St &lt;- 1 - pexp(q = t/exp(effect), rate = alpha.par)\n  return(St)\n}\n\nhtAFTexp &lt;- function(t, alpha.par, x.mat=x.mat, beta.par) {\n  # Combinação linear dos preditores lineares\n  effect &lt;- x.mat %*% beta.par\n  ht &lt;- alpha.par / exp(effect)\n}\n\nloglikelihood &lt;- function(par, times, delta, x.mat) {\n  npar &lt;- length(par)\n  alpha &lt;- par[1]\n  betas &lt;- par[2:npar]\n  \n  St &lt;- StAFTexp(t=times, alpha.par=alpha, beta.par=betas, x.mat=x.mat)\n  ht &lt;- htAFTexp(t=times, alpha.par=alpha, beta.par=betas, x.mat=x.mat)\n  \n  flv &lt;- sum(delta*log(ht) + log(St))\n  return(-flv)\n}\n\n\n\nMaximizando:\n\n\n\nCódigo\ninit &lt;- rep(1, 4)\n\nX &lt;- as.matrix(dados[, 3:ncol(dados)])\n\nfit &lt;- optim(par=init, fn = loglikelihood, \n             gr = NULL, method = \"BFGS\", hessian = TRUE, \n             times=dados$times, delta=dados$delta, x.mat=X)\nfit\n\n\n$par\n[1]  1,5527  0,5088 -0,4647  0,4674\n\n$value\n[1] 313,9\n\n$counts\nfunction gradient \n      39        9 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n        [,1]   [,2]    [,3]    [,4]\n[1,]  185,82 -288,5 -159,72   68,45\n[2,] -288,53  448,0  248,00 -106,28\n[3,] -159,72  248,0  248,00  -49,45\n[4,]   68,45 -106,3  -49,45  467,08\n\n\n\n\n\n4.6.2 Modelo Weibull\nPode-se simular dados de sobrevivência conforme um modelo AFT baseado na distribuição Weibull através da expressão: \\[\nT = - \\alpha \\exp\\{\\mathbf{x'} \\boldsymbol{\\beta}\\} (\\ln{[1 - U]})^{1/\\gamma},\n\\]\nonde \\(U \\sim Uniforme(0, 1)\\). Sendo este o Método da Tranformação da Inversa.\n\n4.6.2.1 Geração dos Dados\n\nFunções de Geração:\n\n\n\nCódigo\ntime &lt;- function(t=t, gamma.par=gamma.par, alpha.par=alpha.par,\n                 beta.par=beta.par, x.mat=x.mat, u.unif=u.unif ){\n  1 - pweibull(q = t/exp(x.mat%*%beta.par), shape = gamma.par, scale = alpha.par) - u.unif\n}\n\ngen.weib &lt;- function(gamma.par=gamma.par, alpha.par=alpha.par, beta.par=beta.par, x.mat=x.mat){\n  raiz &lt;- uniroot(time, c(0.00001, 10000), gamma.par=gamma.par, alpha.par=alpha.par,\n                  beta.par=beta.par, x.mat=x.mat, u.unif=runif(1))\n  weib.time &lt;- raiz$root\n  return(weib.time)\n}\n\nsim.data.weib &lt;- function(n=n, gamma.par=gamma.par, alpha.par=alpha.par, beta.par=beta.par,\n                          x.mat=x.mat, alpha.parc=alpha.parc){\n  t &lt;- rep(0, n)     # Tempo de falha\n  c &lt;- rep(0, n)     # Tempo de censura\n  times &lt;- rep(0, n) # Tempo observado\n  \n  # Iteração\n  for (i in 1:n){\n    t[i] &lt;- gen.weib(gamma.par=gamma.par, alpha.par=alpha.par, beta.par=beta.par, x.mat=x.mat[i,])\n    c[i] &lt;- rexp(1, rate = alpha.parc)\n    times[i] &lt;- min(t[i], c[i])\n  }\n  \n  # Tempos Observados\n  delta &lt;- ifelse(t &lt;= c, 1, 0) \n  dados &lt;- data.frame(times, delta, x.mat)\n}\n\n\n\nSimulação dos dados:\n\n\n\nCódigo\nset.seed(123456789)\n\n# Tamanho da amostra e número de variáveis\nn &lt;- 1000\n\n# Parâmetro da distribuição Weibull\nshape &lt;- 2\nscale &lt;- 1.5\n\n# Matriz Design\nx1 &lt;- rbinom(n = n, size = 1, prob=0.5)\nx2 &lt;- rnorm(n=n)\nX &lt;- cbind(1, x1, x2)\n\n# Vetor de Coeficientes Betas\nbetas &lt;- c(0.5, -0.5, 0.5)\n\n# Simulando o Tempo de Sobrevivência\ndados &lt;- sim.data.weib(n = n, gamma.par = shape, alpha.par = scale, beta.par = betas,\n                       x.mat = X, alpha.parc = 1)\n\n# Proporção de Falhas\nprop &lt;- mean(dados$delta)*100\n\n\nVeja a Tabela 4.2 que apresenta as dez primeiras observações simuladas.\n\n\nCódigo\nlibrary(knitr)\n\nkable(\n  round(head(dados, 10), 4),\n  col.names = c(\"Tempo\", \"Delta\", \"Constante\", \"X1 ~ Bern(0,5)\", \"X2 ~ Normal(0, 1)\"),\n  escape = FALSE,\n  align = \"c\",\n  booktabs = TRUE\n)\n\n\n\n\nTabela 4.2: Dez primeiras observações Simuladas para Dados de Sobrevivência Censurados baseados no Modelo Weibull.\n\n\n\n\n\n\nTempo\nDelta\nConstante\nX1 ~ Bern(0,5)\nX2 ~ Normal(0, 1)\n\n\n\n\n0,8706\n0\n1\n1\n0,2627\n\n\n1,4803\n0\n1\n1\n0,3934\n\n\n0,2484\n0\n1\n1\n1,3079\n\n\n1,3282\n0\n1\n1\n-0,2373\n\n\n0,8490\n1\n1\n1\n-0,3461\n\n\n0,4201\n0\n1\n1\n0,7248\n\n\n0,0028\n0\n1\n0\n-0,4015\n\n\n0,1581\n1\n1\n1\n-1,3736\n\n\n2,5399\n0\n1\n0\n0,6389\n\n\n1,4662\n0\n1\n0\n0,0040\n\n\n\n\n\n\n\n\nA proporção de censura nos dados foi: 27,5%.\n\n\n4.6.2.2 Ajuste do modelo ATF usando o pacote survival:\n\n\nCódigo\nlibrary(survival)\najust &lt;- survreg(Surv(times, delta)~x1+x2, dist = \"weibull\", data=dados)\nsummary(ajust)\n\n\n\nCall:\nsurvreg(formula = Surv(times, delta) ~ x1 + x2, data = dados, \n    dist = \"weibull\")\n              Value Std. Error      z       p\n(Intercept)  0,8694     0,0524  16,58 &lt; 2e-16\nx1          -0,4534     0,0622  -7,29 3,2e-13\nx2           0,4803     0,0316  15,21 &lt; 2e-16\nLog(scale)  -0,6866     0,0427 -16,07 &lt; 2e-16\n\nScale= 0,503 \n\nWeibull distribution\nLoglik(model)= -387,6   Loglik(intercept only)= -503,3\n    Chisq= 231,3 on 2 degrees of freedom, p= 6e-51 \nNumber of Newton-Raphson Iterations: 7 \nn= 1000 \n\n\n\n\n4.6.2.3 Usando a função optim\n\nImplementando a função log-verossimilhança:\n\nA função log-verossimilhança, a ser maximizada, para um modelo AFT baseado na distribuição Weibull é dada por:\n\\[\n\\ln L(\\theta) = \\sum_{i = 1}^{n} \\delta_{i} \\ln{ \\dfrac{ \\gamma }{ \\alpha^{\\gamma} } t_{i}^{\\gamma - 1} \\exp\\{ - \\mathbf{x'}_{i} \\boldsymbol{\\beta} \\} } + \\ln{ \\exp \\left\\{ - \\left( \\dfrac{t_{i}}{\\alpha \\exp\\{ - \\mathbf{x'}_{i} \\boldsymbol{\\beta} \\} } \\right)^{\\gamma} \\right\\} }.\n\\]\n\n\nCódigo\nStAFTweib &lt;- function(t=times, gamma.par=gamma.par, alpha.par=alpha.par, x.mat=x.mat, beta.par=beta.par) {\n  elimpred &lt;- as.numeric(exp(x.mat%*%beta.par))\n  St &lt;- 1 - pweibull(q = t/elimpred, shape = gamma.par, scale = alpha.par)\n  return(St)\n}\n\nhtAFTweib &lt;- function(t=times, gamma.par=gamma.par, alpha.par=alpha.par, x.mat=x.mat, beta.par=beta.par) {\n  elimpred &lt;- as.numeric(exp(x.mat%*%beta.par))\n  f0 &lt;- dweibull(x = t/elimpred, shape = gamma.par, scale = alpha.par)\n  s0 &lt;- 1 - pweibull(q = t/elimpred, shape = gamma.par, scale = alpha.par)\n  h0 &lt;- f0/s0\n  ht &lt;- h0 / exp(x.mat%*%beta.par)\n  return(ht)\n}\n\nloglikelihood &lt;- function(par, times, delta, x.mat) {\n  npar &lt;- length(par)\n  gamma.par &lt;- par[1]\n  alpha.par &lt;- par[2]\n  beta.par &lt;- par[3:npar]\n  \n  St &lt;- StAFTweib(t=times, gamma.par=gamma.par, alpha.par=alpha.par, \n                 beta.par=beta.par, x.mat=x.mat)\n  ht &lt;- htAFTweib(t=times, gamma.par=gamma.par, alpha.par=alpha.par, \n                 beta.par=beta.par, x.mat=x.mat)\n  \n  flv &lt;- sum(delta*log(ht) + log(St))\n  return(-flv)\n}\n\n\n\nMaximizando:\n\n\n\nCódigo\ninit &lt;- rep(1, 5)\n\nX &lt;- as.matrix(dados[, 3:ncol(dados)])\n\nfit &lt;- optim(par=init, fn = loglikelihood, \n             gr = NULL, method = \"BFGS\", hessian = TRUE, \n             times=dados$times, delta=dados$delta, x.mat=X)\nfit\n\n\n$par\n[1]  1,9870  0,9900  0,8795 -0,4534  0,4803\n\n$value\n[1] 387,6\n\n$counts\nfunction gradient \n      61       17 \n\n$convergence\n[1] 0\n\n$message\nNULL\n\n$hessian\n       [,1]   [,2]   [,3]    [,4]    [,5]\n[1,] 159,41  115,5  114,3   47,73   34,15\n[2,] 115,48 1107,9 1096,7  646,08 -478,11\n[3,] 114,32 1096,7 1085,7  639,59 -473,31\n[4,]  47,73  646,1  639,6  639,59 -246,20\n[5,]  34,15 -478,1 -473,3 -246,20 1265,04\n\n\n\n\n\n4.6.3 Modelo Exponencial por Partes",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modelos de Tempo de Vida Acelerado</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referêcias",
    "section": "",
    "text": "Aalen, Odd O. 1978. “Nonparametric Inference for a Family of\nCounting Processes.” Annals of Statistics 6 (4): 701–26.\nhttps://doi.org/10.1214/aos/1176344247.\n\n\nAalen, Odd O., and Søren Johansen. 1978. “An Empirical Transition\nMatrix for Non-Homogeneous Markov Chains Based on Censored\nObservations.” Scandinavian Journal of Statistics 5 (3):\n141–50.\n\n\nBohoris, G. A. 1994. “Comparison of the Cumulative-Hazard and\nKaplan-Meier Estimators of the Survivor Function.” IEEE\nTransactions on Reliability 43 (2): 230–32. https://doi.org/10.1109/24.293488.\n\n\nBreslow, Norman, and John Crowley. 1974. “A Large Sample Study of\nthe Life Table and Product Limit Estimates Under Random\nCensorship.” The Annals of Statistics 2 (3): 437–53. https://doi.org/10.1214/aos/1176342705.\n\n\nBussab, Wilton de Oliveira, and Pedro Alberto Morettin. 2010.\nEstatística Básica. 6ª ed. São Paulo: Saraiva.\n\n\nColosimo, Enrico Antonio, and Suely Ruiz Giolo. 2006. Análise de\nSobrevivência Aplicada. 1st ed. São Paulo, Brasil: Blucher.\n\n\nGehan, Edmund A. 1965. “A Generalized Wilcoxon Test for Comparing\nArbitrarily Singly-Censored Samples.” Biometrika 52\n(1-2): 203–24. https://doi.org/10.2307/2333825.\n\n\nKalbfleisch, John D., and Ross L. Prentice. 1980. The Statistical\nAnalysis of Failure Time Data. Wiley Series in Probability and\nMathematical Statistics. New York: Wiley.\n\n\nKaplan, Edward L., and Paul Meier. 1958. “Nonparametric Estimation\nfrom Incomplete Observations.” Journal of the American\nStatistical Association 53 (282): 457–81. https://doi.org/10.1080/01621459.1958.10501452.\n\n\nKlein, John P. 1991. “Small Sample Moments of Some Estimators of\nthe Variance of the Kaplan-Meier and Nelson-Aalen Estimators.”\nScandinavian Journal of Statistics 18 (4): 333–40. https://doi.org/10.2307/4616203.\n\n\nLatta, Robert B. 1981. “A Monte Carlo Study of Some Two-Sample\nRank Tests with Censored Data.” Journal of the American\nStatistical Association 76 (375): 713–19. https://doi.org/10.2307/2287572.\n\n\nLawless, J. F. 1982. Statistical Models and Methods for Lifetime\nData. Wiley Series in Probability and Statistics. New York: John\nWiley & Sons.\n\n\nLindsey, Jane C., and Louise M. Ryan. 1998. “Methods for\nInterval-Censored Data.” Statistics in Medicine 17 (2):\n219–38. https://doi.org/10.1002/(SICI)1097-0258(19980130)17:2&lt;219::AID-SIM735&gt;3.0.CO;2-D.\n\n\nMantel, Nathan. 1966. “Evaluation of Survival Data and Two New\nRank Order Statistics Arising in Its Consideration.” Cancer\nChemotherapy Reports 50 (3): 163–70.\n\n\nMantel, Nathan, and William Haenszel. 1959. “Statistical Aspects\nof the Analysis of Data from Retrospective Studies of Disease.”\nJournal of the National Cancer Institute 22 (4): 719–48.\n\n\nMeier, Paul. 1975. “Estimation of a Survival Curve from Incomplete\nData.” Journal of the American Statistical Association\n70 (351): 607–10. https://doi.org/10.1080/01621459.1975.10479872.\n\n\nNelson, Wayne. 1972. “Theory and Applications of Hazard Plotting\nfor Censored Failure Data.” Technometrics 14 (4):\n945–66. https://doi.org/10.1080/00401706.1972.10488981.\n\n\nPeto, Richard, and Julian Peto. 1972. “Asymptotically Efficient\nRank Invariant Test Procedures.” Journal of the Royal\nStatistical Society: Series A (General) 135 (2): 185–98. https://doi.org/10.2307/2344317.\n\n\nPrentice, Ross L. 1978. “Linear Rank Tests with Right Censored\nData.” Biometrika 65 (1): 167–79. https://doi.org/10.2307/2335206.\n\n\nTurnbull, Bruce W. 1974. “Nonparametric Estimation of a\nSurvivorship Function with Doubly Censored Data.” Journal of\nthe American Statistical Association 69 (345): 169–73. https://doi.org/10.1080/01621459.1974.10480146.",
    "crumbs": [
      "Referêcias"
    ]
  }
]